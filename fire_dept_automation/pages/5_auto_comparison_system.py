import streamlit as st
import db_manager
import pandas as pd
import os
import fitz  # pymupdf
from PIL import Image
import pytesseract
import re
import config_loader as cfg
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import urllib.request
import subprocess
import utils

# è¨­å®šé é¢é…ç½®
st.set_page_config(layout="wide", page_title=f"{cfg.AGENCY_NAME}æª¢ä¿®ç”³å ±æ›¸æª¢æ ¸æ¯”å°ç³»çµ±")

# è¼‰å…¥ä¸­æ–‡å´é‚Šæ¬„
import sidebar_nav
sidebar_nav.render_chinese_sidebar()

# ==========================================
# ğŸ” ç™»å…¥é–€ç¦æª¢æŸ¥ (CRITICAL: å¿…é ˆåœ¨æ‰€æœ‰å…¶ä»–æ“ä½œä¹‹å‰)
# ==========================================
if "logged_in" not in st.session_state or not st.session_state.logged_in:
    st.warning("âš ï¸ æ­¤é é¢åƒ…é™æ¶ˆé˜²å±€åŒä»ä½¿ç”¨ï¼Œè«‹å…ˆé€²è¡Œç®¡ç†è€…ç™»å…¥ã€‚")
    st.info("æ­£åœ¨å°‡æ‚¨å°å‘è‡³ç™»å…¥é é¢...")
    st.page_link("pages/4_case_review.py", label="ğŸ” å‰å¾€ç™»å…¥é é¢", icon="ğŸ”")
    st.stop()  # é˜»æ­¢ä¸‹æ–¹ç¨‹å¼ç¢¼åŸ·è¡Œ

# é¡¯ç¤ºç™»å…¥ä½¿ç”¨è€…è³‡è¨Š
if 'user' in st.session_state and st.session_state.user:
    current_user = dict(st.session_state.user) # ç¢ºä¿è½‰æ›ç‚ºå­—å…¸ï¼Œé¿å… sqlite3.Row æ²’æœ‰ get æ–¹æ³•çš„å•é¡Œ
    st.sidebar.success(f"ğŸ‘¤ å·²ç™»å…¥ï¼š{current_user.get('username')} ({current_user.get('role')})")
st.sidebar.divider()

# è¼‰å…¥è‡ªå®šç¾© CSS
import utils
utils.load_custom_css()
import doc_integrity  # New module for integrity check

# ==========================================
# åŸæœ‰ç¨‹å¼ç¢¼ç¹¼çºŒ
# ==========================================

# ==========================================
# è¨­å®šå€
# ==========================================
# é è¨­ Tesseract è·¯å¾‘
DEFAULT_TESSERACT_PATH = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

# æœ¬åœ° tessdata è³‡æ–™å¤¾ (é¿å…æ¬Šé™å•é¡Œ)
LOCAL_TESSDATA_DIR = os.path.join(os.getcwd(), "tessdata")

# ==========================================
# å‡½å¼å€
# ==========================================

def send_email(sender_email, sender_password, receiver_email, subject, body):
    """ç™¼é€ Email é€šçŸ¥"""
    try:
        msg = MIMEMultipart()
        msg['From'] = sender_email
        msg['To'] = receiver_email
        msg['Subject'] = subject
        
        msg.attach(MIMEText(body, 'plain'))
        
        # é€£ç·šåˆ° Gmail SMTP Server (ä½¿ç”¨ SSL)
        server = smtplib.SMTP_SSL('smtp.gmail.com', 465)
        server.login(sender_email, sender_password)
        server.send_message(msg)
        server.quit()
        return True, "ç™¼é€æˆåŠŸ"
    except Exception as e:
        return False, f"ç™¼é€å¤±æ•—: {e}"

def download_lang_data():
    """ä¸‹è¼‰ç¹é«”ä¸­æ–‡èªè¨€åŒ…"""
    if not os.path.exists(LOCAL_TESSDATA_DIR):
        os.makedirs(LOCAL_TESSDATA_DIR)
    
    # ä¸‹è¼‰ chi_tra.traineddata
    url = "https://github.com/tesseract-ocr/tessdata_best/raw/main/chi_tra.traineddata"
    dest = os.path.join(LOCAL_TESSDATA_DIR, "chi_tra.traineddata")
    
    if not os.path.exists(dest):
        with st.spinner("æ­£åœ¨ä¸‹è¼‰ç¹é«”ä¸­æ–‡èªè¨€åŒ… (ç´„ 15MB)..."):
            try:
                urllib.request.urlretrieve(url, dest)
                st.success("ä¸‹è¼‰å®Œæˆï¼")
            except Exception as e:
                st.error(f"ä¸‹è¼‰å¤±æ•—: {e}")

    # å˜—è©¦è¤‡è£½ eng.traineddata (å¦‚æœæœ‰çš„è©±)ï¼Œå¦å‰‡ä¹Ÿä¸‹è¼‰
    eng_dest = os.path.join(LOCAL_TESSDATA_DIR, "eng.traineddata")
    if not os.path.exists(eng_dest):
        eng_url = "https://github.com/tesseract-ocr/tessdata_best/raw/main/eng.traineddata"
        try:
            urllib.request.urlretrieve(eng_url, eng_dest)
        except:
            pass # è‹±æ–‡éå¿…è¦ï¼Œå¤±æ•—å°±ç®—äº†


def pdf_to_images(pdf_file):
    """å°‡ PDF è½‰ç‚ºåœ–ç‰‡åˆ—è¡¨ (æ¯ä¸€é ä¸€å¼µåœ–)"""
    doc = fitz.open(stream=pdf_file.read(), filetype="pdf")
    images = []
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        pix = page.get_pixmap(dpi=300) # é«˜è§£æåº¦ä»¥åˆ© OCR
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        images.append(img)
    return images

def perform_ocr(image, tesseract_cmd):
    """å°åœ–ç‰‡é€²è¡Œ OCR è¾¨è­˜ (æ”¹ç”¨ subprocess ä»¥è§£æ±ºç·¨ç¢¼å•é¡Œ)"""
    temp_img_path = os.path.join(os.getcwd(), "temp_ocr_image.png")
    try:
        # 1. å…ˆå°‡åœ–ç‰‡å­˜ç‚ºæš«å­˜æª”
        image.save(temp_img_path)
        
        # 2. çµ„å»ºæŒ‡ä»¤
        # tesseract.exe <image> stdout -l chi_tra+eng --tessdata-dir <dir>
        cmd = [
            tesseract_cmd,
            temp_img_path,
            "stdout",
            "-l", "chi_tra+eng",
            "--tessdata-dir", LOCAL_TESSDATA_DIR
        ]
        
        # 3. åŸ·è¡ŒæŒ‡ä»¤ (éš±è—è¦–çª—)
        startupinfo = subprocess.STARTUPINFO()
        startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
        
        process = subprocess.run(
            cmd,
            capture_output=True,
            startupinfo=startupinfo
        )
        
        # 4. è™•ç†è¼¸å‡º (å˜—è©¦ä¸åŒç·¨ç¢¼)
        stdout_data = process.stdout
        stderr_data = process.stderr
        
        if process.returncode != 0:
            # å¦‚æœå¤±æ•—ï¼Œå˜—è©¦è§£ç¢¼éŒ¯èª¤è¨Šæ¯
            try:
                err_msg = stderr_data.decode('utf-8')
            except:
                err_msg = stderr_data.decode('cp950', errors='ignore')
            return f"OCR Error (Code {process.returncode}): {err_msg}"

        # å˜—è©¦ UTF-8 è§£ç¢¼
        try:
            text = stdout_data.decode('utf-8')
        except UnicodeDecodeError:
            # å¤±æ•—å‰‡å˜—è©¦ Big5 (cp950) - å¸¸è¦‹æ–¼ç¹é«”ä¸­æ–‡ Windows
            text = stdout_data.decode('cp950', errors='ignore')
            
        return text

    except Exception as e:
        return f"Error: {e}"
    finally:
        # æ¸…ç†æš«å­˜æª”
        if os.path.exists(temp_img_path):
            try:
                os.remove(temp_img_path)
            except:
                pass

# å®šç¾©æ¨™æº–è¨­å‚™æ¸…å–® (ä¾é•·åº¦æ’åºï¼Œå„ªå…ˆæ¯”å°é•·å­—ä¸²)
VALID_EQUIPMENT_LIST = sorted([
    "æ»…ç«å™¨", "è‡ªå‹•æ’’æ°´è¨­å‚™", "æƒ°æ€§æ°£é«”æ»…ç«è¨­å‚™", "ç°¡æ˜“è‡ªå‹•æ»…ç«è¨­å‚™", "è­¦å ±è¨­å‚™", 
    "ç«è­¦è‡ªå‹•è­¦å ±è¨­å‚™", "ä¸€ä¸€ä¹ç«ç½é€šå ±è£ç½®", "é¿é›£é€ƒç”Ÿè¨­å‚™", "æ¨™ç¤ºè¨­å‚™", 
    "æ¶ˆé˜²æ¶æ•‘ä¸Šä¹‹å¿…è¦è¨­å‚™", "é€£çµé€æ°´ç®¡", "ç„¡ç·šé›»é€šä¿¡è¼”åŠ©è¨­å‚™", "å…¶ä»–", 
    "å†·å»æ’’æ°´è¨­å‚™", "å®¤å…§æ¶ˆé˜²æ “è¨­å‚™", "æ°´éœ§æ»…ç«è¨­å‚™", "ä¹¾ç²‰æ»…ç«è¨­å‚™", 
    "é¹µåŒ–ç…™æ»…ç«è¨­å‚™", "ç“¦æ–¯æ¼æ°£ç«è­¦è‡ªå‹•è­¦å ±è¨­å‚™", "é¿é›£å™¨å…·", "æ¶ˆé˜²å°ˆç”¨è“„æ°´æ± ", 
    "ç·Šæ€¥é›»æºæ’åº§", "å®¤å¤–æ¶ˆé˜²æ “è¨­å‚™", "æ³¡æ²«æ»…ç«è¨­å‚™", "æµ·é¾æ»…ç«è¨­å‚™", 
    "ç·Šæ€¥å»£æ’­è¨­å‚™", "ç·Šæ€¥ç…§æ˜è¨­å‚™", "æ’ç…™è¨­å‚™", "é˜²ç½ç›£æ§ç³»çµ±ç¶œåˆæ“ä½œè£ç½®", 
    "å°„æ°´è¨­å‚™", "é…ç·š"
], key=len, reverse=True)

def normalize_equipment_str(text):
    """
    å°‡è¼¸å…¥çš„æ–‡å­— (OCR æˆ– ç³»çµ±è³‡æ–™) é€²è¡Œæ¨¡ç³Šæ¯”å°ï¼Œ
    åªä¿ç•™æ¨™æº–è¨­å‚™æ¸…å–®ä¸­**å·²å‹¾é¸**çš„é …ç›®ï¼Œä¸¦ä»¥é “è™Ÿåˆ†éš”ã€‚
    
    åˆ¤æ–·é‚è¼¯ï¼š
    1. å¦‚æœè¨­å‚™åç¨±é™„è¿‘æœ‰é ç¢¼ï¼ˆå¦‚ "2-1", "2-2"ï¼‰ï¼Œè¦–ç‚ºå·²å‹¾é¸
    2. å¦‚æœè¨­å‚™åç¨±å‰æœ‰å‹¾é¸ç¬¦è™Ÿï¼ˆâ˜‘, âœ“, â– , âˆšï¼‰ï¼Œè¦–ç‚ºå·²å‹¾é¸
    3. å¦‚æœè¨­å‚™åç¨±å¾Œæœ‰æ•¸å­—ï¼ˆè¡¨ç¤ºæ•¸é‡æˆ–é ç¢¼ï¼‰ï¼Œè¦–ç‚ºå·²å‹¾é¸
    """
    if not text or not isinstance(text, str):
        return ""
    
    found_items = []
    
    # å…ˆç§»é™¤å¸¸è¦‹å¹²æ“¾å­—å…ƒï¼Œæ–¹ä¾¿æ¯”å°
    clean_text = text.replace(" ", "").replace("ã€€", "")
    
    # å°‡æ–‡å­—æŒ‰è¡Œåˆ†å‰²ï¼Œæ–¹ä¾¿é€è¡Œåˆ†æ
    lines = clean_text.split("\n")
    
    # å®šç¾©å‹¾é¸ç¬¦è™Ÿ
    check_symbols = ['â˜‘', 'âœ“', 'â– ', 'âˆš', 'âœ”', 'â—', 'â˜']  # æ³¨æ„ï¼šâ˜ æ˜¯ç©ºæ–¹æ¡†ï¼Œä¹Ÿå¯èƒ½è¢« OCR èª¤è®€
    
    for item in VALID_EQUIPMENT_LIST:
        item_found = False
        
        # ç­–ç•¥ 1: é€è¡Œæƒæï¼Œæª¢æŸ¥è¨­å‚™åç¨±å¾Œæ˜¯å¦æœ‰é ç¢¼
        for line in lines:
            if item in line or item.replace("è¨­å‚™", "") in line:
                # æª¢æŸ¥é€™è¡Œæ˜¯å¦æœ‰é ç¢¼æ ¼å¼ (å¦‚ "2-1", "2-2", "2-13" ç­‰)
                # é ç¢¼é€šå¸¸æ˜¯ "æ•¸å­—-æ•¸å­—" çš„æ ¼å¼
                if re.search(r'\d+-\d+', line):
                    item_found = True
                    break
                # ä¹Ÿæª¢æŸ¥ç´”æ•¸å­— (å¦‚ "___7" è¡¨ç¤ºç¬¬ 7 é )
                if re.search(r'[._]{2,}\s*\d+', line):
                    item_found = True
                    break
                # æª¢æŸ¥æ˜¯å¦æœ‰å‹¾é¸ç¬¦è™Ÿåœ¨é …ç›®å‰é¢
                for symbol in check_symbols:
                    if symbol in line and line.find(symbol) < line.find(item) if item in line else False:
                        item_found = True
                        break
                if item_found:
                    break
        
        # ç­–ç•¥ 2: å¦‚æœé‚„æ²’æ‰¾åˆ°ï¼Œåšæ•´é«”æ–‡å­—æœå°‹
        if not item_found:
            # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æœå°‹ "è¨­å‚™åç¨± + ä»»æ„å­—å…ƒ + é ç¢¼"
            pattern = re.escape(item) + r'.*?(\d+-\d+)'
            if re.search(pattern, clean_text):
                item_found = True
            
            # ä¹Ÿæª¢æŸ¥ "è¨­å‚™æª¢æŸ¥è¡¨" æ ¼å¼ (å¦‚ "æ»…ç«å™¨æª¢æŸ¥è¡¨ 2-1")
            table_name = item.replace("è¨­å‚™", "") + "æª¢æŸ¥è¡¨"
            if table_name in clean_text:
                pattern2 = re.escape(table_name) + r'.*?(\d+-\d+)'
                if re.search(pattern2, clean_text):
                    item_found = True
        
        if item_found and item not in found_items:
            found_items.append(item)
            
    return "ã€".join(found_items)

def extract_info_from_ocr(text, pages_text_list=None):
    """å¾ OCR æ–‡å­—ä¸­æå–é—œéµè³‡è¨Š (æ¥µè‡´å»ç©ºç™½ç‰ˆ)"""
    info = {}
    
    # --- ç¬¬ä¸€é è§£æ (åŸºæœ¬è³‡æ–™) ---
    if text:
        lines = text.split('\n')
        for line in lines:
            # å¼·åŠ›å»é™¤æ‰€æœ‰ç©ºç™½ (åŒ…å«å…¨å½¢ç©ºæ ¼)
            clean_line = line.replace(" ", "").replace("ã€€", "").strip()
            if not clean_line: continue
            
            # 1. ç®¡ç†æ¬Šäºº
            # å„ªå…ˆæ‰¾ "ç®¡ç†æ¬Šäºº"
            if "ç®¡ç†æ¬Šäºº" in clean_line:
                match = re.search(r"ç®¡ç†æ¬Šäºº[:ï¼š|](.*)", clean_line)
                if match:
                    val = match.group(1)
                    # å¦‚æœæŠ“åˆ°çš„æ˜¯ "é€šè¨Šè™•..." é€™ç¨®ç„¡æ•ˆè³‡æ–™ï¼Œå°±å¿½ç•¥
                    if "é€šè¨Šè™•" not in val:
                        info['ç®¡ç†æ¬Šäºº'] = val
            
            # å‚™ç”¨ï¼šæ‰¾ "å§“å" (ä½†è¦æ’é™¤ "æª¢ä¿®äººå“¡å§“å")
            if "å§“å" in clean_line and "æª¢ä¿®äººå“¡" not in clean_line and "ç®¡ç†æ¬Šäºº" not in info:
                 match = re.search(r"å§“å[:ï¼š|](.*)", clean_line)
                 if match:
                     # å¯èƒ½æœƒæŠ“åˆ° "å»–å‰éŠ˜èº«åˆ†è­‰å­—è™Ÿ..."ï¼Œè©¦è‘—åˆ‡æ‰å¾Œé¢
                     val = match.group(1)
                     if "èº«åˆ†è­‰" in val:
                         val = val.split("èº«åˆ†è­‰")[0]
                     info['ç®¡ç†æ¬Šäºº'] = val
            
            # 2. åœ°å€
            if "åœ°å€" in clean_line:
                 # å„ªå…ˆæŠ“ "å ´æ‰€åœ°å€"
                 if "å ´æ‰€åœ°å€" in clean_line:
                     match = re.search(r"å ´æ‰€åœ°å€[:ï¼š|](.*)", clean_line)
                     if match:
                         info['å ´æ‰€åœ°å€'] = match.group(1)
                 # å¦‚æœæ˜¯ "åœ°å€" ä¸” å­—å…¸è£¡é‚„æ²’æœ‰ "å ´æ‰€åœ°å€" (é¿å…è¦†è“‹æ‰çœŸæ­£çš„å ´æ‰€åœ°å€ï¼Œå› ç‚ºå¾Œé¢å¯èƒ½æœƒå‡ºç¾æª¢ä¿®å–®ä½çš„åœ°å€)
                 elif "åœ°å€" in clean_line and 'å ´æ‰€åœ°å€' not in info:
                     match = re.search(r"åœ°å€[:ï¼š|](.*)", clean_line)
                     if match:
                         info['å ´æ‰€åœ°å€'] = match.group(1)

            # 3. é›»è©±
            if "é›»è©±" in clean_line:
                # æ’é™¤ "ç®¡ç†æ¬Šäººé›»è©±" (é€šå¸¸æˆ‘å€‘æƒ³æŠ“å ´æ‰€é›»è©±)
                # åªæœ‰ç•¶å­—å…¸è£¡é‚„æ²’æœ‰é›»è©±æ™‚æ‰æŠ“å– (é¿å…æŠ“åˆ°ä¸‹é¢æª¢ä¿®å…¬å¸çš„é›»è©±)
                if 'å ´æ‰€é›»è©±' not in info:
                    # ä¿®æ”¹ Regex ä»¥æ”¯æ´æ‹¬è™Ÿå’Œç©ºæ ¼ï¼Œä¾‹å¦‚ (089) 322112
                    match = re.search(r"é›»è©±[:ï¼š|]([\d\-\(\)\s]+)", clean_line)
                    if match:
                        # æŠ“å‡ºä¾†çš„å¯èƒ½æ˜¯ "089-330928" æˆ– "(089) 322112"
                        val = match.group(1).strip()
                        # ç°¡å–®éæ¿¾ï¼Œè‡³å°‘è¦æœ‰æ•¸å­—
                        if any(char.isdigit() for char in val):
                            info['å ´æ‰€é›»è©±'] = val
                     
            # 4. å ´æ‰€åç¨±
            if "å ´æ‰€åç¨±" in clean_line:
                match = re.search(r"å ´æ‰€åç¨±[:ï¼š|](.*)", clean_line)
                if match:
                    info['å ´æ‰€åç¨±'] = match.group(1)

            # 5. æ¶ˆé˜²è¨­å‚™ç¨®é¡ (ç¬¬ä¸€é å‚™ç”¨)
            # å¦‚æœæ²’æœ‰ç¬¬äºŒé è³‡æ–™ï¼Œæ‰å˜—è©¦å¾ç¬¬ä¸€é æŠ“ (é€šå¸¸æ˜¯ "ç”³å ±é …ç›®" æˆ– "æª¢ä¿®é …ç›®")
            if not pages_text_list:
                if "ç”³å ±é …ç›®" in clean_line or "æª¢ä¿®é …ç›®" in clean_line:
                     match = re.search(r"(ç”³å ±é …ç›®|æª¢ä¿®é …ç›®)[:ï¼š|](.*)", clean_line)
                     if match:
                         # ä½¿ç”¨æ­£è¦åŒ–å‡½å¼è™•ç†
                         info['æ¶ˆé˜²è¨­å‚™ç¨®é¡'] = normalize_equipment_str(match.group(2))

    # --- å¤šé è§£æ (å°‹æ‰¾æ¶ˆé˜²è¨­å‚™ç¨®é¡) ---
    if pages_text_list and isinstance(pages_text_list, list):
        target_page_text = None
        
        # 1. å„ªå…ˆå°‹æ‰¾ç›®éŒ„é  (æ ¹æ“šä½¿ç”¨è€…æŒ‡å®šçš„é—œéµå­—)
        # é—œéµå­—: "ç›®éŒ„", "é™„è¡¨", "äºŒã€æ¶ˆé˜²å®‰å…¨è¨­å‚™æª¢æŸ¥è¡¨"
        toc_keywords = ["ç›®éŒ„", "é™„è¡¨", "äºŒã€æ¶ˆé˜²å®‰å…¨è¨­å‚™æª¢æŸ¥è¡¨", "æ¶ˆé˜²å®‰å…¨è¨­å‚™æª¢ä¿®ç”³å ±æ›¸ç›®éŒ„"]
        
        for i, page_text in enumerate(pages_text_list):
            clean_text = page_text.replace(" ", "").replace("ã€€", "").strip()
            
            # æª¢æŸ¥æ˜¯å¦åŒ…å«ä»»ä¸€é—œéµå­—
            if any(kw.replace(" ", "") in clean_text for kw in toc_keywords):
                target_page_text = page_text
                info['toc_page_num'] = i + 1 # ç´€éŒ„é ç¢¼
                # print(f"DEBUG: Found TOC page with keyword at page {i+1}") # Debug use
                break
        
        # 4. æœ€å¾Œå›é€€ï¼šä½¿ç”¨ç¬¬äºŒé  (Index 1)
        if not target_page_text and len(pages_text_list) > 1:
            target_page_text = pages_text_list[1]
            info['toc_page_num'] = 2
            
        if target_page_text:
            # ç­–ç•¥ï¼š
            # 1. æ‰¾åˆ° "äºŒã€æ¶ˆé˜²å®‰å…¨è¨­å‚™æª¢æŸ¥è¡¨" ä¹‹å¾Œçš„å…§å®¹
            # 2. æŠ“å–æ‰€æœ‰åŒ…å« "æª¢æŸ¥è¡¨" çš„è¡Œ
            # 3. å‚³å…¥ normalize_equipment_str é€²è¡Œçµ±ä¸€æ¯”å°
            
            # ç‚ºäº†æé«˜æº–ç¢ºç‡ï¼Œæˆ‘å€‘å…ˆæŠŠ "äºŒã€æ¶ˆé˜²å®‰å…¨è¨­å‚™æª¢æŸ¥è¡¨" ä¹‹å¾Œçš„æ–‡å­—æˆªå–å‡ºä¾†
            # ç°¡å–®åšæ³•ï¼šæ‰¾åˆ°é—œéµå­—å¾Œï¼Œå–å…¶å¾Œçš„æ‰€æœ‰æ–‡å­—
            clean_page_text = target_page_text.replace(" ", "").replace("ã€€", "")
            if "æ¶ˆé˜²å®‰å…¨è¨­å‚™æª¢æŸ¥è¡¨" in clean_page_text:
                # åˆ‡å‰²å‡ºå¾ŒåŠæ®µ
                relevant_text = clean_page_text.split("æ¶ˆé˜²å®‰å…¨è¨­å‚™æª¢æŸ¥è¡¨", 1)[1]
                
                # ç›´æ¥å°é€™æ®µæ–‡å­—é€²è¡Œæ­£è¦åŒ–æ¯”å°
                normalized_eq = normalize_equipment_str(relevant_text)
                if normalized_eq:
                    info['æ¶ˆé˜²è¨­å‚™ç¨®é¡'] = normalized_eq
                 
    return info






# ==========================================
# ä¸»ç¨‹å¼å€
# ==========================================

st.title(f"ğŸš’ {cfg.AGENCY_NAME}æª¢ä¿®ç”³å ±æ›¸æª¢æ ¸æ¯”å°ç³»çµ±")

# CSS æ¨£å¼ï¼šå·¦å³åˆ†æ¬„ç¨ç«‹æ²å‹• (Split View)
st.markdown("""
    <style>
    /* é‡å°ä¸»å€å¡Š (Main) çš„é›™æ¬„ä½è¨­å®šç¨ç«‹æ²å‹• */
    
    /* å·¦å´æ¬„ä½ (ç”³å ±æª”æ¡ˆ)ï¼šè¨­å®šå›ºå®šé«˜åº¦ + æ²å‹•è»¸ */
    section[data-testid="stMain"] div[data-testid="column"]:nth-of-type(1) > div[data-testid="stVerticalBlock"] {
        height: 80vh;       /* è¨­å®šé«˜åº¦ä½”è¢å¹• 80% */
        overflow-y: auto;   /* è¶…éé«˜åº¦é¡¯ç¤ºæ²å‹•è»¸ */
        padding-right: 15px;
        border-right: 1px solid #444; /* ä¸­é–“åŠ ä¸€æ¢åˆ†éš”ç·š */
    }
    
    /* å³å´æ¬„ä½ (æ¯”å°è¡¨æ ¼)ï¼šè¨­å®šå›ºå®šé«˜åº¦ + æ²å‹•è»¸ */
    section[data-testid="stMain"] div[data-testid="column"]:nth-of-type(2) > div[data-testid="stVerticalBlock"] {
        height: 80vh;       /* è¨­å®šé«˜åº¦ä½”è¢å¹• 80% */
        overflow-y: auto;   /* è¶…éé«˜åº¦é¡¯ç¤ºæ²å‹•è»¸ */
        padding-left: 15px;
    }
    </style>
    """, unsafe_allow_html=True)

# --- CRITICAL: è·¯å¾‘è®Šæ•¸ Session è¨˜æ†¶èˆ‡åˆå§‹åŒ– ---
# Tesseract è·¯å¾‘åˆå§‹åŒ–
if "tesseract_exe_path" not in st.session_state or not st.session_state["tesseract_exe_path"]:
    st.session_state["tesseract_exe_path"] = utils.get_default_tesseract_path()

# Excel è·¯å¾‘åˆå§‹åŒ–
if "system_excel_path" not in st.session_state or not st.session_state["system_excel_path"]:
    st.session_state["system_excel_path"] = utils.get_default_excel_path()

# æª¢æŸ¥ç‹€æ…‹ä»¥æ±ºå®š Expander æ˜¯å¦å±•é–‹
# ä½¿ç”¨ Session State çš„å€¼é€²è¡Œæª¢æŸ¥ï¼Œç¢ºä¿ç©©å®šæ€§

# --- DEBUG: è¼¸å‡ºè·¯å¾‘æª¢æŸ¥è³‡è¨Š ---
print("-" * 50, flush=True)
print(f"DEBUG: Check Tesseract Path: [{st.session_state.get('tesseract_exe_path')}]", flush=True)
print(f"DEBUG: Check Excel Path: [{st.session_state.get('system_excel_path')}]", flush=True)
print("-" * 50, flush=True)
# -----------------------------

use_vision_ai = False # åˆå§‹åŒ–å…¨åŸŸè®Šæ•¸ï¼Œé¿å… NameError

tesseract_is_ok = os.path.exists(st.session_state["tesseract_exe_path"])
excel_is_loaded = False

if os.path.exists(st.session_state["system_excel_path"]):
    # å˜—è©¦é è¼‰å…¥æª¢æŸ¥ (åˆ©ç”¨ cache)
    df_check = utils.load_system_data(st.session_state["system_excel_path"])
    if df_check is not None and not df_check.empty:
        excel_is_loaded = True

expand_config = not (tesseract_is_ok and excel_is_loaded)

# --- å´é‚Šæ¬„ï¼šè³‡æ–™è¼‰å…¥ ---
with st.sidebar:
    # è¼‰å…¥è³‡æ–™ (ä½¿ç”¨ Session State çš„å€¼)
    df_system = utils.load_system_data(st.session_state["system_excel_path"])
    
    selected_place = None
    
    # 1. é¸æ“‡å ´æ‰€ (æ”¾åœ¨æœ€ä¸Šé¢)
    if df_system is not None:
        st.header("1. é¸æ“‡æ¯”å°å ´æ‰€")
        
        # å–å¾—æ‰€æœ‰å ´æ‰€åç¨±
        all_place_names = df_system['å ´æ‰€åç¨±'].astype(str).unique().tolist()
        
        # æœå°‹æ¡†
        search_term = st.text_input("ğŸ” æœå°‹å ´æ‰€åç¨± (æ”¯æ´æ¨¡ç³Šæ¯”å°)", "")
        
        # æ ¹æ“šæœå°‹çµæœéæ¿¾
        if search_term:
            filtered_places = [p for p in all_place_names if search_term in p]
        else:
            filtered_places = all_place_names
            
        # å¦‚æœæœå°‹ä¸åˆ°ï¼Œé¡¯ç¤ºæç¤º
        if not filtered_places:
            st.warning("æ‰¾ä¸åˆ°ç¬¦åˆçš„å ´æ‰€")
        else:
            # ä¸‹æ‹‰é¸å–® (åªé¡¯ç¤ºéæ¿¾å¾Œçš„çµæœ)
            selected_place = st.selectbox(
                "è«‹é¸æ“‡å ´æ‰€", 
                filtered_places,
                index=None,  # é è¨­ä¸é¸å–ä»»ä½•é …ç›®
                placeholder="è«‹é¸æ“‡å ´æ‰€..."
            )
        
        st.divider()
    else:
        st.warning("å°šæœªè¼‰å…¥ç³»çµ±è³‡æ–™ï¼Œè«‹å…ˆè¨­å®šè³‡æ–™ä¾†æºã€‚")
        st.divider()
    
    # 2. è¨­å®šèˆ‡è³‡æ–™ä¾†æº (ä½¿ç”¨ Expander åŒ…è¦†)
    with st.expander("2. è¨­å®šèˆ‡è³‡æ–™ä¾†æº", expanded=expand_config):
        # Tesseract è¨­å®š
        st.markdown("#### OCR è¾¨è­˜å¼•æ“è¨­å®š")
        user_input_path = st.text_input("Tesseract åŸ·è¡Œæª”è·¯å¾‘", key="tesseract_exe_path")
        
        # æ™ºæ…§ä¿®æ­£è·¯å¾‘
        tesseract_path = user_input_path
        if os.path.isdir(user_input_path):
            tesseract_path = os.path.join(user_input_path, "tesseract.exe")
            st.info(f"ğŸ’¡ å·²è‡ªå‹•ä¿®æ­£è·¯å¾‘ç‚ºï¼š{tesseract_path}")
            
        if not os.path.exists(tesseract_path):
            st.error(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆï¼š{tesseract_path}")
        else:
            st.success("âœ… Tesseract è·¯å¾‘æ­£ç¢º")
            
        # æª¢æŸ¥èªè¨€åŒ…
        if not os.path.exists(os.path.join(LOCAL_TESSDATA_DIR, "chi_tra.traineddata")):
            st.warning("âš ï¸ ç¼ºå°‘ç¹é«”ä¸­æ–‡èªè¨€åŒ…")
            if st.button("ğŸ“¥ ä¸‹è¼‰ä¸­æ–‡èªè¨€åŒ… (å¿…è¦)"):
                download_lang_data()
        
        st.divider()
        
        # Excel è³‡æ–™ä¾†æºè¨­å®š
        st.markdown("#### ç³»çµ±è³‡æ–™ä¾†æºè¨­å®š")
        st.text_input("ç³»çµ±åˆ—ç®¡è³‡æ–™è¡¨ Excel è·¯å¾‘", key="system_excel_path")
        
        if not os.path.exists(st.session_state["system_excel_path"]):
            st.error(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆï¼š{st.session_state['system_excel_path']}")
        else:
            st.success("âœ… Excel æª”æ¡ˆè®€å–æˆåŠŸ")
            if st.button("ğŸ”„ é‡æ–°è®€å– Excel"):
                utils.load_system_data.clear()
                st.cache_data.clear()
                st.rerun()
    # 3. é™¤éŒ¯ç”¨ï¼šé¡¯ç¤ºæ¬„ä½åç¨±
    if df_system is not None:
        with st.expander("3. ğŸ” æŸ¥çœ‹ Excel æ¬„ä½åç¨± (é™¤éŒ¯ç”¨)"):
            st.write(df_system.columns.tolist())

# --- ä¸»ç•«é¢ï¼šæ¯”å°å€ ---
uploaded_file = None
target_row = None

# 1. å–å¾—æ¡ˆä»¶è³‡æ–™ (æ ¹æ“šè§’è‰²æ¬Šé™)
if 'user' in st.session_state and st.session_state.user:
    current_username = st.session_state.user['username']
    current_role = st.session_state.user['role']
    
    if current_role == "admin":
        # Admin å¯ä»¥çœ‹åˆ°æ‰€æœ‰æ¡ˆä»¶
        my_cases = db_manager.get_all_cases()
        st.toast(f"ğŸ‘‘ ç®¡ç†å“¡æ¨¡å¼ï¼šå·²è¼‰å…¥å…¨ç³»çµ±å…± {len(my_cases)} ç­†æ¡ˆä»¶", icon="ğŸ›¡ï¸")
    else:
        # ä¸€èˆ¬åŒä»åªèƒ½çœ‹åˆ°æŒ‡æ´¾çµ¦è‡ªå·±çš„
        my_cases = db_manager.get_cases_by_assignee(current_username)
else:
    my_cases = []

# 2. å»ºç«‹æ¡ˆä»¶é¸æ“‡é¸å–®
case_options = {f"{c['id']} - {c['place_name']} - {c['status']}": c for c in my_cases}
selected_case_label = st.selectbox(
    "è«‹é¸æ“‡è¦å¯©æ ¸çš„æ¡ˆä»¶",
    options=list(case_options.keys()),
    index=None,
    placeholder="è«‹é¸æ“‡è¦å¯©æ ¸çš„æ¡ˆä»¶..."
)

target_case = None
uploaded_file_path = None

if selected_case_label:
    target_case = case_options[selected_case_label]
    uploaded_file_path = target_case['file_path']

# 1. å…ˆå»ºç«‹ç‰ˆé¢ (ä½¿ç”¨ Tabs åˆ†é )
tab_main, tab_check = st.tabs(["ğŸ” ç”³å ±æ›¸æ¯”å°", "ğŸ“‘ æ–‡ä»¶å®Œæ•´æ€§æª¢æŸ¥"])

# ä¸»æ¯”å°é é¢
col1, col2 = tab_main.columns([1, 1])

# ç”¨æ–¼å„²å­˜ OCR çµæœ
all_ocr_text = ""
page_one_text = ""
page_two_text = ""
extracted_data = {}
ocr_place_name = ""

# å·¦æ¬„ï¼šæ°‘çœ¾ç”³å ±è³‡æ–™ (PDF/åœ–ç‰‡)
with col1:
    # st.subheader("ğŸ“„ æ°‘çœ¾ç”³å ±è³‡æ–™ (OCR è¾¨è­˜)") # ç§»é™¤èˆŠæ¨™é¡Œ
    
    # ä½¿ç”¨ Columns å°‡æ¨™é¡Œèˆ‡ç‹€æ…‹è¨Šæ¯æ’åœ¨åŒä¸€åˆ—
    col_header, col_status_msg = st.columns([3, 2]) # èª¿æ•´æ¯”ä¾‹ä»¥é¿å…æ¨™é¡Œæ›è¡Œ
    with col_header:
        st.subheader("ğŸ“„ æ°‘çœ¾ç”³å ±è³‡æ–™")
    
    # å»ºç«‹ä¸‰æ¬„ä½ˆå±€ï¼šæŒ‰éˆ• | OCR å¼•æ“ | AI è¨­å®š
    col_btn, col_engine, col_ai = st.columns([1, 2, 2])
    
    with col_btn:
        force_reocr = st.button("ğŸ”„ å¼·åˆ¶é‡æ–°è¾¨è­˜", help="å¦‚æœè¦ºå¾—è¾¨è­˜çµæœæœ‰èª¤ï¼Œå¯é»æ­¤é‡æ–°åŸ·è¡Œ OCR")
    
    with col_engine:
        # OCR å¼•æ“é¸æ“‡
        ocr_engine = st.radio(
            "OCR å¼•æ“",
            options=["Tesseract", "PaddleOCR"],
            index=1, # é è¨­ PaddleOCR
            horizontal=True,
            label_visibility="collapsed" # éš±è—æ¨™é¡Œï¼Œç¯€çœç©ºé–“
        )
        use_paddle = (ocr_engine == "PaddleOCR")
        
        # å¿«é€Ÿæ¨¡å¼é¸é …
        use_fast_mode = st.checkbox("âš¡ å¿«é€Ÿæ¨¡å¼ (å£“ç¸®åœ–ç‰‡)", value=True, help="é™ä½åœ–ç‰‡è§£æåº¦ (150 DPI) ä»¥åŠ å¿« OCR é€Ÿåº¦ï¼Œä½†å¯èƒ½å½±éŸ¿å°å­—è¾¨è­˜ç‡ã€‚")
        
        # æª¢æŸ¥ PaddleOCR å¯ç”¨æ€§
        if use_paddle:
            try:
                import paddle_ocr
                if not paddle_ocr.is_paddle_available():
                    st.caption("âš ï¸ PaddleOCR æœªå®‰è£")
            except:
                st.caption("âš ï¸ PaddleOCR æœªå®‰è£")

    with col_ai:
        # AI è¨­å®š
        # use_ai_mode = st.checkbox("å•Ÿç”¨ AI æ™ºæ…§åˆ†æ (Ollama)", value=True) # ç§»é™¤ Checkboxï¼Œæ”¹ç‚ºå¸¸é§
        use_ai_mode = True # å¼·åˆ¶å•Ÿç”¨
        st.caption("âœ… å·²å•Ÿç”¨ AI æ™ºæ…§åˆ†æ (Ollama)")
        
        use_vision_ai = st.checkbox("å•Ÿç”¨ Vision AI (å¯¦é©—æ€§)", value=False, help="ä½¿ç”¨å¤šæ¨¡æ…‹æ¨¡å‹ (Llama 3.2 Vision) ç›´æ¥åˆ†æåœ–ç‰‡ï¼Œå¯æ›´æº–ç¢ºè­˜åˆ¥ç›®éŒ„èˆ‡è¡¨æ ¼çµæ§‹ï¼Œä½†é€Ÿåº¦è¼ƒæ…¢ã€‚")
        
        # æ¨¡å‹é¸æ“‡ (ä¸‹æ‹‰å¼é¸å–®)
        if use_ai_mode:
            text_model = st.selectbox(
                "é¸æ“‡æ¨¡å‹",
                options=["llama3", "gemma2", "mistral", "qwen2.5:7b"],
                index=0,
                label_visibility="collapsed" # éš±è—æ¨™é¡Œï¼Œç¯€çœç©ºé–“
            )
        else:
            text_model = "llama3"

    if target_case and uploaded_file_path:
        if not os.path.exists(uploaded_file_path):
             st.error(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆï¼š{uploaded_file_path}")
        else:
            # ç”¢ç”Ÿæª”æ¡ˆå”¯ä¸€è­˜åˆ¥ç¢¼ (ä½¿ç”¨æª”å+å¤§å°)
            file_key = f"{os.path.basename(uploaded_file_path)}_{os.path.getsize(uploaded_file_path)}"
            
            # æª¢æŸ¥ Session State æ˜¯å¦å·²æœ‰æ­¤æª”æ¡ˆçš„ OCR çµæœ
            if 'ocr_cache' not in st.session_state:
                st.session_state.ocr_cache = {}
            
            # åˆ¤æ–·æ˜¯å¦éœ€è¦åŸ·è¡Œ OCR
            # æ¢ä»¶ï¼š
            # 1. æª”æ¡ˆè®Šæ›´ (file_key ä¸åŒ)
            # 2. ä½¿ç”¨è€…å¼·åˆ¶é‡æ–°è¾¨è­˜
            # 3. Cache ç‚ºç©º
            # 4. OCR å¼•æ“è®Šæ›´ (åµæ¸¬ session state ä¸­çš„ engine)
            
            # æª¢æŸ¥ä¸Šæ¬¡ä½¿ç”¨çš„å¼•æ“
            last_engine = st.session_state.ocr_cache.get('last_engine')
            engine_changed = last_engine != ocr_engine
            
            cache_miss = st.session_state.ocr_cache.get('file_key') != file_key
            
            if cache_miss or force_reocr or engine_changed:
                if force_reocr:
                    st.toast("æ­£åœ¨é‡æ–°åŸ·è¡Œ OCR...", icon="ğŸ”„")
                if engine_changed:
                    st.toast(f"åˆ‡æ›å¼•æ“è‡³ {ocr_engine}ï¼Œé‡æ–°è¾¨è­˜...", icon="âš™ï¸")
                
                # æ›´æ–° last_engine
                st.session_state.ocr_cache['last_engine'] = ocr_engine
                
                # æ¸…é™¤ AI å¿«å–ï¼Œç¢ºä¿é‡æ–°åˆ†æ
                if 'ai_result' in st.session_state.ocr_cache:
                    del st.session_state.ocr_cache['ai_result']
                if 'last_text_model' in st.session_state.ocr_cache:
                    del st.session_state.ocr_cache['last_text_model']
                
                # æ¸…é™¤ Vision AI å¿«å–
                if 'vision_analysis' in st.session_state:
                    del st.session_state['vision_analysis']
                if 'vision_cache_key' in st.session_state:
                    del st.session_state['vision_cache_key']
                
                # 1. å…ˆè½‰æ›ä¸¦é¡¯ç¤ºåœ–ç‰‡ (è®“ä½¿ç”¨è€…å…ˆçœ‹åˆ°é è¦½)
                images = []
                # target_dpi = 150 if use_fast_mode else 300
                target_dpi = 300 # å¼·åˆ¶ä½¿ç”¨ 300 DPI ä»¥æå‡ OCR å°å‹¾é¸æ¡†çš„è¾¨è­˜ç‡ (User Request)
                
                try:
                    ext = os.path.splitext(uploaded_file_path)[1].lower()
                    if ext == ".pdf":
                        # é¡¯ç¤ºè½‰æ›è¨Šæ¯
                        with st.spinner(f"ğŸ“„ æ­£åœ¨å°‡ PDF è½‰æ›ç‚ºåœ–ç‰‡ (DPI: {target_dpi})..."):
                            with open(uploaded_file_path, "rb") as f:
                                images = utils.pdf_to_images(f, dpi=target_dpi)
                    elif ext in [".doc", ".docx"]:
                         with st.spinner("ğŸ“„ æ­£åœ¨å°‡ Word æ–‡ä»¶è½‰æ›ç‚º PDF (éœ€å®‰è£ Microsoft Word)..."):
                            temp_pdf_path = None
                            try:
                                temp_pdf_path = utils.convert_doc_to_pdf(uploaded_file_path)
                                with open(temp_pdf_path, "rb") as f:
                                    images = utils.pdf_to_images(f, dpi=target_dpi)
                            except Exception as e:
                                st.error(f"âŒ Word è½‰æ›å¤±æ•—: {e}")
                                images = []
                            finally:
                                # Clean up temp PDF
                                if temp_pdf_path and os.path.exists(temp_pdf_path):
                                    try: os.remove(temp_pdf_path)
                                    except: pass
                    elif ext in [".jpg", ".jpeg", ".png", ".bmp", ".tiff"]:
                        img = Image.open(uploaded_file_path)
                        if use_fast_mode and img.width > 1500:
                            ratio = 1500 / img.width
                            new_height = int(img.height * ratio)
                            img = img.resize((1500, new_height), Image.Resampling.LANCZOS)
                        images = [img]
                    else:
                        st.error(f"âŒ ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼ï¼š{ext}ã€‚è«‹ä¸Šå‚³ PDFã€Word æˆ–åœ–ç‰‡æª”ã€‚")
                        images = []
                except Exception as e:
                    st.error(f"ç„¡æ³•è®€å–æª”æ¡ˆ: {e}")
                    images = []
                
                if images:
                    # å…ˆé¡¯ç¤ºåœ–ç‰‡é è¦½
                    for i, img in enumerate(images):
                        st.image(img, caption=f"ç¬¬ {i+1} é  (é è¦½)", use_column_width=True)
                    
                    # 2. åŸ·è¡Œ OCR
                    with st.spinner("ğŸ” æ­£åœ¨é€²è¡Œ OCR è¾¨è­˜ä¸­ (è«‹ç¨å€™)..."):
                        temp_all_text = ""
                        temp_p1_text = ""
                        temp_p2_text = ""
                        
                        # åŸ·è¡Œ OCR
                        pages_text = []
                        pages_info = [] # Store page info
                        
                        for i, img in enumerate(images):
                            # åŸ·è¡Œ OCR (æ ¹æ“šé¸å®šçš„å¼•æ“)
                            if use_paddle:
                                try:
                                    import paddle_ocr
                                    ocr_text = paddle_ocr.perform_paddle_ocr(img)
                                    
                                    # æª¢æŸ¥ PaddleOCR æ˜¯å¦å›å‚³éŒ¯èª¤
                                    if "Error:" in ocr_text:
                                        st.warning(f"PaddleOCR åŸ·è¡Œå¤±æ•— (ç¬¬ {i+1} é ): {ocr_text}")
                                        st.info("ğŸ”„ è‡ªå‹•åˆ‡æ›è‡³ Tesseract é€²è¡Œé‡è©¦...")
                                        ocr_text = perform_ocr(img, tesseract_path)
                                        
                                except Exception as e:
                                    st.warning(f"PaddleOCR åŸ·è¡Œå¤±æ•—ï¼Œåˆ‡æ›è‡³ Tesseract: {e}")
                                    ocr_text = perform_ocr(img, tesseract_path)
                            else:
                                ocr_text = perform_ocr(img, tesseract_path)
                            
                            # å†æ¬¡æª¢æŸ¥ Tesseract æ˜¯å¦ä¹Ÿå¤±æ•—
                            if "Error:" in ocr_text:
                                st.error(f"âŒ OCR åš´é‡å¤±æ•— (ç¬¬ {i+1} é ): {ocr_text}")
                                
                            temp_all_text += ocr_text + "\n"
                            pages_text.append(ocr_text)
                            
                            # Identify page type
                            first_30 = ocr_text[:30]
                            page_type = doc_integrity.identify_page_type(first_30)
                            
                            pages_info.append({
                                "page_num": i + 1,
                                "first_30": first_30,
                                "type": page_type,
                                "text": ocr_text
                            })
                            
                            if i == 0: temp_p1_text = ocr_text
                            if i == 1: temp_p2_text = ocr_text
                        
                        # å­˜å…¥ Session State
                        st.session_state.ocr_cache['file_key'] = file_key
                        st.session_state.ocr_cache['all_ocr_text'] = temp_all_text
                        st.session_state.ocr_cache['page_one_text'] = temp_p1_text
                        st.session_state.ocr_cache['page_two_text'] = temp_p2_text
                        st.session_state.ocr_cache['pages_text'] = pages_text # å„²å­˜æ‰€æœ‰é é¢æ–‡å­—
                        st.session_state.ocr_cache['pages_info'] = pages_info # å„²å­˜é é¢è³‡è¨Š
                        st.session_state.ocr_cache['images'] = images 
                        
                        # é‡æ–°æ•´ç†é é¢ä»¥é¡¯ç¤º OCR çµæœ
                        st.rerun()
            else:
                with col_status_msg:
                    st.success("âœ… ä½¿ç”¨å¿«å–è³‡æ–™ (ç„¡éœ€é‡æ–°è¾¨è­˜)")
            
            # å¾ Session State å–å‡ºè³‡æ–™ (Cache Hit)
            all_ocr_text = st.session_state.ocr_cache.get('all_ocr_text', "")
            page_one_text = st.session_state.ocr_cache.get('page_one_text', "")
            page_two_text = st.session_state.ocr_cache.get('page_two_text', "")
            pages_text = st.session_state.ocr_cache.get('pages_text', [])
            cached_images = st.session_state.ocr_cache.get('images', [])
            # æå–è³‡æ–™ (é‚è¼¯åˆ†æµ)
            if use_ai_mode:
                import ai_engine
                if ai_engine.is_ollama_available():
                    # --- AI Result Caching Logic ---
                    cached_ai_result = st.session_state.ocr_cache.get('ai_result')
                    cached_model = st.session_state.ocr_cache.get('last_text_model')
                    
                    # Check if cache is valid (exists and model hasn't changed)
                    if cached_ai_result and cached_model == text_model:
                        ai_result = cached_ai_result
                        st.caption(f"âš¡ ä½¿ç”¨ AI åˆ†æå¿«å–è³‡æ–™ (Model: {text_model})")
                    else:
                        # åŸ·è¡Œ AI åˆ†æ
                        with st.spinner(f"ğŸ¤– AI ({text_model}) æ­£åœ¨åˆ†ææ–‡ä»¶å…§å®¹..."):
                            if use_vision_ai:
                                # === Vision AI æ··åˆæ¨¡å¼ ===
                                st.info("ğŸ‘ï¸ æ­£åœ¨ä½¿ç”¨ Vision AI é€²è¡Œè¦–è¦ºåŒ–åˆ†æ (Llama 3.2 Vision)...")
                                
                                # 1. ä½¿ç”¨ Vision AI åˆ†ææ–‡ä»¶çµæ§‹èˆ‡å‹¾é¸é …ç›® (é‡å°åœ–ç‰‡)
                                # æ³¨æ„: é€™è£¡å‡è¨­ä½¿ç”¨è€…å·²å®‰è£ llama3.2-vision
                                vision_result = ai_engine.analyze_document_structure(cached_images, model="llama3.2-vision")
                                
                                # 2. ä½¿ç”¨ Text AI åˆ†æåŸºæœ¬è³‡æ–™ (é‡å°ç¬¬ä¸€é  OCR æ–‡å­—)
                                # Vision æ¨¡å‹æœ‰æ™‚å°å¯†é›†æ–‡å­—çš„æå–ä¸å¦‚ç´”æ–‡å­—æ¨¡å‹ç©©å®šï¼Œå› æ­¤æ··åˆä½¿ç”¨
                                text_result = ai_engine.analyze_page_with_ai(page_one_text, model=text_model)
                                
                                # 3. åˆä½µçµæœ
                                ai_result = text_result
                                if vision_result.get('required_items'):
                                    ai_result['equipment_list'] = vision_result['required_items']
                                    st.toast(f"Vision AI æˆåŠŸæå– {len(ai_result['equipment_list'])} é …è¨­å‚™", icon="ğŸ‘ï¸")
                                else:
                                    st.warning("Vision AI æœªèƒ½æå–åˆ°è¨­å‚™æ¸…å–®ï¼Œå°‡ä½¿ç”¨ OCR æ–‡å­—åˆ†æçµæœä½œç‚ºå‚™æ¡ˆã€‚")
                                
                            else:
                                # === ç´”æ–‡å­—æ¨¡å¼ ===
                                ai_result = ai_engine.analyze_document(pages_text, model=text_model)
                            
                            # ç«‹å³æ‡‰ç”¨ç°¡ç¹è½‰æ›
                            ai_result = utils.convert_to_traditional(ai_result)
                            
                            # Save to cache
                            st.session_state.ocr_cache['ai_result'] = ai_result
                            st.session_state.ocr_cache['last_text_model'] = text_model
                            st.toast("å·²å®Œæˆ AI æ™ºæ…§åˆ†æ", icon="ğŸ¤–")
                    
                    # è™•ç† AI çµæœ
                    if "error" in ai_result:
                        st.error(f"AI åˆ†æéŒ¯èª¤: {ai_result['error']}")
                        if "raw_response" in ai_result:
                            with st.expander("ğŸ” æŸ¥çœ‹ AI åŸå§‹å›æ‡‰ (é™¤éŒ¯ç”¨)"):
                                st.code(ai_result["raw_response"])
                        
                        extracted_data = extract_info_from_ocr(page_one_text, pages_text)
                        # æ‡‰ç”¨ç°¡ç¹è½‰æ›
                        extracted_data = utils.convert_to_traditional(extracted_data)
                    else:
                        # å®šç¾©æ¸…æ´—å‡½å¼
                        def clean_ai_value(val):
                            if isinstance(val, dict):
                                return str(list(val.values())[0]).replace(" ", "")
                            if isinstance(val, list):
                                return "ã€".join([str(v) for v in val])
                            if val is None:
                                return ""
                            if isinstance(val, str):
                                return val.replace(" ", "")
                            return str(val).replace(" ", "")

                        # Helper function to process equipment list
                        def process_equipment_list(eq_list):
                            if not eq_list: return ""
                            processed = []
                            for item in eq_list:
                                clean_item = clean_ai_value(item)
                                if clean_item:
                                    processed.append(clean_item)
                            return "ã€".join(processed)

                        # å˜—è©¦æ˜ å°„æ¬„ä½
                        extracted_data = {
                            'å ´æ‰€åç¨±': clean_ai_value(ai_result.get('place_name')),
                            'å ´æ‰€åœ°å€': clean_ai_value(ai_result.get('address')),
                            'ç®¡ç†æ¬Šäºº': clean_ai_value(ai_result.get('management_person')),
                            'å ´æ‰€é›»è©±': clean_ai_value(ai_result.get('phone_number')),
                            'æ¶ˆé˜²è¨­å‚™ç¨®é¡': process_equipment_list(ai_result.get('equipment_list', []))
                        }
                        
                        # --- å¼·åˆ¶ç²å–ç›®éŒ„é ç¢¼ (TOC Page Number) ---
                        ocr_info_for_toc = extract_info_from_ocr(page_one_text, pages_text)
                        if 'toc_page_num' in ocr_info_for_toc:
                            extracted_data['toc_page_num'] = ocr_info_for_toc['toc_page_num']
                        
                        # --- Fallback æ©Ÿåˆ¶ ---
                        # å¦‚æœ AI æœªèƒ½è­˜åˆ¥å ´æ‰€åç¨±æˆ–æ¶ˆé˜²è¨­å‚™ç¨®é¡ï¼Œä½¿ç”¨ OCR è¦å‰‡æå–è£œæ•‘
                        needs_fallback = (
                            not extracted_data.get('å ´æ‰€åç¨±') or 
                            not extracted_data.get('æ¶ˆé˜²è¨­å‚™ç¨®é¡')
                        )
                        
                        if needs_fallback:
                            if not extracted_data.get('å ´æ‰€åç¨±'):
                                st.warning("âš ï¸ AI æœªèƒ½è­˜åˆ¥å ´æ‰€åç¨±ï¼Œå˜—è©¦ä½¿ç”¨è¦å‰‡æå–è£œæ•‘...")
                            if not extracted_data.get('æ¶ˆé˜²è¨­å‚™ç¨®é¡'):
                                st.warning("âš ï¸ AI æœªèƒ½è­˜åˆ¥æ¶ˆé˜²è¨­å‚™ç¨®é¡ï¼Œå˜—è©¦ä½¿ç”¨ OCR è¦å‰‡æå–è£œæ•‘...")
                            
                            fallback_data = extract_info_from_ocr(page_one_text, pages_text)
                            for key, val in fallback_data.items():
                                if not extracted_data.get(key):
                                    extracted_data[key] = val
                        
                        with st.expander("ğŸ¤– æŸ¥çœ‹ AI å®Œæ•´åˆ†æçµæœ (JSON)", expanded=False):
                            st.json(ai_result)
                else:
                    st.warning("âš ï¸ åµæ¸¬ä¸åˆ° Ollama æœå‹™ï¼Œå·²è‡ªå‹•åˆ‡æ›å›å‚³çµ± OCR è¦å‰‡æ¨¡å¼")
                    extracted_data = extract_info_from_ocr(page_one_text, pages_text)
                    # æ‡‰ç”¨ç°¡ç¹è½‰æ›
                    extracted_data = utils.convert_to_traditional(extracted_data)
            else:
                # å‚³çµ± OCR è¦å‰‡æ¨¡å¼
                extracted_data = extract_info_from_ocr(page_one_text, pages_text)
                # æ‡‰ç”¨ç°¡ç¹è½‰æ›
                extracted_data = utils.convert_to_traditional(extracted_data)
                
            ocr_place_name = extracted_data.get('å ´æ‰€åç¨±', '')

            # é¡¯ç¤ºåœ–ç‰‡èˆ‡ OCR çµæœ (é€™æ˜¯ Rerun å¾Œæˆ– Cache Hit æœƒçœ‹åˆ°çš„)
            for i, img in enumerate(cached_images):
                st.image(img, caption=f"ç¬¬ {i+1} é ", use_column_width=True)
                with st.expander(f"ç¬¬ {i+1} é  OCR æ–‡å­—å…§å®¹ (é™¤éŒ¯ç”¨)", expanded=False):

                    # é¡¯ç¤ºæ¯ä¸€é çš„å‰30å€‹å­—å’Œå®Œæ•´å…§å®¹

                    if i < len(pages_text):

                        page_text = pages_text[i]

                        preview_text = page_text[:30] if len(page_text) > 30 else page_text

                        st.text(f"å‰30å­—: {preview_text}")

                        st.text(f"\nå®Œæ•´å…§å®¹:\n{page_text}")

                    else:

                        st.text("(ç„¡æ³•å–å¾—æ­¤é å…§å®¹)")

                    
                    if "Error" in all_ocr_text:
                            st.error("OCR åŸ·è¡Œå¤±æ•—ï¼Œè«‹æª¢æŸ¥å´é‚Šæ¬„çš„ Tesseract è¨­å®šã€‚")
    else:
        st.info("ğŸ‘ˆ è«‹åœ¨ä¸Šæ–¹é¸æ“‡æ¡ˆä»¶ä»¥é–‹å§‹æ¯”å°ã€‚")

# é‚è¼¯ï¼šæ±ºå®šä½¿ç”¨å“ªä¸€ç­†ç³»çµ±è³‡æ–™ (target_row)
# å„ªå…ˆé †åºï¼š
# 1. è‡ªå‹•æ¯”å°ï¼šè‹¥ OCR æœ‰æŠ“åˆ°å ´æ‰€åç¨±ï¼Œä¸”åœ¨ç³»çµ±è³‡æ–™ä¸­æ‰¾å¾—åˆ° (å®Œå…¨ç¬¦åˆæˆ–åŒ…å«)
# 2. æ‰‹å‹•é¸æ“‡ï¼šä½¿ç”¨å´é‚Šæ¬„é¸å–çš„ selected_place

auto_matched_place = None
if df_system is not None and ocr_place_name:
    # === æ”¹é€²ï¼šå…ˆæ¸…ç† OCR å ´æ‰€åç¨±ä¸­çš„ç©ºæ ¼ ===
    clean_ocr_place = ocr_place_name.replace(" ", "").replace("ã€€", "").replace("å°", "è‡º")
    
    print(f"ğŸ” DEBUG: Attempting auto-match. OCR place name: [{ocr_place_name}] -> cleaned: [{clean_ocr_place}]")
    print(f"ğŸ” DEBUG: df_system has {len(df_system)} rows")
    
    # 1. å˜—è©¦å®Œå…¨ç¬¦åˆï¼ˆå…ˆä½¿ç”¨æ¸…ç†å¾Œçš„åç¨±ï¼‰
    # ç‚ºç³»çµ±è³‡æ–™å»ºç«‹æ¸…ç†å¾Œçš„æ¯”å°æ¬„ä½
    df_system['_clean_name'] = df_system['å ´æ‰€åç¨±'].astype(str).str.replace(" ", "").str.replace("ã€€", "").str.replace("å°", "è‡º")
    
    match = df_system[df_system['_clean_name'] == clean_ocr_place]
    if not match.empty:
        auto_matched_place = match.iloc[0]['å ´æ‰€åç¨±']  # ä½¿ç”¨åŸå§‹åç¨±
        target_row = match.iloc[0]
        print(f"âœ… DEBUG: Exact match found! place: [{auto_matched_place}], equipment: [{target_row.get('æ¶ˆé˜²å®‰å…¨è¨­å‚™', 'N/A')}]")
    else:
        # 2. æ¨¡ç³Š/åŒ…å«æœå°‹
        for idx, row in df_system.iterrows():
            sys_name = str(row['å ´æ‰€åç¨±'])
            clean_sys = row['_clean_name']
            
            if clean_ocr_place and (clean_ocr_place in clean_sys or clean_sys in clean_ocr_place):
                auto_matched_place = sys_name
                target_row = row
                print(f"âœ… DEBUG: Fuzzy match found! place: [{auto_matched_place}], equipment: [{target_row.get('æ¶ˆé˜²å®‰å…¨è¨­å‚™', 'N/A')}]")
                break
    
    # æ¸…ç†è‡¨æ™‚æ¬„ä½
    if '_clean_name' in df_system.columns:
        df_system.drop('_clean_name', axis=1, inplace=True)

# å¦‚æœæ²’æœ‰è‡ªå‹•æ¯”å°åˆ°ï¼Œå‰‡ä½¿ç”¨æ‰‹å‹•é¸æ“‡çš„
if target_row is None and selected_place and df_system is not None:
    match = df_system[df_system['å ´æ‰€åç¨±'] == selected_place]
    if not match.empty:
        target_row = match.iloc[0]

# å³ä½¿è‡ªå‹•æ¯”å°æˆåŠŸ,è‹¥æ‰‹å‹•é¸æ“‡äº†ä¸åŒå ´æ‰€,å„ªå…ˆä½¿ç”¨æ‰‹å‹•é¸æ“‡
if selected_place and df_system is not None and auto_matched_place != selected_place:
    match = df_system[df_system['å ´æ‰€åç¨±'] == selected_place]
    if not match.empty:
        target_row = match.iloc[0]

# å³æ¬„ï¼šç³»çµ±åˆ—ç®¡è³‡æ–™
with col2:
    # --- å¯©æ ¸å€å¡Š (ç½®é ‚) ---
    st.markdown("### ğŸ‘® æ¡ˆä»¶å¯©æ ¸")
    
    # ç”³è«‹äººä¿¡ç®±
    default_email = target_case['applicant_email'] if target_case else ""
    applicant_email = st.text_input("ç”³è«‹äººä¿¡ç®±", value=default_email, placeholder="example@email.com")
    
    # å¯©æ ¸çµæœé€šçŸ¥
    st.write("å¯©æ ¸çµæœé€šçŸ¥ï¼š")
    
    # è‡ªè¨‚è¨Šæ¯è¼¸å…¥æ¡†
    custom_message = st.text_area(
        "çµ¦ç”³è«‹äººçš„è¨Šæ¯",
        placeholder="è«‹åœ¨æ­¤è¼¸å…¥è¦é™„åŠ çµ¦ç”³è«‹äººçš„è¨Šæ¯ï¼ˆé¸å¡«ï¼‰...",
        height=100,
        help="æ­¤è¨Šæ¯å°‡æœƒé™„åŠ åœ¨é€šçŸ¥éƒµä»¶ä¸­ç™¼é€çµ¦ç”³è«‹äºº"
    )
    
    # å–å¾— Email è¨­å®š
    sender_email = st.secrets["email"].get("sender_email", "") if "email" in st.secrets else ""
    sender_password = st.secrets["email"].get("sender_password", "") if "email" in st.secrets else ""
    
    # å®šç¾©ç™¼é€é‚è¼¯
    def handle_review(status, subject_prefix, msg_template, custom_msg=""):
        if not applicant_email:
            st.warning("è«‹å…ˆè¼¸å…¥ç”³è«‹äººä¿¡ç®±")
            return
        
        # é¡¯ç¤º UI è¨Šæ¯ (æ¨¡æ“¬)
        if status == "success":
            st.success(f"å·²ç”¢ç”Ÿã€{subject_prefix}ã€‘é€šçŸ¥")
            color_theme = "#38a169" # Green
        elif status == "warning":
            st.warning(f"å·²ç”¢ç”Ÿã€{subject_prefix}ã€‘é€šçŸ¥")
            color_theme = "#d97706" # Yellow/Orange
        else:
            st.error(f"å·²ç”¢ç”Ÿã€{subject_prefix}ã€‘é€šçŸ¥")
            color_theme = "#e53e3e" # Red
            
        # å˜—è©¦ç™¼é€çœŸå¯¦éƒµä»¶
        if sender_email and sender_password:
            with st.spinner("ğŸ“§ æ­£åœ¨ç™¼é€éƒµä»¶..."):
                subject = f"ã€æ¶ˆé˜²å±€é€šçŸ¥ã€‘æ¡ˆä»¶å¯©æ ¸çµæœï¼š{subject_prefix}"
                
                # çµ„åˆè‡ªè¨‚è¨Šæ¯
                custom_msg_html = ""
                if custom_msg and custom_msg.strip():
                    # å°‡æ›è¡Œè½‰ç‚º HTML æ›è¡Œ
                    formatted_msg = custom_msg.strip().replace("\n", "<br>")
                    custom_msg_html = f"""
                    <div style="background-color: #f5f5f5; border-left: 4px solid #4a90d9; padding: 15px; margin: 15px 0;">
                        <p style="margin: 0; font-weight: bold; color: #333;">ğŸ“ æ‰¿è¾¦äººå‚™è¨»ï¼š</p>
                        <p style="margin: 10px 0 0 0; color: #555;">{formatted_msg}</p>
                    </div>
                    """
                
                # ä½¿ç”¨ HTML æ¨¡æ¿ç”Ÿæˆå…§å®¹
                content_html = f"""
                <p>æ‚¨çš„æ¶ˆé˜²å®‰å…¨è¨­å‚™æª¢ä¿®ç”³å ±æ¡ˆä»¶å¯©æ ¸çµæœç‚ºï¼š<strong>{subject_prefix}</strong>ã€‚</p>
                <p>{msg_template}</p>
                {custom_msg_html}
                <p>è‹¥æœ‰ä»»ä½•ç–‘å•ï¼Œè«‹è¯ç¹«æœ¬å±€é é˜²èª¿æŸ¥ç§‘ã€‚</p>
                """
                
                # å‘¼å« utils.generate_email_html ç”Ÿæˆå®Œæ•´ HTML
                case_dict = dict(target_case) if target_case else {}
                recipient_name = case_dict.get('applicant_name', 'ç”³è«‹äºº')
                
                full_html_body = utils.generate_email_html(
                    title=subject,
                    recipient_name=recipient_name,
                    content_html=content_html,
                    color_theme=color_theme
                )
                
                success, msg = utils.send_email(sender_email, sender_password, applicant_email, subject, full_html_body)
                
                if success:
                    st.toast(f"âœ… éƒµä»¶å·²æˆåŠŸç™¼é€è‡³ {applicant_email}")
                else:
                    st.error(msg)
        else:
            st.info("ğŸ’¡ æç¤ºï¼šè‹¥éœ€ç™¼é€çœŸå¯¦éƒµä»¶ï¼Œè«‹è‡³å´é‚Šæ¬„è¨­å®šå¯„ä»¶è€…è³‡è¨Šã€‚")

    # æŒ‰éˆ•å€ (ç§»å‡ºå·¢ç‹€ columns)
    b1, b2, b3 = st.columns(3)
    
    with b1:
        if st.button("âœ… åˆæ ¼", use_container_width=True):
            if target_case:
                db_manager.update_case_status(target_case['id'], "å¯é ˜ä»¶")
                st.cache_data.clear()
                handle_review("success", "åˆæ ¼", "æ­å–œæ‚¨ï¼Œæ¡ˆä»¶å·²å¯©æ ¸é€šéã€‚", custom_message)
                st.rerun()
    
    with b2:
        if st.button("âš ï¸ è£œä»¶", use_container_width=True):
            if target_case:
                db_manager.update_case_status(target_case['id'], "å¾…è£œä»¶")
                st.cache_data.clear()
                handle_review("warning", "è£œä»¶", "è«‹å„˜é€Ÿè£œé½Šç›¸é—œæ–‡ä»¶ã€‚", custom_message)
                st.rerun()

    with b3:
        if st.button("ğŸš« é€€ä»¶", use_container_width=True):
            if target_case:
                db_manager.update_case_status(target_case['id'], "å·²é€€ä»¶")
                st.cache_data.clear()
                handle_review("error", "é€€ä»¶", "æ¡ˆä»¶å·²è¢«é€€å›ï¼Œè«‹ä¿®æ­£å¾Œé‡æ–°ç”³å ±ã€‚", custom_message)
                st.rerun()
    
    st.divider()
    
    st.subheader("ğŸ’» ç³»çµ±åˆ—ç®¡è³‡æ–™ vs ç”³å ±è³‡æ–™")
    
    if target_row is not None:
        # é¡¯ç¤ºç›®å‰ä½¿ç”¨çš„å ´æ‰€è³‡æ–™ä¾†æº
        if auto_matched_place:
            st.success(f"ğŸ¤– å·²è‡ªå‹•å°æ‡‰ç³»çµ±å ´æ‰€ï¼š{auto_matched_place}")
        elif selected_place:
            st.info(f"ğŸ‘¤ ç›®å‰æ‰‹å‹•é¸æ“‡å ´æ‰€ï¼š{selected_place}")
            if ocr_place_name:
                st.warning(f"âš ï¸ ç³»çµ±ç„¡æ³•è‡ªå‹•å°æ‡‰ OCR å ´æ‰€ã€Œ{ocr_place_name}ã€ï¼Œè«‹ç¢ºèªæ‰‹å‹•é¸æ“‡æ˜¯å¦æ­£ç¢ºã€‚")
        
        if target_case and uploaded_file_path:
            # é¡¯ç¤ºé–å®šè³‡è¨Š
            if page_one_text:
                st.caption("â„¹ï¸ å·²é–å®šä½¿ç”¨ç¬¬ 1 é å…§å®¹é€²è¡Œè‡ªå‹•å¡«å…¥ (åŸºæœ¬è³‡æ–™)")
            
            toc_page_num = extracted_data.get('toc_page_num', 2)
            st.caption(f"â„¹ï¸ å·²é–å®šä½¿ç”¨ç¬¬ {toc_page_num} é å…§å®¹é€²è¡Œè‡ªå‹•å¡«å…¥ (æ¶ˆé˜²è¨­å‚™ç¨®é¡)")
        else:
            st.caption("â„¹ï¸ ç­‰å¾…ä¸Šå‚³ç”³å ±æª”æ¡ˆä»¥é€²è¡Œè‡ªå‹•å¡«å…¥...")
        
        # å®šç¾©æ¬„ä½å°æ‡‰
        field_mapping = {
            'å ´æ‰€åç¨±': 'å ´æ‰€åç¨±',
            'å ´æ‰€åœ°å€': 'å ´æ‰€åœ°å€',
            'ç®¡ç†æ¬Šäºº': 'ç®¡ç†æ¬Šäººå§“å',
            'é›»è©±': 'å ´æ‰€é›»è©±',
            'æ¶ˆé˜²è¨­å‚™ç¨®é¡': 'æ¶ˆé˜²å®‰å…¨è¨­å‚™'
        }

        # æª¢æŸ¥å ´æ‰€åç¨±æ˜¯å¦ä¸€è‡´ (å¦‚æœæ˜¯æ‰‹å‹•é¸æ“‡æ‰éœ€è¦è­¦å‘Šï¼Œè‡ªå‹•å°æ‡‰é€šå¸¸å°±æ˜¯ä¸€è‡´çš„)
        # åªè¦æœ‰é¸æ“‡å ´æ‰€ä¸”æœ‰å°æ‡‰çš„ç³»çµ±è³‡æ–™,å°±é¡¯ç¤ºç³»çµ±è³‡æ–™
        # ä¸éœ€è¦ç­‰åˆ°ä¸Šå‚³æª”æ¡ˆæˆ–é¸æ“‡æ¡ˆä»¶
        show_system_data = target_row is not None
        
        # å¦‚æœ OCR å ´æ‰€åç¨±èˆ‡æ‰‹å‹•é¸æ“‡çš„å ´æ‰€ä¸ç¬¦,é¡¯ç¤ºè­¦å‘Šä½†ä»é¡¯ç¤ºè³‡æ–™
        if show_system_data and not auto_matched_place and ocr_place_name and selected_place:
            clean_ocr = ocr_place_name.replace("å°", "è‡º").replace(" ", "")
            clean_sys = selected_place.replace("å°", "è‡º").replace(" ", "")
            
            if clean_sys not in clean_ocr and clean_ocr not in clean_sys:
                 st.warning(f"âš ï¸ æ³¨æ„ï¼šOCR è¾¨è­˜åˆ°çš„å ´æ‰€åç¨±ã€Œ{ocr_place_name}ã€èˆ‡æ‚¨é¸æ“‡çš„ç³»çµ±å ´æ‰€ã€Œ{selected_place}ã€ä¸ç¬¦,è«‹ç¢ºèªæ˜¯å¦æ­£ç¢ºã€‚")

        # å»ºç«‹æ¯”å°è¡¨æ ¼è³‡æ–™
        comparison_data = []
        
        # ç¨ç«‹å„²å­˜æ¶ˆé˜²è¨­å‚™è³‡æ–™
        equip_sys_val = ""
        equip_ocr_val = ""
        
        for display_name, excel_col in field_mapping.items():
            # ç³»çµ±è³‡æ–™
            sys_val = ""
            if show_system_data:
                sys_val = target_row.get(excel_col, "ç„¡è³‡æ–™")
                if pd.isna(sys_val): sys_val = ""
            
            # ç”³å ±è³‡æ–™
            ocr_key = display_name
            if display_name == 'é›»è©±':
                ocr_key = 'å ´æ‰€é›»è©±'
            
            ocr_val = extracted_data.get(ocr_key, "")
            
            # ç‰¹æ®Šè™•ç†ï¼šæ¶ˆé˜²è¨­å‚™ç¨®é¡ (ç¨ç«‹è™•ç†ï¼Œä¸åŠ å…¥è¡¨æ ¼)
            if display_name == 'æ¶ˆé˜²è¨­å‚™ç¨®é¡':
                if isinstance(sys_val, str) and show_system_data:
                    equip_sys_val = normalize_equipment_str(sys_val)
                else:
                    equip_sys_val = sys_val # å¯èƒ½æ˜¯ç©ºå­—ä¸²
                
                equip_ocr_val = ocr_val
                continue # è·³éåŠ å…¥è¡¨æ ¼
            
            comparison_data.append({
                "æ¬„ä½": display_name,
                "ç³»çµ±è³‡æ–™": sys_val,
                "ç”³å ±è³‡æ–™ (OCR/äººå·¥)": ocr_val
            })
            
        # è½‰ç‚º DataFrame
        if comparison_data:
            df_comp = pd.DataFrame(comparison_data)
            st.dataframe(
                df_comp,
                column_config={
                    "æ¬„ä½": st.column_config.TextColumn("æ¯”å°é …ç›®", width="medium"),
                    "ç³»çµ±è³‡æ–™": st.column_config.TextColumn("ç³»çµ±åˆ—ç®¡è³‡æ–™", width="medium"),
                    "ç”³å ±è³‡æ–™ (OCR/äººå·¥)": st.column_config.TextColumn("ç”³å ±æ›¸è³‡æ–™ (AI/OCR)", width="medium"),
                },
                use_container_width=True,
                hide_index=True
            )
        else:
            st.info("å°šç„¡æ¯”å°è³‡æ–™")
        
        # --- æ¶ˆé˜²è¨­å‚™å°ˆå±¬æ¯”å°å€ ---
        st.write("---")
        with st.expander("ğŸ”¥ æ¶ˆé˜²è¨­å‚™è©³ç´°æ¯”å°èˆ‡ç·¨è¼¯", expanded=True):
            # è¦–è¦ºåŒ–æ¯”å°å€å¡Š (Diff View)
            st.subheader("ğŸ“Š è¦–è¦ºåŒ–æ¯”å°")
            
            # è½‰æ›ç‚ºé›†åˆä»¥é€²è¡Œæ¯”å°
            sys_set = set(equip_sys_val.split("ã€")) if equip_sys_val else set()
            ocr_set = set(equip_ocr_val.split("ã€")) if equip_ocr_val else set()
            
            # å»é™¤ç©ºå­—ä¸²
            sys_set.discard("")
            ocr_set.discard("")
            
            # æ¸²æŸ“å·®ç•°è¦–è¦ºåŒ–
            if sys_set or ocr_set:
                diff_html = utils.render_equipment_diff(sys_set, ocr_set)
                st.markdown(diff_html, unsafe_allow_html=True)
            else:
                st.info("ç„¡è¨­å‚™è³‡æ–™")
            
            st.divider()
            st.subheader("âœï¸ ç·¨è¼¯è¨­å‚™æ¸…å–®")
            
            col_equip1, col_equip2 = st.columns(2)
            
            # æ ¼å¼åŒ–é¡¯ç¤º (å°‡é “è™Ÿè½‰ç‚ºæ›è¡Œ)
            fmt_sys_val = equip_sys_val.replace("ã€", "\n") if equip_sys_val else ""
            
            # --- Session State åŒæ­¥é‚è¼¯ (ä¿®æ­£ç”³å ±è³‡æ–™æœªè¼‰å…¥å•é¡Œ) ---
            # åˆå§‹åŒ– last_equip_ocr_val
            if "last_equip_ocr_val" not in st.session_state:
                st.session_state.last_equip_ocr_val = equip_ocr_val
                st.session_state.modified_equip_ocr = equip_ocr_val
            
            # å¦‚æœæª¢æ¸¬åˆ° equip_ocr_val æ”¹è®Šäº† (ä¾‹å¦‚ AI é‡æ–°åˆ†æå®Œæˆ)ï¼Œå¼·åˆ¶æ›´æ–° modified_equip_ocr
            if equip_ocr_val != st.session_state.last_equip_ocr_val:
                st.session_state.modified_equip_ocr = equip_ocr_val
                st.session_state.last_equip_ocr_val = equip_ocr_val
            
            # ç¢ºä¿ modified_equip_ocr å­˜åœ¨
            if "modified_equip_ocr" not in st.session_state:
                st.session_state.modified_equip_ocr = equip_ocr_val
            
            # æ ¼å¼åŒ– OCR å€¼ (é¡¯ç¤ºç”¨)
            fmt_ocr_val = st.session_state.modified_equip_ocr.replace("ã€", "\n") if st.session_state.modified_equip_ocr else ""

            with col_equip1:
                st.text_area("ç³»çµ±åˆ—ç®¡è¨­å‚™ (å”¯è®€)", value=fmt_sys_val, height=200, disabled=True)
            
            with col_equip2:
                new_equip_str = st.text_area("ç”³å ±è¨­å‚™ (å¯ç·¨è¼¯)", value=fmt_ocr_val, height=200, help="è‹¥è¾¨è­˜æœ‰èª¤ï¼Œè«‹åœ¨æ­¤ä¿®æ­£ (æ¯è¡Œä¸€é …)")
                
                # è™•ç†ä¿®æ”¹
                if new_equip_str != fmt_ocr_val:
                    # å°‡æ›è¡Œè½‰å›é “è™Ÿå„²å­˜
                    updated_val = new_equip_str.replace("\n", "ã€")
                    st.session_state.modified_equip_ocr = updated_val
                    equip_ocr_val = updated_val
                    st.rerun()
                else:
                    # ä½¿ç”¨ Session State çš„å€¼ (è½‰å›é “è™Ÿæ ¼å¼) ä½œç‚ºæ¯”å°ç”¨
                    equip_ocr_val = st.session_state.modified_equip_ocr

        # æª¢æ ¸æ¸…å–®
        st.write("### âœ… å·®ç•°æª¢æ ¸")
        
        # è‡ªå‹•åˆ¤æ–·å·®ç•° (è¡¨æ ¼éƒ¨åˆ†)
        if comparison_data:
            for item in comparison_data:
                field = item['æ¬„ä½']
                sys_val = str(item['ç³»çµ±è³‡æ–™']).strip()
                ocr_val = str(item['ç”³å ±è³‡æ–™ (OCR/äººå·¥)']).strip()
                
                # åœ°å€æ¨¡ç³Šæ¯”å°é‚è¼¯
                if field == 'å ´æ‰€åœ°å€':
                    # å®šç¾©æ­£è¦åŒ–å‡½å¼
                    def normalize_addr(addr):
                        if not addr: return ""
                        # 1. çµ±ä¸€ å°/è‡º
                        addr = addr.replace("å°", "è‡º")
                        # 2. å»é™¤é–‹é ­çš„ "è‡ºæ±ç¸£" (æˆ– "å°æ±ç¸£")
                        addr = addr.replace("è‡ºæ±ç¸£", "")
                        # 3. å»é™¤ç©ºç™½
                        addr = addr.replace(" ", "")
                        return addr
                    
                    norm_sys = normalize_addr(sys_val)
                    norm_ocr = normalize_addr(ocr_val)
                    
                    # åš´æ ¼åˆ¤æ–·é‚è¼¯
                    if not sys_val and ocr_val:
                        st.error(f"âŒ ã€{field}ã€‘ä¸ä¸€è‡´ (ç³»çµ±ç„¡è³‡æ–™)")
                    elif not sys_val and not ocr_val:
                        st.success(f"âœ… ã€{field}ã€‘ä¸€è‡´ (çš†ç„¡è³‡æ–™)")
                    elif sys_val and not ocr_val:
                        st.warning(f"âš ï¸ ã€{field}ã€‘ç”³å ±è³‡æ–™ç©ºç™½ (ç³»çµ±: {sys_val})")
                    else:
                        # å…©è€…çš†æœ‰å€¼ï¼Œé€²è¡Œæ¯”å°
                        if norm_sys == norm_ocr:
                            st.success(f"âœ… ã€{field}ã€‘ä¸€è‡´")
                        elif norm_ocr in norm_sys or norm_sys in norm_ocr:
                            st.success(f"âœ… ã€{field}ã€‘ä¸€è‡´ (æ¨¡ç³Šæ¯”å°æˆåŠŸ)")
                        else:
                            st.error(f"âŒ ã€{field}ã€‘ä¸ä¸€è‡´ï¼\nç³»çµ±ï¼š{sys_val}\nç”³å ±ï¼š{ocr_val}")
                
                # å…¶ä»–æ¬„ä½çš„ä¸€èˆ¬æ¯”å°
                else:
                    # åš´æ ¼åˆ¤æ–·é‚è¼¯
                    if not sys_val and ocr_val:
                        st.error(f"âŒ ã€{field}ã€‘ä¸ä¸€è‡´ (ç³»çµ±ç„¡è³‡æ–™)")
                    elif not sys_val and not ocr_val:
                        st.success(f"âœ… ã€{field}ã€‘ä¸€è‡´ (çš†ç„¡è³‡æ–™)")
                    elif sys_val and not ocr_val:
                        st.warning(f"âš ï¸ ã€{field}ã€‘ç”³å ±è³‡æ–™ç©ºç™½ (ç³»çµ±: {sys_val})")
                    else:
                        # å…©è€…çš†æœ‰å€¼
                        if sys_val == ocr_val:
                            st.success(f"âœ… ã€{field}ã€‘ä¸€è‡´")
                        elif ocr_val in sys_val or sys_val in ocr_val:
                             st.success(f"âœ… ã€{field}ã€‘ä¸€è‡´ (éƒ¨åˆ†ç¬¦åˆ)")
                        else:
                             st.error(f"âŒ ã€{field}ã€‘ä¸ä¸€è‡´ï¼\nç³»çµ±ï¼š{sys_val}\nç”³å ±ï¼š{ocr_val}")

        # --- æ¶ˆé˜²è¨­å‚™æ¯”å°é‚è¼¯ (ç¨ç«‹) ---
        field = 'æ¶ˆé˜²è¨­å‚™ç¨®é¡'
        sys_val = equip_sys_val
        ocr_val = equip_ocr_val
        
        # åš´æ ¼åˆ¤æ–·é‚è¼¯
        if not sys_val and ocr_val:
            st.error(f"âŒ ã€{field}ã€‘ä¸ä¸€è‡´ (ç³»çµ±ç„¡è³‡æ–™)")
            # ä¾ç„¶é¡¯ç¤ºå·®ç•°è©³æƒ…
            ocr_set = set(ocr_val.split("ã€")) if ocr_val else set()
            ocr_set.discard("")
            col1, col2 = st.columns(2)
            with col1:
                 st.markdown("**âŒ ç³»çµ±ç„¡è³‡æ–™**")
            with col2:
                 st.markdown(f"**â“ ç”³å ±è³‡æ–™ï¼š**")
                 for item in ocr_set:
                     st.markdown(f"- <span style='color:orange'>{item}</span>", unsafe_allow_html=True)
                     
        elif not sys_val and not ocr_val:
            st.success(f"âœ… ã€{field}ã€‘ä¸€è‡´ (çš†ç„¡è³‡æ–™)")
        elif sys_val and not ocr_val:
            st.warning(f"âš ï¸ ã€{field}ã€‘ç”³å ±è³‡æ–™ç©ºç™½ (ç³»çµ±: {sys_val})")
        else:
            # å…©è€…çš†æœ‰å€¼
            if sys_val != ocr_val:
                # è½‰ç‚ºé›†åˆé€²è¡Œæ¯”å°
                sys_set = set(sys_val.split("ã€")) if sys_val else set()
                ocr_set = set(ocr_val.split("ã€")) if ocr_val else set()
                
                # å»é™¤ç©ºå­—ä¸²
                sys_set.discard("")
                ocr_set.discard("")
                
                # è¨ˆç®—å·®ç•°
                missing_in_ocr = sys_set - ocr_set # ç³»çµ±æœ‰ï¼Œç”³å ±ç„¡ (æ¼å ±?)
                extra_in_ocr = ocr_set - sys_set   # ç”³å ±æœ‰ï¼Œç³»çµ±ç„¡ (æ–°å¢?)
                
                if not missing_in_ocr and not extra_in_ocr:
                    st.success(f"âœ… ã€{field}ã€‘ä¸€è‡´")
                else:
                    st.error(f"âš ï¸ ã€{field}ã€‘ä¸ä¸€è‡´ï¼")
                    
                    # ä½¿ç”¨ Columns é¡¯ç¤ºå·®ç•°ï¼Œæ¯”è¼ƒæ¸…æ¥š
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        if missing_in_ocr:
                            st.markdown(f"**âŒ ç³»çµ±æœ‰ï¼Œä½†ç”³å ±è³‡æ–™æœªåˆ—å‡ºï¼š**")
                            for item in missing_in_ocr:
                                st.markdown(f"- <span style='color:red'>{item}</span>", unsafe_allow_html=True)
                        else:
                            st.markdown("**âœ… ç³»çµ±é …ç›®çš†å·²ç”³å ±**")
                            
                    with col2:
                        if extra_in_ocr:
                            st.markdown(f"**â“ ç”³å ±è³‡æ–™å¤šå‡ºçš„é …ç›®ï¼š**")
                            for item in extra_in_ocr:
                                st.markdown(f"- <span style='color:orange'>{item}</span>", unsafe_allow_html=True)
                        else:
                            st.markdown("**âœ… ç„¡é¡å¤–ç”³å ±é …ç›®**")
            else:
                st.success(f"âœ… ã€{field}ã€‘ä¸€è‡´")

        # --- æ–°å¢ï¼šæª¢æŸ¥é …ç›® (æ¶ˆé˜²è¨­å‚™) ---
        st.write("---")
        st.subheader("âœ… æª¢æŸ¥é …ç›® (æ¶ˆé˜²å®‰å…¨è¨­å‚™)")
        
        # å®šç¾©è¨­å‚™æ¸…å–®
        equipment_categories = {
            "æ»…ç«è¨­å‚™": [
                "æ»…ç«å™¨", "å®¤å…§æ¶ˆé˜²æ “è¨­å‚™", "å®¤å¤–æ¶ˆé˜²æ “è¨­å‚™", "è‡ªå‹•æ’’æ°´è¨­å‚™", 
                "æ°´éœ§æ»…ç«è¨­å‚™", "æ³¡æ²«æ»…ç«è¨­å‚™", "æƒ°æ€§æ°£é«”æ»…ç«è¨­å‚™", "ä¹¾ç²‰æ»…ç«è¨­å‚™", 
                "æµ·é¾æ»…ç«è¨­å‚™", "ç°¡æ˜“è‡ªå‹•æ»…ç«è¨­å‚™", "é¹µåŒ–çƒ´æ»…ç«è¨­å‚™"
            ],
            "è­¦å ±è¨­å‚™": [
                "ç«è­¦è‡ªå‹•è­¦å ±è¨­å‚™", "ç“¦æ–¯æ¼æ°£ç«è­¦è‡ªå‹•è­¦å ±è¨­å‚™", "ç·Šæ€¥å»£æ’­è¨­å‚™", 
                "ä¸€ä¸€ä¹ç«ç½é€šå ±è£ç½®"
            ],
            "é¿é›£é€ƒç”Ÿè¨­å‚™": [
                "æ¨™ç¤ºè¨­å‚™", "é¿é›£å™¨å…·", "ç·Šæ€¥ç…§æ˜è¨­å‚™"
            ],
            "æ¶ˆé˜²æ¶æ•‘ä¸Šä¹‹å¿…è¦è¨­å‚™": [
                "é€£çµé€æ°´ç®¡", "æ¶ˆé˜²å°ˆç”¨è“„æ°´æ± ", "æ’ç…™è¨­å‚™", "ç„¡ç·šé›»é€šä¿¡è¼”åŠ©è¨­å‚™", 
                "ç·Šæ€¥é›»æºæ’åº§", "é˜²ç½ç›£æ§ç³»çµ±ç¶œåˆæ“ä½œè£ç½®"
            ],
            "å…¶ä»–": [
                "å†·å»æ’’æ°´è¨­å‚™", "å°„æ°´è¨­å‚™", "é…ç·š"
            ]
        }
        
        # === æ”¹é€²ï¼šä½¿ç”¨ OCR è­˜åˆ¥çš„è¨­å‚™ + ç³»çµ±è³‡æ–™é›™é‡åˆ¤æ–· ===
        # å°‡ OCR è¨­å‚™å­—ä¸²è½‰ç‚ºé›†åˆ
        ocr_equip_str = equip_ocr_val if 'equip_ocr_val' in dir() and equip_ocr_val else ""
        ocr_equip_set = set(ocr_equip_str.split("ã€")) if ocr_equip_str else set()
        ocr_equip_set.discard("")
        
        # ç³»çµ±è³‡æ–™å­—ä¸²
        system_row_str = target_row.to_string() if target_row is not None else ""
        
        # ç”¨ä¾†æ”¶é›†å·²å‹¾é¸çš„è¨­å‚™ (ç”¨æ–¼åŒæ­¥åˆ°ç·¨è¼¯æ¸…å–®)
        checkbox_detected_items = []
        
        # é¡¯ç¤º Checkbox
        for category, items in equipment_categories.items():
            st.write(f"**{category}**")
            cols = st.columns(3) # åˆ†ä¸‰æ¬„é¡¯ç¤ºæ¯”è¼ƒæ•´é½Š
            for i, item in enumerate(items):
                # åˆ¤æ–·æ˜¯å¦è¦æ‰“å‹¾ï¼š
                # 1. OCR è­˜åˆ¥çš„è¨­å‚™ä¸­æœ‰è©²é …ç›®
                # 2. æˆ–ç³»çµ±è³‡æ–™ä¸­æœ‰è©²é …ç›® (ä½œç‚ºå‚™æ¡ˆ)
                is_in_ocr = any(item in eq or eq in item for eq in ocr_equip_set if eq)
                is_in_system = item in system_row_str
                is_checked = is_in_ocr or is_in_system
                
                # æ”¶é›†å·²å‹¾é¸çš„è¨­å‚™
                if is_checked:
                    checkbox_detected_items.append(item)
                
                # ä½¿ç”¨ columns æ’ç‰ˆ
                with cols[i % 3]:
                    # å¦‚æœæ˜¯ OCR åµæ¸¬åˆ°çš„ï¼Œé¡¯ç¤ºç¶ è‰²ï¼›å¦‚æœåªåœ¨ç³»çµ±æœ‰å‰‡é¡¯ç¤ºè—è‰²
                    if is_in_ocr:
                        st.checkbox(f"âœ… {item}", value=True, key=f"chk_{item}", disabled=True)
                    elif is_in_system:
                        st.checkbox(f"ğŸ“‹ {item}", value=True, key=f"chk_{item}", disabled=True, help="ç³»çµ±åˆ—ç®¡é …ç›®")
                    else:
                        st.checkbox(item, value=False, key=f"chk_{item}", disabled=True)
        
        # === åŒæ­¥åˆ°ç·¨è¼¯è¨­å‚™æ¸…å–® ===
        # å¦‚æœ OCR æ²’æœ‰åµæ¸¬åˆ°ä»»ä½•è¨­å‚™ï¼Œä½† checkbox å€å¡Šæœ‰åµæ¸¬åˆ°ï¼Œå‰‡åŒæ­¥
        if not equip_ocr_val and checkbox_detected_items:
            # æ›´æ–° session state
            synced_equip = "ã€".join(checkbox_detected_items)
            if st.session_state.get('modified_equip_ocr') != synced_equip:
                st.session_state.modified_equip_ocr = synced_equip
                st.session_state.last_equip_ocr_val = synced_equip
                st.info(f"â„¹ï¸ å·²å¾æª¢æŸ¥é …ç›®åŒæ­¥ {len(checkbox_detected_items)} é …è¨­å‚™åˆ°ç·¨è¼¯æ¸…å–®")
    
    else:
        # å³ä½¿æ²’æœ‰æ¯”å°æˆåŠŸ,ä¹Ÿè¦é¡¯ç¤ºå·²åˆ†æçš„ç”³å ±è³‡æ–™
        if 'extracted_data' in dir() and extracted_data:
            # é¡¯ç¤ºæ›´å…·é«”çš„æç¤ºè¨Šæ¯
            if ocr_place_name and df_system is not None:
                st.warning(f"âš ï¸ ç³»çµ±ç„¡æ³•è‡ªå‹•å°æ‡‰ OCR è¾¨è­˜åˆ°çš„å ´æ‰€ã€Œ{ocr_place_name}ã€åˆ°ç³»çµ±åˆ—ç®¡è³‡æ–™ã€‚")
                st.caption("ğŸ’¡ å¯èƒ½åŸå› ï¼šå ´æ‰€åç¨±ä¸åœ¨ç³»çµ±è³‡æ–™ä¸­ï¼Œæˆ–åç¨±æœ‰äº›å¾®å·®ç•°ã€‚è«‹å˜—è©¦åœ¨å·¦å´æ‰‹å‹•é¸æ“‡æ­£ç¢ºçš„å ´æ‰€åç¨±ã€‚")
                
                # å˜—è©¦æä¾›ç›¸ä¼¼åç¨±å»ºè­°
                if df_system is not None and 'å ´æ‰€åç¨±' in df_system.columns:
                    clean_ocr = ocr_place_name.replace("å°", "è‡º").replace(" ", "")
                    similar_places = []
                    for place in df_system['å ´æ‰€åç¨±'].astype(str).unique():
                        clean_place = place.replace("å°", "è‡º").replace(" ", "")
                        # æª¢æŸ¥æ˜¯å¦æœ‰éƒ¨åˆ†åŒ¹é…
                        if any(char in clean_place for char in clean_ocr if char):
                            similar_places.append(place)
                    
                    if similar_places and len(similar_places) <= 10:
                        with st.expander("ğŸ” å¯èƒ½ç›¸ä¼¼çš„å ´æ‰€åç¨±", expanded=True):
                            for sp in similar_places[:5]:
                                st.write(f"â€¢ {sp}")
            elif df_system is None:
                st.error("âŒ å°šæœªè¼‰å…¥ç³»çµ± Excel è³‡æ–™ï¼Œç„¡æ³•é€²è¡Œæ¯”å°ã€‚")
                st.info("ğŸ‘ˆ è«‹åœ¨å·¦å´ã€Œè¨­å®šèˆ‡è³‡æ–™ä¾†æºã€å€å¡Šè¨­å®š Excel è·¯å¾‘ã€‚")
            else:
                st.info("âš ï¸ å°šæœªé¸æ“‡ç³»çµ±å ´æ‰€é€²è¡Œæ¯”å°,ä½†ä»¥ä¸‹æ˜¯ OCR/AI åˆ†æçµæœï¼š")
            
            # é¡¯ç¤ºåˆ†æçµæœ
            st.markdown("#### ğŸ“„ ç”³å ±è³‡æ–™ (OCR/AI åˆ†æ)")
            
            display_fields = ['å ´æ‰€åç¨±', 'å ´æ‰€åœ°å€', 'ç®¡ç†æ¬Šäºº', 'å ´æ‰€é›»è©±']
            for field in display_fields:
                val = extracted_data.get(field, '')
                if val:
                    st.text_input(f"{field}", value=val, disabled=True, key=f"display_{field}")
            
            # é¡¯ç¤ºæ¶ˆé˜²è¨­å‚™
            equip_val = extracted_data.get('æ¶ˆé˜²è¨­å‚™ç¨®é¡', '')
            if equip_val:
                st.text_area("æ¶ˆé˜²è¨­å‚™ç¨®é¡", value=equip_val.replace("ã€", "\n") if equip_val else "", height=150, disabled=True, key="display_equip")
        else:
            if df_system is None:
                 st.warning("è«‹å…ˆåœ¨å·¦å´è¼‰å…¥ç³»çµ± Excel è³‡æ–™ã€‚")
            elif not selected_place:
                 st.info("ğŸ‘ˆ è«‹å…ˆå¾å·¦å´é¸å–®é¸æ“‡ä¸€å€‹å ´æ‰€ï¼Œä»¥é–‹å§‹é€²è¡Œæ¯”å°ã€‚")
            else:
                 st.info("ğŸ‘ˆ è«‹åœ¨ä¸Šæ–¹é¸æ“‡æ¡ˆä»¶ä»¥é–‹å§‹æ¯”å°ã€‚")

# ==========================================
# Tab 2: æ–‡ä»¶å®Œæ•´æ€§æª¢æŸ¥
# ==========================================
with tab_check:
    st.subheader("ğŸ“‘ æ–‡ä»¶å®Œæ•´æ€§æª¢æŸ¥")
    
    # é¡¯ç¤ºç•¶å‰ä½¿ç”¨çš„åˆ†ææ¨¡å¼
    if use_vision_ai:
        st.caption("ğŸ” ä½¿ç”¨ Vision AI æ¨¡å¼ (ç›´æ¥åˆ†ææƒæåœ–ç‰‡)")
    else:
        st.caption("ğŸ“ ä½¿ç”¨å‚³çµ± OCR æ¨¡å¼ (Tesseract)")
    
    if 'ocr_cache' in st.session_state and 'pages_info' in st.session_state.ocr_cache:
        images = st.session_state.ocr_cache.get('images', [])
        pages_info = st.session_state.ocr_cache.get('pages_info', [])  # åœ¨å…©ç¨®æ¨¡å¼éƒ½éœ€è¦é€™å€‹è®Šæ•¸
        
        # === Vision AI æ¨¡å¼ ===
        if use_vision_ai and images:
            st.info("ğŸ¤– æ­£åœ¨ä½¿ç”¨ Vision AI é€²è¡Œæ–‡ä»¶çµæ§‹åˆ†æ...")
            
            try:
                import ai_engine
                
                # æª¢æŸ¥ Vision AI æ˜¯å¦å¯ç”¨
                if not ai_engine.is_ollama_available():
                    st.error("âŒ Ollama æœå‹™æœªå•Ÿå‹•")
                    st.info("è«‹åŸ·è¡Œ: `ollama serve` æˆ–å•Ÿå‹• Ollama Desktop")
                elif not ai_engine.check_vision_model_available():
                    st.error("âŒ Vision æ¨¡å‹æœªå®‰è£")
                    st.info("è«‹åŸ·è¡Œ: `ollama pull llama3.2-vision`")
                else:
                    # åŸ·è¡Œ Vision AI åˆ†æ (ä½¿ç”¨ cache é¿å…é‡è¤‡åˆ†æ)
                    cache_key = st.session_state.ocr_cache.get('file_key')
                    
                    if 'vision_analysis' not in st.session_state or st.session_state.get('vision_cache_key') != cache_key:
                        with st.spinner("ğŸ” Vision AI æ­£åœ¨åˆ†ææ–‡ä»¶çµæ§‹ (å¯èƒ½éœ€è¦ 1-2 åˆ†é˜)..."):
                            result = ai_engine.analyze_document_structure(images)
                            st.session_state.vision_analysis = result
                            st.session_state.vision_cache_key = cache_key
                    else:
                        result = st.session_state.vision_analysis
                        st.success("âœ… ä½¿ç”¨å¿«å–çš„ Vision AI åˆ†æçµæœ")
                    
                    if result.get('error'):
                        st.error(f"âŒ Vision AI åˆ†æå¤±æ•—: {result['error']}")
                    else:
                        # é¡¯ç¤ºé é¢è­˜åˆ¥çµæœ
                        col_v1, col_v2 = st.columns([1, 1])
                        
                        with col_v1:
                            st.markdown("#### 1. é é¢è­˜åˆ¥çµæœ")
                            page_map_df = pd.DataFrame([
                                {'é ç¢¼': k, 'æ–‡ä»¶é¡å‹': v} 
                                for k, v in result['page_map'].items()
                            ])
                            st.dataframe(page_map_df, use_container_width=True, hide_index=True)
                            
                            if result['toc_page']:
                                st.success(f"âœ… å·²è­˜åˆ¥ç›®éŒ„é : ç¬¬ {result['toc_page']} é ")
                                st.write("**ç›®éŒ„å‹¾é¸é …ç›®:**")
                                if result['required_items']:
                                    for item in result['required_items']:
                                        st.markdown(f"- {item}")
                                else:
                                    st.info("æœªæª¢æ¸¬åˆ°å‹¾é¸é …ç›®")
                        
                        with col_v2:
                            st.markdown("#### 2. å®Œæ•´æ€§é©—è­‰å ±å‘Š")
                            if result['validation_report'] is not None and not result['validation_report'].empty:
                                st.dataframe(
                                    result['validation_report'],
                                    use_container_width=True,
                                    hide_index=True
                                )
                                
                                # çµ±è¨ˆ
                                missing = result['validation_report']['ç‹€æ…‹'].str.contains('ç¼ºä»¶').sum()
                                if missing == 0:
                                    st.success("ğŸ‰ æ–‡ä»¶å®Œæ•´ï¼æ‰€æœ‰å‹¾é¸é …ç›®çš†å·²æª¢é™„ã€‚")
                                else:
                                    st.error(f"âš ï¸ ç™¼ç¾ {missing} é …ç¼ºä»¶")
                            else:
                                st.info("ç›®éŒ„é æœªå‹¾é¸ä»»ä½•é …ç›®")
                
            except ImportError:
                st.error("âŒ ai_engine æ¨¡çµ„è¼‰å…¥å¤±æ•—")
            except Exception as e:
                st.error(f"âŒ Vision AI åŸ·è¡ŒéŒ¯èª¤: {e}")
        
        # === å‚³çµ± OCR æ¨¡å¼ ===
        # (pages_info å·²åœ¨ä¸Šæ–¹çµ±ä¸€åˆå§‹åŒ–)
        
        # å»ºç«‹å…©æ¬„ç‰ˆé¢é…ç½®ï¼ˆVision AI å’Œå‚³çµ±æ¨¡å¼éƒ½éœ€è¦ï¼‰
        col_check_1, col_check_2 = st.columns([1, 1])
        
        # åˆå§‹åŒ–è®Šæ•¸ï¼ˆå…©ç¨®æ¨¡å¼éƒ½éœ€è¦ï¼‰
        selected_reqs = []
        
        # å‚³çµ± OCR æ¨¡å¼çš„ç‰¹å®šé‚è¼¯
        if not use_vision_ai:
            with col_check_1:
                st.markdown("#### 1. ç›®éŒ„è§£æ")
                # Find TOC
                toc_page = next((p for p in pages_info if p['type'] == 'ç›®éŒ„'), None)
                
                # Fallback: Search by keywords if not found (é‡å° OCR é›œè¨Šè™•ç†)
                if not toc_page:
                    toc_keywords = ["ç›®éŒ„", "é™„è¡¨", "æ¶ˆé˜²å®‰å…¨è¨­å‚™æª¢ä¿®ç”³å ±æ›¸ç›®éŒ„"]
                    for p in pages_info:
                        # å–å‰ 200 å­—ä¸¦æ¸…æ´— (å»é™¤ç©ºæ ¼ã€è±ç·šã€å…¨å½¢ç©ºæ ¼)
                        clean_text = p['text'][:200].replace(" ", "").replace("|", "").replace("ã€€", "")
                        
                        # æª¢æŸ¥é—œéµå­—
                        if any(kw in clean_text for kw in toc_keywords):
                            toc_page = p
                            p['type'] = 'ç›®éŒ„' # æ›´æ–°é¡å‹ä»¥ä¾¿å¾ŒçºŒé¡¯ç¤º
                            break
                
                if toc_page:
                    st.success(f"âœ… å·²è­˜åˆ¥ç›®éŒ„é  (ç¬¬ {toc_page['page_num']} é )")
                    toc_img = images[toc_page['page_num']-1]
                    st.image(toc_img, caption="ç›®éŒ„é é è¦½", use_column_width=True)
                    
                    # Parse TOC (Lazy load)
                    if 'detected_reqs' not in st.session_state or st.session_state.get('last_file_key') != st.session_state.ocr_cache.get('file_key'):
                        with st.spinner("ğŸ” æ­£åœ¨åˆ†æç›®éŒ„å‹¾é¸é …ç›®..."):
                            st.session_state.detected_reqs = doc_integrity.parse_toc_requirements(toc_img, toc_page['text'])
                            st.session_state.last_file_key = st.session_state.ocr_cache.get('file_key')
                    
                    # Full list of possible documents
                    all_docs = [
                        "æ¶ˆé˜²å®‰å…¨è¨­å‚™æª¢ä¿®ç”³å ±è¡¨", "æ¶ˆé˜²å®‰å…¨è¨­å‚™æª¢ä¿®å ±å‘Šæ›¸", "æ¶ˆé˜²å®‰å…¨è¨­å‚™æ”¹å–„è¨ˆç•«æ›¸", "æ¶ˆé˜²å®‰å…¨è¨­å‚™ç¨®é¡åŠæ•¸é‡è¡¨",
                        "æ»…ç«å™¨æª¢æŸ¥è¡¨", "å®¤å…§æ¶ˆé˜²æ “è¨­å‚™æª¢æŸ¥è¡¨", "è‡ªå‹•æ’’æ°´è¨­å‚™æª¢æŸ¥è¡¨", "æ³¡æ²«æ»…ç«è¨­å‚™æª¢æŸ¥è¡¨", 
                        "ç«è­¦è‡ªå‹•è­¦å ±è¨­å‚™æª¢æŸ¥è¡¨", "ç·Šæ€¥å»£æ’­è¨­å‚™æª¢æŸ¥è¡¨", "æ¨™ç¤ºè¨­å‚™æª¢æŸ¥è¡¨", "é¿é›£è¨­å‚™æª¢æŸ¥è¡¨",
                        "ç·Šæ€¥ç…§æ˜è¨­å‚™æª¢æŸ¥è¡¨", "é€£çµé€æ°´ç®¡æª¢æŸ¥è¡¨", "æ’ç…™è¨­å‚™æª¢æŸ¥è¡¨", "ç„¡ç·šé›»é€šä¿¡è¼”åŠ©è¨­å‚™æª¢æŸ¥è¡¨",
                        "å»ºç¯‰ç‰©ä½¿ç”¨åŸ·ç…§å½±æœ¬", "ç‡Ÿåˆ©äº‹æ¥­ç™»è¨˜è­‰å½±æœ¬", "å°ˆæ¥­æ©Ÿæ§‹åˆæ ¼è­‰æ›¸å½±æœ¬", 
                        "æ¶ˆé˜²è¨­å‚™å¸«(å£«)è­‰æ›¸å½±æœ¬", "ç®¡ç†æ¬Šäººèº«åˆ†è­‰å½±æœ¬"
                    ]
                    
                    # UI for manual correction
                    selected_reqs = st.multiselect(
                        "ç›®éŒ„å‹¾é¸é …ç›® (ç³»çµ±è‡ªå‹•åµæ¸¬ï¼Œå¯æ‰‹å‹•ä¿®æ­£)", 
                        options=all_docs,
                        default=[d for d in st.session_state.detected_reqs if d in all_docs]
                    )
                    
                else:
                    st.warning("âš ï¸ æœªè‡ªå‹•è­˜åˆ¥å‡ºç›®éŒ„é ")
                    st.info("è«‹ç¢ºèªä¸Šå‚³æ–‡ä»¶åŒ…å«ç›®éŒ„ï¼Œæˆ– OCR è¾¨è­˜æ˜¯å¦æ¸…æ™°ã€‚")
                    selected_reqs = []

        with col_check_2:
            # åªæœ‰åœ¨é Vision AI æ¨¡å¼ä¸‹æ‰é¡¯ç¤ºé€™è£¡çš„å ±å‘Š (é¿å…é‡è¤‡)
            if not use_vision_ai:
                st.markdown("#### 2. å®Œæ•´æ€§åˆ†æå ±å‘Š")
            
            if not selected_reqs:
                st.info("ğŸ‘ˆ è«‹å…ˆç¢ºèªå·¦å´ç›®éŒ„å‹¾é¸é …ç›®")
            else:
                # Analysis Logic
                report_data = []
                
                # Get all identified page types
                found_types = set(p['type'] for p in pages_info)
                
                # 1. Check Required Docs
                for req in selected_reqs:
                    status = "âŒ ç¼ºæ¼"
                    note = ""
                    
                    # Fuzzy match logic
                    # If req is in found_types (exact match)
                    if req in found_types:
                        status = "âœ… å·²æª¢é™„"
                    else:
                        # Fuzzy check
                        # e.g. "æ»…ç«å™¨æª¢æŸ¥è¡¨" vs "æ»…ç«å™¨" (from identify_page_type)
                        # Our identify_page_type returns standardized names, so exact match should work if keywords align.
                        # Let's check if any found type contains core keywords of req
                        core_key = req[:4]
                        for ft in found_types:
                            if core_key in ft:
                                status = "âœ… å·²æª¢é™„"
                                note = f"(å°æ‡‰: {ft})"
                                break
                    
                    report_data.append({
                        "é …ç›®": req,
                        "ç‹€æ…‹": status,
                        "å‚™è¨»": note
                    })
                
                # Display Table
                st.dataframe(
                    pd.DataFrame(report_data),
                    column_config={
                        "ç‹€æ…‹": st.column_config.TextColumn("ç‹€æ…‹", width="small"),
                    },
                    use_container_width=True,
                    hide_index=True
                )
                
                # Summary
                missing_count = sum(1 for r in report_data if "ç¼ºæ¼" in r['ç‹€æ…‹'])
                if missing_count == 0:
                    st.success("ğŸ‰ æ–‡ä»¶å®Œæ•´ï¼æ‰€æœ‰ç›®éŒ„å‹¾é¸é …ç›®çš†å·²æª¢é™„ã€‚")
                else:
                    st.error(f"âš ï¸ ç™¼ç¾ {missing_count} é …ç¼ºæ¼æ–‡ä»¶ï¼Œè«‹æª¢æŸ¥ã€‚")
                    
            st.divider()
            with st.expander("æŸ¥çœ‹æ‰€æœ‰è­˜åˆ¥é é¢"):
                st.dataframe(
                    pd.DataFrame(pages_info)[['page_num', 'type', 'first_30']],
                    column_config={
                        "page_num": "é ç¢¼",
                        "type": "è­˜åˆ¥é¡å‹",
                        "first_30": "é é¦–æ–‡å­— (å‰30å­—)"
                    },
                    hide_index=True,
                    use_container_width=True
                )

    else:
        st.info("è«‹å…ˆåœ¨ã€Œç”³å ±æ›¸æ¯”å°ã€åˆ†é ä¸Šå‚³ä¸¦è§£ææ–‡ä»¶ã€‚")
