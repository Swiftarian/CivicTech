import requests
import json
import re
import base64
import pandas as pd
from pathlib import Path

# Ollama API è¨­å®š
OLLAMA_CHAT_URL = "http://localhost:11434/api/chat"
OLLAMA_GENERATE_URL = "http://localhost:11434/api/generate"
DEFAULT_TEXT_MODEL = "llama3"
DEFAULT_VISION_MODEL = "llama3.2-vision"

def is_ollama_available():
    """æª¢æŸ¥ Ollama æœå‹™æ˜¯å¦é‹ä½œä¸­"""
    try:
        response = requests.get("http://localhost:11434/", timeout=2)
        return response.status_code == 200
    except:
        return False

def check_vision_model_available(model_name=DEFAULT_VISION_MODEL):
    """æª¢æŸ¥æŒ‡å®šçš„ Vision æ¨¡å‹æ˜¯å¦å¯ç”¨"""
    if not is_ollama_available():
        return False
    
    try:
        # å˜—è©¦åˆ—å‡ºå¯ç”¨æ¨¡å‹
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json().get('models', [])
            return any(model_name in m['name'] for m in models)
        return False
    except:
        return False

def image_to_base64(image_path):
    """å°‡åœ–ç‰‡æª”æ¡ˆè½‰æ›ç‚º base64 ç·¨ç¢¼"""
    with open(image_path, 'rb') as img_file:
        return base64.b64encode(img_file.read()).decode('utf-8')

def compress_image_for_vision(image_path, max_width=1024, quality=85):
    """
    å£“ç¸®åœ–ç‰‡ä»¥åŠ é€Ÿ Vision AI åˆ†æ
    
    Args:
        image_path: åŸå§‹åœ–ç‰‡è·¯å¾‘
        max_width: æœ€å¤§å¯¬åº¦ (é è¨­ 1024px)
        quality: JPEG å“è³ª (0-100ï¼Œé è¨­ 85)
        
    Returns:
        str: å£“ç¸®å¾Œåœ–ç‰‡çš„ base64 ç·¨ç¢¼
    """
    from PIL import Image
    import io
    
    try:
        with Image.open(image_path) as img:
            # è¨ˆç®—ç¸®æ”¾æ¯”ä¾‹
            if img.width > max_width:
                ratio = max_width / img.width
                new_height = int(img.height * ratio)
                img = img.resize((max_width, new_height), Image.Resampling.LANCZOS)
            
            # è½‰æ›ç‚º RGB (ç§»é™¤é€æ˜é€šé“)
            if img.mode in ('RGBA', 'P'):
                img = img.convert('RGB')
            
            # å£“ç¸®ç‚º JPEG
            buffer = io.BytesIO()
            img.save(buffer, format='JPEG', quality=quality, optimize=True)
            buffer.seek(0)
            
            return base64.b64encode(buffer.read()).decode('utf-8')
    except Exception as e:
        print(f"åœ–ç‰‡å£“ç¸®å¤±æ•—: {e}ï¼Œä½¿ç”¨åŸå§‹åœ–ç‰‡")
        return image_to_base64(image_path)

def compress_pil_image_for_vision(pil_image, max_width=1024, quality=85):
    """
    å£“ç¸® PIL Image ç‰©ä»¶ä»¥åŠ é€Ÿ Vision AI åˆ†æ
    
    Args:
        pil_image: PIL Image ç‰©ä»¶
        max_width: æœ€å¤§å¯¬åº¦ (é è¨­ 1024px)
        quality: JPEG å“è³ª (0-100ï¼Œé è¨­ 85)
        
    Returns:
        str: å£“ç¸®å¾Œåœ–ç‰‡çš„ base64 ç·¨ç¢¼
    """
    import io
    
    try:
        img = pil_image.copy()
        
        # è¨ˆç®—ç¸®æ”¾æ¯”ä¾‹
        if img.width > max_width:
            ratio = max_width / img.width
            new_height = int(img.height * ratio)
            img = img.resize((max_width, new_height), Image.Resampling.LANCZOS)
        
        # è½‰æ›ç‚º RGB (ç§»é™¤é€æ˜é€šé“)
        if img.mode in ('RGBA', 'P'):
            img = img.convert('RGB')
        
        # å£“ç¸®ç‚º JPEG
        buffer = io.BytesIO()
        img.save(buffer, format='JPEG', quality=quality, optimize=True)
        buffer.seek(0)
        
        return base64.b64encode(buffer.read()).decode('utf-8')
    except Exception as e:
        print(f"PIL åœ–ç‰‡å£“ç¸®å¤±æ•—: {e}")
        # Fallback: ç›´æ¥è½‰ base64
        buffer = io.BytesIO()
        pil_image.save(buffer, format='PNG')
        buffer.seek(0)
        return base64.b64encode(buffer.read()).decode('utf-8')

def classify_page_with_vision(image_path, model=DEFAULT_VISION_MODEL):
    """
    ä½¿ç”¨ Vision AI è¾¨è­˜é é¢é¡å‹
    
    Args:
        image_path (str): åœ–ç‰‡æª”æ¡ˆè·¯å¾‘
        model (str): Vision æ¨¡å‹åç¨±
        
    Returns:
        str: æ–‡ä»¶é¡å‹ (ä¾‹å¦‚: "æª¢ä¿®ç”³å ±æ›¸", "æª¢ä¿®ç›®éŒ„", "æœªçŸ¥é é¢")
    """
    try:
        # å°‡åœ–ç‰‡è½‰ç‚º base64
        img_base64 = image_to_base64(image_path)
        
        # æ§‹å»º prompt
        prompt = """é€™æ˜¯ä¸€ä»½æ¶ˆé˜²ç”³å ±æ–‡ä»¶çš„æƒæåœ–ã€‚è«‹è¾¨è­˜é€™é æœ€ä¸Šæ–¹çš„æ¨™é¡Œï¼ˆé€šå¸¸åœ¨å‰ 30% å€åŸŸï¼‰ï¼Œåˆ¤æ–·é€™æ˜¯ä»€éº¼æ–‡ä»¶ï¼Ÿ

è«‹åªå›å‚³æ–‡ä»¶åç¨±ï¼ˆä¾‹å¦‚ï¼š'æª¢ä¿®ç”³å ±æ›¸'ã€'æª¢ä¿®ç›®éŒ„'ã€'å¹³é¢åœ–'ã€'æ»…ç«å™¨æª¢æŸ¥è¡¨'ã€'æ¶ˆé˜²æ “æª¢æŸ¥è¡¨'ï¼‰ï¼Œä¸è¦å›å‚³å…¶ä»–èªªæ˜æ–‡å­—ã€‚

å¦‚æœç„¡æ³•ç¢ºå®šï¼Œè«‹å›å‚³ 'æœªçŸ¥é é¢'ã€‚"""
        
        # å‘¼å« Ollama Chat API (æ”¯æ´ vision)
        payload = {
            "model": model,
            "messages": [
                {
                    "role": "user",
                    "content": prompt,
                    "images": [img_base64]
                }
            ],
            "stream": False
        }
        
        response = requests.post(OLLAMA_CHAT_URL, json=payload, timeout=60)
        
        if response.status_code == 200:
            result = response.json()
            doc_type = result['message']['content'].strip()
            # ç§»é™¤å¯èƒ½çš„å¼•è™Ÿ
            doc_type = doc_type.strip('"\'')
            return doc_type
        else:
            return "æœªçŸ¥é é¢"
            
    except Exception as e:
        print(f"Vision AI è¾¨è­˜å¤±æ•—: {e}")
        return "æœªçŸ¥é é¢"

def extract_checked_items_with_vision(image_path, model=DEFAULT_VISION_MODEL):
    """
    ä½¿ç”¨ Vision AI åµæ¸¬ç›®éŒ„é çš„å‹¾é¸é …ç›®
    
    Args:
        image_path (str): ç›®éŒ„é åœ–ç‰‡è·¯å¾‘
        model (str): Vision æ¨¡å‹åç¨±
        
    Returns:
        list: å·²å‹¾é¸çš„é …ç›®åˆ—è¡¨
    """
    try:
        img_base64 = image_to_base64(image_path)
        
        # å¼·åˆ¶çµæ§‹åŒ–è¼¸å‡ºçš„ prompt
        # å¼·åˆ¶çµæ§‹åŒ–è¼¸å‡ºçš„ prompt
        prompt = """é€™æ˜¯ä¸€å¼µæª¢ä¿®é …ç›®æ¸…å–®ã€‚è«‹ä»”ç´°è§€å¯Ÿæ¯ä¸€é …å‰é¢çš„æ–¹æ¡† (â–¡)ã€‚

è«‹åˆ—å‡ºæ‰€æœ‰ã€æ–¹æ¡†å…§æœ‰æ‰“å‹¾ (âœ“, v)ã€‘ã€ã€è¢«å¡—é»‘ã€‘æˆ–ã€æœ‰ä»»ä½•æ‰‹å¯«æ¨™è¨˜ã€‘çš„é …ç›®åç¨±ã€‚

è¦å‰‡ï¼š
1. åªè¦æ–¹æ¡†å…§ä¸æ˜¯ç©ºç™½çš„ï¼Œå°±è¦–ç‚ºå·²å‹¾é¸ã€‚
2. å¦‚æœæ–¹æ¡†è¢«å¡—æ»¿é»‘è‰²ï¼Œè¦–ç‚ºå·²å‹¾é¸ã€‚
3. å¦‚æœæ–¹æ¡†å…§æœ‰æ‰“å‹¾æˆ–æ‰“å‰ï¼Œè¦–ç‚ºå·²å‹¾é¸ã€‚
4. å¿½ç•¥å®Œå…¨ç©ºç™½çš„æ–¹æ¡†ã€‚

IMPORTANT: Do NOT output any markdown, explanations, or code blocks. Only output a valid JSON array of strings.

Example: ["æ»…ç«å™¨", "é¿é›£å™¨å…·", "ç«è­¦è‡ªå‹•è­¦å ±è¨­å‚™"]

å¦‚æœæ²’æœ‰ä»»ä½•é …ç›®è¢«å‹¾é¸ï¼Œè«‹å›å‚³ç©ºé™£åˆ—: []"""
        
        payload = {
            "model": model,
            "messages": [
                {
                    "role": "user",
                    "content": prompt,
                    "images": [img_base64]
                }
            ],
            "stream": False
        }
        
        response = requests.post(OLLAMA_CHAT_URL, json=payload, timeout=60)
        
        if response.status_code == 200:
            result = response.json()
            content = result['message']['content'].strip()
            
            # ä½¿ç”¨ Regex æå– JSON é™£åˆ—ï¼ˆé˜²æ­¢æ¨¡å‹è¼¸å‡ºå¤šé¤˜æ–‡å­—ï¼‰
            json_match = re.search(r'\[.*\]', content, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                checked_items = json.loads(json_str)
                return checked_items
            else:
                # å¦‚æœæ‰¾ä¸åˆ° JSONï¼Œå›å‚³ç©ºåˆ—è¡¨
                print(f"ç„¡æ³•å¾å›æ‡‰ä¸­æå– JSON: {content}")
                return []
        else:
            return []
            
    except Exception as e:
        print(f"å‹¾é¸é …ç›®æå–å¤±æ•—: {e}")
        return []

def analyze_document_structure(pdf_images_or_path, model=DEFAULT_VISION_MODEL):
    """
    å®Œæ•´çš„æ–‡ä»¶çµæ§‹åˆ†æ (4-step æµç¨‹)
    
    Args:
        pdf_images_or_path: å¯ä»¥æ˜¯ä»¥ä¸‹ä¹‹ä¸€:
            - list of PIL Images
            - list of image file paths
            - PDF file path (æœƒè‡ªå‹•è½‰æ›ç‚ºåœ–ç‰‡)
        model (str): Vision æ¨¡å‹åç¨±
        
    Returns:
        dict: {
            'page_map': {é ç¢¼: æ–‡ä»¶é¡å‹},
            'toc_page': ç›®éŒ„é ç¢¼ (or None),
            'required_items': [å·²å‹¾é¸é …ç›®åˆ—è¡¨],
            'validation_report': pd.DataFrame,
            'error': error message (if any)
        }
    """
    # ç’°å¢ƒæª¢æŸ¥
    if not is_ollama_available():
        raise RuntimeError("Ollama æœå‹™æœªå•Ÿå‹•ï¼Œè«‹å…ˆåŸ·è¡Œ 'ollama serve' æˆ–å•Ÿå‹• Ollama Desktop")
    
    if not check_vision_model_available(model):
        raise RuntimeError(f"Vision æ¨¡å‹ '{model}' æœªå®‰è£ï¼Œè«‹åŸ·è¡Œ: ollama pull {model}")
    
    # è™•ç†è¼¸å…¥ (å¦‚æœæ˜¯ PDF è·¯å¾‘ï¼Œéœ€è¦è½‰æ›ç‚ºåœ–ç‰‡)
    # é€™è£¡å‡è¨­å·²ç¶“ç”±èª¿ç”¨æ–¹è½‰æ›å¥½ï¼ˆå› ç‚ºä¸»ç¨‹å¼å·²æœ‰è½‰æ›é‚è¼¯ï¼‰
    if isinstance(pdf_images_or_path, (str, Path)):
        # å¦‚æœå‚³å…¥çš„æ˜¯ PDF pathï¼Œé€™è£¡å¯ä»¥æ·»åŠ  pdf2image è½‰æ›é‚è¼¯
        # ä½†ç‚ºäº†ç°¡åŒ–ï¼Œæˆ‘å€‘å‡è¨­ä¸»ç¨‹å¼å·²è™•ç†å¥½åœ–ç‰‡åˆ—è¡¨
        raise NotImplementedError("è«‹å…ˆå°‡ PDF è½‰ç‚ºåœ–ç‰‡åˆ—è¡¨å†å‚³å…¥")
    
    images = pdf_images_or_path
    
    # çµæœå®¹å™¨
    result = {
        'page_map': {},
        'toc_page': None,
        'required_items': [],
        'validation_report': None,
        'error': None
    }
    
    try:
        # Step 1: é é¢è­˜åˆ¥ (Page Classification)
        print("ğŸ” Step 1: æ­£åœ¨é€²è¡Œé é¢è­˜åˆ¥...")
        for i, img in enumerate(images):
            page_num = i + 1
            
            # å¦‚æœæ˜¯ PIL Imageï¼Œéœ€è¦å…ˆå„²å­˜ç‚ºè‡¨æ™‚æª”æ¡ˆ
            if hasattr(img, 'save'):
                import os
                import tempfile
                temp_dir = tempfile.gettempdir()
                temp_path = os.path.join(temp_dir, f"temp_page_{page_num}.png")
                img.save(temp_path)
                doc_type = classify_page_with_vision(temp_path, model)
                try:
                    os.remove(temp_path)
                except:
                    pass  # å¿½ç•¥åˆªé™¤éŒ¯èª¤
            else:
                # å‡è¨­æ˜¯æª”æ¡ˆè·¯å¾‘
                doc_type = classify_page_with_vision(img, model)
            
            result['page_map'][page_num] = doc_type
            print(f"  ç¬¬ {page_num} é : {doc_type}")
        
        # Step 2: åµæ¸¬ã€Œæª¢ä¿®ç›®éŒ„ã€èˆ‡å‹¾é¸é …ç›®
        print("\nğŸ“‹ Step 2: æ­£åœ¨å°‹æ‰¾ç›®éŒ„é ä¸¦æå–å‹¾é¸é …ç›®...")
        
        # å°‹æ‰¾ç›®éŒ„é 
        toc_keywords = ['ç›®éŒ„', 'æª¢ä¿®é …ç›®', 'ç”³å ±é …ç›®', 'æ¸…å–®']
        for page_num, doc_type in result['page_map'].items():
            if any(keyword in doc_type for keyword in toc_keywords):
                result['toc_page'] = page_num
                print(f"  âœ… æ‰¾åˆ°ç›®éŒ„é : ç¬¬ {page_num} é ")
                
                # æå–å‹¾é¸é …ç›®
                img = images[page_num - 1]
                if hasattr(img, 'save'):
                    import os
                    import tempfile
                    temp_dir = tempfile.gettempdir()
                    temp_path = os.path.join(temp_dir, "temp_toc.png")
                    img.save(temp_path)
                    required_items = extract_checked_items_with_vision(temp_path, model)
                    try:
                        os.remove(temp_path)
                    except:
                        pass
                else:
                    required_items = extract_checked_items_with_vision(img, model)
                
                result['required_items'] = required_items
                print(f"  æ‰¾åˆ° {len(required_items)} å€‹å‹¾é¸é …ç›®: {required_items}")
                break
        
        if not result['toc_page']:
            print("  âš ï¸ æœªæ‰¾åˆ°ç›®éŒ„é ")
        
        # Step 3 & 4: äº¤å‰æ¯”å° & ç”Ÿæˆå ±å‘Š
        print("\nâœ… Step 3 & 4: æ­£åœ¨é€²è¡Œäº¤å‰æ¯”å°ä¸¦ç”Ÿæˆå ±å‘Š...")
        
        report_data = []
        for item in result['required_items']:
            # åˆ¤å®šè¦å‰‡: åœ¨ page_map ä¸­å°‹æ‰¾åŒ…å«è©²é …ç›®åç¨±çš„é é¢
            found_pages = []
            for page_num, doc_type in result['page_map'].items():
                # æ¨¡ç³ŠåŒ¹é… (ä¾‹å¦‚ "æ»…ç«å™¨" æ‡‰è©²åŒ¹é… "æ»…ç«å™¨æª¢æŸ¥è¡¨")
                if item in doc_type or doc_type in item:
                    found_pages.append(page_num)
            
            status = "âœ… åˆè¦" if found_pages else "âŒ ç¼ºä»¶"
            page_list = ", ".join([f"ç¬¬{p}é " for p in found_pages]) if found_pages else "-"
            
            report_data.append({
                'æ‡‰æª¢é™„é …ç›®': item,
                'æ˜¯å¦å‹¾é¸': 'âœ“',
                'å¯¦éš›é æ•¸': page_list,
                'ç‹€æ…‹': status
            })
        
        result['validation_report'] = pd.DataFrame(report_data)
        
        print("  âœ… å ±å‘Šç”Ÿæˆå®Œæˆ")
        return result
        
    except Exception as e:
        result['error'] = str(e)
        print(f"âŒ åˆ†æéç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        return result

def analyze_page_with_ai(text_content, model=DEFAULT_TEXT_MODEL):
    """
    ä½¿ç”¨ AI åˆ†æå–®é å…§å®¹ (åŸºæ–¼æ–‡å­—çš„ OCR çµæœ)
    
    Args:
        text_content (str): OCR è¾¨è­˜å‡ºçš„æ–‡å­—
        model (str): ä½¿ç”¨çš„æ¨¡å‹åç¨±
        
    Returns:
        dict: AI åˆ†æçµæœ
    """
    if not text_content.strip():
        return {"error": "No text content"}

    prompt = f"""ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ¶ˆé˜²å®‰å…¨æª¢æŸ¥å“¡ã€‚è«‹å¾ä»¥ä¸‹ OCR æ–‡å­—ä¸­æå–é—œéµè³‡è¨Šã€‚
    
    OCR æ–‡å­—:
    ----------------
    {text_content}
    ----------------
    
    ğŸ“Œ **æ ¸å¿ƒè¦å‰‡ï¼ˆæœ€é«˜å„ªå…ˆç´š - å¿…é ˆåš´æ ¼éµå®ˆï¼‰**ï¼š
    
    âš ï¸ **å‹¾é¸ç¬¦è™Ÿè­˜åˆ¥è¦å‰‡ï¼ˆé€™æ˜¯æœ€é‡è¦çš„è¦å‰‡ï¼ï¼‰**ï¼š
    1. åœ¨ç›®éŒ„é ï¼ˆã€Œæ¶ˆé˜²å®‰å…¨è¨­å‚™æª¢ä¿®ç”³å ±æ›¸ç›®éŒ„ã€ï¼‰ä¸­ï¼Œæ¯å€‹è¨­å‚™å‰é¢éƒ½æœ‰æ–¹æ¡†
    2. **ä¸»è¦åˆ¤æ–·ä¾æ“šï¼šæ–¹æ¡†å…§æœ‰æ‰“å‹¾ï¼ˆâœ“ã€â˜‘ã€âˆšã€âœ”ã€â– ã€â—ï¼‰çš„é …ç›®**
    3. **ğŸ’¡ é ç¢¼åˆ¤æ–·æ³• (æœ€æº–ç¢ºçš„æ–¹æ³•ï¼)**ï¼š
       - åœ¨ç›®éŒ„é ä¸­ï¼Œæ¯å€‹è¨­å‚™é …ç›®å¾Œé¢æœƒæœ‰é ç¢¼ï¼ˆå¦‚ "2-1", "2-13", "2-24"ï¼‰
       - **å¦‚æœè¨­å‚™åç¨±å¾Œé¢æœ‰é ç¢¼ï¼Œå°±è¡¨ç¤ºè©²è¨­å‚™å·²å‹¾é¸ä¸¦æœ‰ç›¸æ‡‰çš„æª¢æŸ¥è¡¨**
       - ä¾‹å¦‚ï¼šã€Œæ»…ç«å™¨æª¢æŸ¥è¡¨ 2-1ã€â†’ æ»…ç«å™¨å·²å‹¾é¸
       - ä¾‹å¦‚ï¼šã€Œå®¤å…§æ¶ˆé˜²æ “è¨­å‚™æª¢æŸ¥è¡¨ 2-2ã€â†’ å®¤å…§æ¶ˆé˜²æ “è¨­å‚™å·²å‹¾é¸
       - **å¦‚æœè¨­å‚™åç¨±å¾Œé¢æ²’æœ‰é ç¢¼ï¼Œè¡¨ç¤ºè©²è¨­å‚™æœªå‹¾é¸**
    
    âœ… **æ­£ç¢ºç¯„ä¾‹**ï¼ˆæ‡‰è©²æå–ï¼‰ï¼š
    - "â˜‘ æ»…ç«å™¨æª¢æŸ¥è¡¨ 2-1" â†’ æå– "æ»…ç«å™¨"
    - "å®¤å…§æ¶ˆé˜²æ “è¨­å‚™æª¢æŸ¥è¡¨ 2-2" â†’ æå– "å®¤å…§æ¶ˆé˜²æ “è¨­å‚™" (æœ‰é ç¢¼)
    - "ç«è­¦è‡ªå‹•è­¦å ±è¨­å‚™æª¢æŸ¥è¡¨ 2-13" â†’ æå– "ç«è­¦è‡ªå‹•è­¦å ±è¨­å‚™"
    - "ç·Šæ€¥å»£æ’­è¨­å‚™æª¢æŸ¥è¡¨ 2-14" â†’ æå– "ç·Šæ€¥å»£æ’­è¨­å‚™"
    - "æ¨™ç¤ºè¨­å‚™æª¢æŸ¥è¡¨ 2-17" â†’ æå– "æ¨™ç¤ºè¨­å‚™"
    - "é¿é›£å™¨å…·æª¢æŸ¥è¡¨ 2-18" â†’ æå– "é¿é›£å™¨å…·"
    - "ç·Šæ€¥ç…§æ˜è¨­å‚™æª¢æŸ¥è¡¨ 2-19" â†’ æå– "ç·Šæ€¥ç…§æ˜è¨­å‚™"
    - "é…ç·šæª¢æŸ¥è¡¨ 2-24" â†’ æå– "é…ç·š"
    
    âŒ **éŒ¯èª¤ç¯„ä¾‹**ï¼ˆçµ•å°ä¸è¦æå–ï¼‰ï¼š
    - "â˜ å®¤å¤–æ¶ˆé˜²æ “è¨­å‚™" â†’ **ä¸æå–**ï¼ˆæ˜ç¢ºçš„ç©ºç™½æ–¹æ¡†ï¼‰
    - "â–¡ æ’ç…™è¨­å‚™" â†’ **ä¸æå–**ï¼ˆç„¡é ç¢¼ï¼‰
    - "é€£çµé€æ°´ç®¡" â†’ **ä¸æå–**ï¼ˆç„¡é ç¢¼ï¼Œç„¡å‹¾é¸ï¼‰
    
    ğŸ’¡ **å¯¦éš›æ¡ˆä¾‹**ï¼š
    å¦‚æœ OCR æ–‡å­—é¡¯ç¤ºï¼š
    ```
    æ»…ç«å™¨æª¢æŸ¥è¡¨ 2-1
    å®¤å…§æ¶ˆé˜²æ “è¨­å‚™æª¢æŸ¥è¡¨ 2-2
    â–¡ å®¤å¤–æ¶ˆé˜²æ “è¨­å‚™
    ç«è­¦è‡ªå‹•è­¦å ±è¨­å‚™æª¢æŸ¥è¡¨ 2-13
    ç·Šæ€¥å»£æ’­è¨­å‚™æª¢æŸ¥è¡¨ 2-14
    â–¡ æ’ç…™è¨­å‚™
    æ¨™ç¤ºè¨­å‚™æª¢æŸ¥è¡¨ 2-17
    é¿é›£å™¨å…·æª¢æŸ¥è¡¨ 2-18
    ç·Šæ€¥ç…§æ˜è¨­å‚™æª¢æŸ¥è¡¨ 2-19
    é…ç·šæª¢æŸ¥è¡¨ 2-24
    ```
    æ­£ç¢ºçš„ equipment_list æ‡‰è©²æ˜¯ï¼š["æ»…ç«å™¨", "å®¤å…§æ¶ˆé˜²æ “è¨­å‚™", "ç«è­¦è‡ªå‹•è­¦å ±è¨­å‚™", "ç·Šæ€¥å»£æ’­è¨­å‚™", "æ¨™ç¤ºè¨­å‚™", "é¿é›£å™¨å…·", "ç·Šæ€¥ç…§æ˜è¨­å‚™", "é…ç·š"]
    (å®¤å¤–æ¶ˆé˜²æ “å’Œæ’ç…™è¨­å‚™æ²’æœ‰é ç¢¼ï¼Œæ‰€ä»¥ä¸æå–)
    
    ---
    
    è«‹æå–ä»¥ä¸‹æ¬„ä½ä¸¦ä»¥ JSON æ ¼å¼å›å‚³ã€‚
    
    âš ï¸ **å…¶ä»–é‡è¦è¦å‰‡**ï¼š
    0. **å¼·åˆ¶ä½¿ç”¨ç¹é«”ä¸­æ–‡**ï¼šæ‰€æœ‰è¼¸å‡ºå¿…é ˆä½¿ç”¨å°ç£ç¹é«”ä¸­æ–‡ï¼Œåš´ç¦ä½¿ç”¨ç°¡é«”å­—ï¼ˆä¾‹å¦‚ï¼šã€Œå°æ±ã€è€Œéã€Œå°ä¸œã€ã€ã€Œç¶±ã€è€Œéã€Œçº²ã€ï¼‰ã€‚
    1. **å»é™¤æ‰€æœ‰ç©ºæ ¼**ï¼šæ‰€æœ‰è¼¸å‡ºçš„å€¼éƒ½å¿…é ˆå»é™¤æ‰€æœ‰ç©ºæ ¼ (ä¾‹å¦‚ "é³³ ä»™" -> "é³³ä»™")ã€‚
    2. **å–®ä¸€å­—ä¸²**ï¼šåœ°å€å’Œç®¡ç†æ¬Šäººå¿…é ˆæ˜¯å–®ä¸€å­—ä¸²ï¼Œåš´ç¦ä½¿ç”¨å·¢ç‹€ JSON (ä¾‹å¦‚ä¸è¦å›å‚³ {{'city': ...}})ã€‚
    3. **OCR å®¹éŒ¯**ï¼šOCR å¯èƒ½æœ‰éŒ¯å­—ã€ç¼ºå­—ã€å¤šå­—æˆ–ç©ºæ ¼å•é¡Œï¼Œè«‹ä½¿ç”¨æ¨¡ç³Šæ¯”å°ï¼Œç›¸ä¼¼åº¦ 80% ä»¥ä¸Šå³å¯æ¥å—ã€‚
    
    æ¬„ä½èªªæ˜ï¼š
    1. document_type: æ–‡ä»¶é¡å‹
    2. place_name: å ´æ‰€åç¨± (å»é™¤ç©ºæ ¼)
    3. address: åœ°å€ (å®Œæ•´åœ°å€å­—ä¸²ï¼Œå»é™¤ç©ºæ ¼)
    4. management_person: ç®¡ç†æ¬Šäºº (å§“åå­—ä¸²ï¼Œå»é™¤ç©ºæ ¼)
    5. phone_number: é›»è©±è™Ÿç¢¼ (å»é™¤ç©ºæ ¼ï¼Œä¿ç•™å€ç¢¼å’Œåˆ†æ©Ÿï¼Œä¾‹å¦‚ï¼šã€Œ(089)322112ã€â†’ã€Œ089-322112ã€ï¼Œã€Œ(089)3221123#457ã€â†’ã€Œ089-3221123#457ã€)
    6. equipment_list: æ¶ˆé˜²è¨­å‚™åˆ—è¡¨ (Arrayï¼Œæ¯å€‹é …ç›®ä¹Ÿè¦å»é™¤ç©ºæ ¼)

    ğŸ“‹ **æ¨™æº–è¨­å‚™æ¸…å–®** (è«‹å„ªå…ˆå¾ä»¥ä¸‹æ¸…å–®ä¸­æ¯”å°ï¼Œä½¿ç”¨æ¨¡ç³Šæ¯”å°):
    - æ»…ç«å™¨
    - å®¤å…§æ¶ˆé˜²æ “è¨­å‚™
    - å®¤å¤–æ¶ˆé˜²æ “è¨­å‚™
    - è‡ªå‹•æ’’æ°´è¨­å‚™
    - æ°´éœ§æ»…ç«è¨­å‚™
    - æ³¡æ²«æ»…ç«è¨­å‚™
    - äºŒæ°§åŒ–ç¢³æ»…ç«è¨­å‚™
    - ä¹¾ç²‰æ»…ç«è¨­å‚™
    - æµ·é¾æ»…ç«è¨­å‚™(å«æµ·é¾æ›¿ä»£å“)
    - ç«è­¦è‡ªå‹•è­¦å ±è¨­å‚™
    - ç“¦æ–¯æ¼æ°£ç«è­¦è‡ªå‹•è­¦å ±è¨­å‚™
    - ç·Šæ€¥å»£æ’­è¨­å‚™
    - æ¨™ç¤ºè¨­å‚™
    - é¿é›£å™¨å…·
    - ç·Šæ€¥ç…§æ˜è¨­å‚™
    - é€£çµé€æ°´ç®¡
    - æ¶ˆé˜²å°ˆç”¨è“„æ°´æ± 
    - æ’ç…™è¨­å‚™
    - ç„¡ç·šé›»é€šä¿¡è¼”åŠ©è¨­å‚™
    
    ğŸ” **æ¨¡ç³Šæ¯”å°è¦å‰‡**ï¼š
    - OCR å¯èƒ½å°‡ã€Œå…§ã€è­˜åˆ¥ç‚ºã€Œå†…ã€ã€ã€Œæ “ã€è­˜åˆ¥ç‚ºã€Œæ‹´ã€
    - å¯èƒ½æœ‰å¤šé¤˜ç©ºæ ¼ï¼šã€Œå®¤ å…§ æ¶ˆ é˜² æ “ã€-> ã€Œå®¤å…§æ¶ˆé˜²æ “è¨­å‚™ã€
    - å¯èƒ½ç¼ºå°‘ã€Œè¨­å‚™ã€äºŒå­—ï¼šã€Œå®¤å…§æ¶ˆé˜²æ “ã€-> ã€Œå®¤å…§æ¶ˆé˜²æ “è¨­å‚™ã€
    - ç°¡é«”è½‰ç¹é«”ï¼šã€Œç­ç«å™¨ã€-> ã€Œæ»…ç«å™¨ã€
    - å…¨å½¢è½‰åŠå½¢ï¼šã€Œ(å«æµ·é¾æ›¿ä»£å“)ã€-> ã€Œ(å«æµ·é¾æ›¿ä»£å“)ã€
    
    OCR è¼¸å…¥: "å®¤ å†… æ¶ˆ é˜² æ‹´"
    æ­£ç¢ºè¼¸å‡º: "å®¤å…§æ¶ˆé˜²æ “è¨­å‚™"
    
    OCR è¼¸å…¥: "ç«è­¦è‡ªå‹•è­¦å ±"
    æ­£ç¢ºè¼¸å‡º: "ç«è­¦è‡ªå‹•è­¦å ±è¨­å‚™"

    å¦‚æœæ‰¾ä¸åˆ°æ¬„ä½ï¼Œè«‹å¡« nullã€‚åªå›å‚³ JSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ã€‚
    """
    
    payload = {
        "model": model,
        "prompt": prompt,
        "stream": False
    }
    
    try:
        response = requests.post(OLLAMA_GENERATE_URL, json=payload, timeout=60)  # Extended timeout
        if response.status_code == 200:
            result = response.json()
            response_text = result.get('response', '')
            
            if not response_text or not response_text.strip():
                return {"error": "AI returned empty response"}

            # Debug: Print raw response (truncated for readability)
            print(f"ğŸ¤– AI Raw Response (first 500 chars): {response_text[:500]}")

            # Multi-step JSON extraction with fallbacks
            extracted_json = None
            
            # Step 1: Try to extract JSON from markdown code block (```json ... ```)
            markdown_match = re.search(r'```(?:json)?\s*(\{[\s\S]*?\})\s*```', response_text, re.DOTALL)
            if markdown_match:
                try:
                    extracted_json = json.loads(markdown_match.group(1))
                    print("âœ… Extracted JSON from markdown code block")
                except json.JSONDecodeError:
                    pass
            
            # Step 2: Try direct JSON object extraction (greedy match for nested objects)
            if not extracted_json:
                # Use a more sophisticated regex that handles nested braces
                json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', response_text, re.DOTALL)
                if json_match:
                    try:
                        extracted_json = json.loads(json_match.group(0))
                        print("âœ… Extracted JSON with regex")
                    except json.JSONDecodeError:
                        pass
            
            # Step 3: Try finding JSON with balanced braces
            if not extracted_json:
                start_idx = response_text.find('{')
                if start_idx != -1:
                    brace_count = 0
                    end_idx = start_idx
                    for i, char in enumerate(response_text[start_idx:], start_idx):
                        if char == '{':
                            brace_count += 1
                        elif char == '}':
                            brace_count -= 1
                            if brace_count == 0:
                                end_idx = i + 1
                                break
                    
                    if end_idx > start_idx:
                        json_str = response_text[start_idx:end_idx]
                        try:
                            extracted_json = json.loads(json_str)
                            print("âœ… Extracted JSON with brace balancing")
                        except json.JSONDecodeError:
                            pass
            
            # Step 4: Try ast.literal_eval for Python dict-like strings
            if not extracted_json:
                try:
                    import ast
                    # Find dict-like structure
                    dict_match = re.search(r'\{.*\}', response_text, re.DOTALL)
                    if dict_match:
                        extracted_json = ast.literal_eval(dict_match.group(0))
                        print("âœ… Extracted using ast.literal_eval")
                except:
                    pass
            
            # If extraction successful, return the JSON
            if extracted_json and isinstance(extracted_json, dict):
                return extracted_json
            
            # If all extraction methods fail, return error with raw response
            print(f"âš ï¸ All JSON extraction methods failed")
            return {
                "error": "No JSON object found in AI response",
                "raw_response": response_text[:1000],  # Truncate for display
                "document_type": None,
                "place_name": None,
                "address": None,
                "management_person": None,
                "equipment_list": []
            }
                
        else:
            return {"error": f"API Error: {response.status_code}"}
    except requests.Timeout:
        return {"error": "AI request timed out (60s). The model may be loading or overloaded."}
    except Exception as e:
        return {"error": str(e)}

def analyze_document(pages_text, model=DEFAULT_TEXT_MODEL):
    """
    åˆ†ææ•´ä»½æ–‡ä»¶ (å¤šé ) - åŸºæ–¼ OCR æ–‡å­—
    
    Args:
        pages_text (list): æ¯ä¸€é çš„ OCR æ–‡å­—åˆ—è¡¨
        
    Returns:
        dict: æ•´åˆå¾Œçš„åˆ†æçµæœ
    """
    if not is_ollama_available():
        return {"error": "Ollama service not available"}
        
    # é€™è£¡å¯ä»¥å¯¦ä½œæ›´è¤‡é›œçš„é‚è¼¯ï¼Œä¾‹å¦‚åªåˆ†æç¬¬ä¸€é ï¼Œæˆ–æ˜¯å½™æ•´æ‰€æœ‰é é¢
    # å„ªåŒ–ï¼šåŒæ™‚åˆ†æç¬¬ä¸€é (åŸºæœ¬è³‡æ–™)å’Œç›®éŒ„é (è¨­å‚™æ¸…å–®)
    if pages_text:
        combined_text = pages_text[0] # é è¨­åŒ…å«ç¬¬ä¸€é 
        
        # å°‹æ‰¾ç›®éŒ„é  (é—œéµå­—: ç›®éŒ„, é™„è¡¨, æª¢æŸ¥è¡¨)
        toc_keywords = ["ç›®éŒ„", "é™„è¡¨", "æª¢æŸ¥è¡¨"]
        toc_text = ""
        
        # å¾ç¬¬äºŒé é–‹å§‹æ‰¾ (index 1)
        if len(pages_text) > 1:
            for i in range(1, len(pages_text)):
                page_content = pages_text[i]
                # ç°¡å–®åˆ¤æ–·
                if any(kw in page_content for kw in toc_keywords):
                    toc_text = page_content
                    break
            
            # å¦‚æœæ²’æ‰¾åˆ°æ˜ç¢ºçš„ç›®éŒ„é ï¼Œä½†æœ‰ç¬¬äºŒé ï¼Œå°±é è¨­æŠ“ç¬¬äºŒé  (é€šå¸¸ç›®éŒ„åœ¨ç¬¬äºŒé )
            if not toc_text and len(pages_text) > 1:
                toc_text = pages_text[1]
        
        if toc_text:
            combined_text += "\n\n--- (ä»¥ä¸‹ç‚ºç›®éŒ„é å…§å®¹) ---\n\n" + toc_text
            
        return analyze_page_with_ai(combined_text, model)
    return {}
