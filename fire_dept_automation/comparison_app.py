import streamlit as st
import pandas as pd
import os
import fitz  # pymupdf
from PIL import Image
import pytesseract
import re
import config_loader

# è¨­å®šé é¢é…ç½®
st.set_page_config(layout="wide", page_title="è‡ºæ±ç¸£æ¶ˆé˜²å±€æª¢ä¿®ç”³å ±æ›¸æª¢æ ¸æ¯”å°ç³»çµ±")

import urllib.request
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

# ==========================================
# è¨­å®šå€
# ==========================================
# é è¨­ Tesseract è·¯å¾‘
DEFAULT_TESSERACT_PATH = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

# æœ¬åœ° tessdata è³‡æ–™å¤¾ (é¿å…æ¬Šé™å•é¡Œ)
LOCAL_TESSDATA_DIR = os.path.join(os.getcwd(), "tessdata")

# ==========================================
# å‡½å¼å€
# ==========================================

def send_email(sender_email, sender_password, receiver_email, subject, body):
    """ç™¼é€ Email é€šçŸ¥"""
    try:
        msg = MIMEMultipart()
        msg['From'] = sender_email
        msg['To'] = receiver_email
        msg['Subject'] = subject
        
        msg.attach(MIMEText(body, 'plain'))
        
        # é€£ç·šåˆ° Gmail SMTP Server (ä½¿ç”¨ SSL)
        server = smtplib.SMTP_SSL('smtp.gmail.com', 465)
        server.login(sender_email, sender_password)
        server.send_message(msg)
        server.quit()
        return True, "ç™¼é€æˆåŠŸ"
    except Exception as e:
        return False, f"ç™¼é€å¤±æ•—: {e}"

def download_lang_data():
    """ä¸‹è¼‰ç¹é«”ä¸­æ–‡èªè¨€åŒ…"""
    if not os.path.exists(LOCAL_TESSDATA_DIR):
        os.makedirs(LOCAL_TESSDATA_DIR)
    
    # ä¸‹è¼‰ chi_tra.traineddata
    url = "https://github.com/tesseract-ocr/tessdata_best/raw/main/chi_tra.traineddata"
    dest = os.path.join(LOCAL_TESSDATA_DIR, "chi_tra.traineddata")
    
    if not os.path.exists(dest):
        with st.spinner("æ­£åœ¨ä¸‹è¼‰ç¹é«”ä¸­æ–‡èªè¨€åŒ… (ç´„ 15MB)..."):
            try:
                urllib.request.urlretrieve(url, dest)
                st.success("ä¸‹è¼‰å®Œæˆï¼")
            except Exception as e:
                st.error(f"ä¸‹è¼‰å¤±æ•—: {e}")

    # å˜—è©¦è¤‡è£½ eng.traineddata (å¦‚æœæœ‰çš„è©±)ï¼Œå¦å‰‡ä¹Ÿä¸‹è¼‰
    eng_dest = os.path.join(LOCAL_TESSDATA_DIR, "eng.traineddata")
    if not os.path.exists(eng_dest):
        eng_url = "https://github.com/tesseract-ocr/tessdata_best/raw/main/eng.traineddata"
        try:
            urllib.request.urlretrieve(eng_url, eng_dest)
        except:
            pass # è‹±æ–‡éå¿…è¦ï¼Œå¤±æ•—å°±ç®—äº†

@st.cache_data
def load_system_data(excel_source):
    """
    è®€å–ç³»çµ±åˆ—ç®¡è³‡æ–™ Excel (ä¿®æ­£ç‰ˆ)
    Args:
        excel_source: æª”æ¡ˆè·¯å¾‘ (str) æˆ– æª”æ¡ˆç‰©ä»¶ (UploadedFile)
    """
    if excel_source is None:
        return None
    try:
        # å¦‚æœæ˜¯å­—ä¸²è·¯å¾‘ï¼Œå…ˆæª¢æŸ¥å­˜åœ¨æ€§
        if isinstance(excel_source, str):
            if not os.path.exists(excel_source):
                return None
            engine = 'xlrd' if excel_source.endswith('.xls') else None
            df = pd.read_excel(excel_source, header=1, engine=engine)
        else:
            # å¦‚æœæ˜¯æª”æ¡ˆç‰©ä»¶ï¼Œç›´æ¥è®€å–
            filename = getattr(excel_source, 'name', '')
            engine = 'xlrd' if filename.endswith('.xls') else None
            df = pd.read_excel(excel_source, header=1, engine=engine)
            
        # æ¸…ç†æ¬„ä½åç¨± (å»é™¤å‰å¾Œç©ºç™½ã€æ›è¡Œç¬¦è™Ÿ)
        df.columns = df.columns.astype(str).str.strip().str.replace('\n', '').str.replace('\r', '')
        return df
    except Exception as e:
        st.error(f"è®€å– Excel å¤±æ•—: {e}")
        return None

def pdf_to_images(pdf_file):
    """å°‡ PDF è½‰ç‚ºåœ–ç‰‡åˆ—è¡¨ (æ¯ä¸€é ä¸€å¼µåœ–)"""
    doc = fitz.open(stream=pdf_file.read(), filetype="pdf")
    images = []
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        pix = page.get_pixmap(dpi=300) # é«˜è§£æåº¦ä»¥åˆ© OCR
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        images.append(img)
    return images

import subprocess

def perform_ocr(image, tesseract_cmd):
    """å°åœ–ç‰‡é€²è¡Œ OCR è¾¨è­˜ (æ”¹ç”¨ subprocess ä»¥è§£æ±ºç·¨ç¢¼å•é¡Œ)"""
    temp_img_path = os.path.join(os.getcwd(), "temp_ocr_image.png")
    try:
        # 1. å…ˆå°‡åœ–ç‰‡å­˜ç‚ºæš«å­˜æª”
        image.save(temp_img_path)
        
        # 2. çµ„å»ºæŒ‡ä»¤
        # tesseract.exe <image> stdout -l chi_tra+eng --tessdata-dir <dir>
        cmd = [
            tesseract_cmd,
            temp_img_path,
            "stdout",
            "-l", "chi_tra+eng",
            "--tessdata-dir", LOCAL_TESSDATA_DIR
        ]
        
        # 3. åŸ·è¡ŒæŒ‡ä»¤ (éš±è—è¦–çª—)
        startupinfo = subprocess.STARTUPINFO()
        startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
        
        process = subprocess.run(
            cmd,
            capture_output=True,
            startupinfo=startupinfo
        )
        
        # 4. è™•ç†è¼¸å‡º (å˜—è©¦ä¸åŒç·¨ç¢¼)
        stdout_data = process.stdout
        stderr_data = process.stderr
        
        if process.returncode != 0:
            # å¦‚æœå¤±æ•—ï¼Œå˜—è©¦è§£ç¢¼éŒ¯èª¤è¨Šæ¯
            try:
                err_msg = stderr_data.decode('utf-8')
            except:
                err_msg = stderr_data.decode('cp950', errors='ignore')
            return f"OCR Error (Code {process.returncode}): {err_msg}"

        # å˜—è©¦ UTF-8 è§£ç¢¼
        try:
            text = stdout_data.decode('utf-8')
        except UnicodeDecodeError:
            # å¤±æ•—å‰‡å˜—è©¦ Big5 (cp950) - å¸¸è¦‹æ–¼ç¹é«”ä¸­æ–‡ Windows
            text = stdout_data.decode('cp950', errors='ignore')
            
        return text

    except Exception as e:
        return f"Error: {e}"
    finally:
        # æ¸…ç†æš«å­˜æª”
        if os.path.exists(temp_img_path):
            try:
                os.remove(temp_img_path)
            except:
                pass

# å®šç¾©æ¨™æº–è¨­å‚™æ¸…å–® (ä¾é•·åº¦æ’åºï¼Œå„ªå…ˆæ¯”å°é•·å­—ä¸²)
VALID_EQUIPMENT_LIST = sorted([
    "æ»…ç«å™¨", "è‡ªå‹•æ’’æ°´è¨­å‚™", "æƒ°æ€§æ°£é«”æ»…ç«è¨­å‚™", "ç°¡æ˜“è‡ªå‹•æ»…ç«è¨­å‚™", "è­¦å ±è¨­å‚™", 
    "ç«è­¦è‡ªå‹•è­¦å ±è¨­å‚™", "ä¸€ä¸€ä¹ç«ç½é€šå ±è£ç½®", "é¿é›£é€ƒç”Ÿè¨­å‚™", "æ¨™ç¤ºè¨­å‚™", 
    "æ¶ˆé˜²æ¶æ•‘ä¸Šä¹‹å¿…è¦è¨­å‚™", "é€£çµé€æ°´ç®¡", "ç„¡ç·šé›»é€šä¿¡è¼”åŠ©è¨­å‚™", "å…¶ä»–", 
    "å†·å»æ’’æ°´è¨­å‚™", "å®¤å…§æ¶ˆé˜²æ “è¨­å‚™", "æ°´éœ§æ»…ç«è¨­å‚™", "ä¹¾ç²‰æ»…ç«è¨­å‚™", 
    "é¹µåŒ–ç…™æ»…ç«è¨­å‚™", "ç“¦æ–¯æ¼æ°£ç«è­¦è‡ªå‹•è­¦å ±è¨­å‚™", "é¿é›£å™¨å…·", "æ¶ˆé˜²å°ˆç”¨è“„æ°´æ± ", 
    "ç·Šæ€¥é›»æºæ’åº§", "å®¤å¤–æ¶ˆé˜²æ “è¨­å‚™", "æ³¡æ²«æ»…ç«è¨­å‚™", "æµ·é¾æ»…ç«è¨­å‚™", 
    "ç·Šæ€¥å»£æ’­è¨­å‚™", "ç·Šæ€¥ç…§æ˜è¨­å‚™", "æ’ç…™è¨­å‚™", "é˜²ç½ç›£æ§ç³»çµ±ç¶œåˆæ“ä½œè£ç½®", 
    "å°„æ°´è¨­å‚™", "é…ç·š"
], key=len, reverse=True)

def normalize_equipment_str(text):
    """
    å°‡è¼¸å…¥çš„æ–‡å­— (OCR æˆ– ç³»çµ±è³‡æ–™) é€²è¡Œæ¨¡ç³Šæ¯”å°ï¼Œ
    åªä¿ç•™æ¨™æº–è¨­å‚™æ¸…å–®ä¸­çš„é …ç›®ï¼Œä¸¦ä»¥é “è™Ÿåˆ†éš”ã€‚
    """
    if not text or not isinstance(text, str):
        return ""
    
    found_items = []
    # ç‚ºäº†é¿å…é‡è¤‡åŒ¹é… (ä¾‹å¦‚ "ç«è­¦è‡ªå‹•è­¦å ±è¨­å‚™" åŒ…å« "è­¦å ±è¨­å‚™")
    # æˆ‘å€‘å·²ç¶“å°‡åˆ—è¡¨æŒ‰é•·åº¦æ’åºã€‚
    # ä½†é€™è£¡æˆ‘å€‘æ¡å–ç°¡å–®ç­–ç•¥ï¼šåªè¦å­—ä¸²ä¸­æœ‰å‡ºç¾è©²è¨­å‚™åç¨±ï¼Œå°±åˆ—å…¥ã€‚
    # ç‚ºäº†é¿å…é‡è¤‡ (ä¾‹å¦‚åŒä¸€å€‹è©å‡ºç¾å…©æ¬¡)ï¼Œä½¿ç”¨ set æˆ–æª¢æŸ¥æ˜¯å¦å­˜åœ¨
    
    # å…ˆç§»é™¤å¸¸è¦‹å¹²æ“¾å­—å…ƒï¼Œæ–¹ä¾¿æ¯”å°
    clean_text = text.replace(" ", "").replace("ã€€", "").replace("\n", "")
    
    for item in VALID_EQUIPMENT_LIST:
        if item in clean_text:
            found_items.append(item)
            
    return "ã€".join(found_items)

def extract_info_from_ocr(text, pages_text_list=None):
    """å¾ OCR æ–‡å­—ä¸­æå–é—œéµè³‡è¨Š (æ¥µè‡´å»ç©ºç™½ç‰ˆ)"""
    info = {}
    
    # --- ç¬¬ä¸€é è§£æ (åŸºæœ¬è³‡æ–™) ---
    if text:
        lines = text.split('\n')
        for line in lines:
            # å¼·åŠ›å»é™¤æ‰€æœ‰ç©ºç™½ (åŒ…å«å…¨å½¢ç©ºæ ¼)
            clean_line = line.replace(" ", "").replace("ã€€", "").strip()
            if not clean_line: continue
            
            # 1. ç®¡ç†æ¬Šäºº
            # å„ªå…ˆæ‰¾ "ç®¡ç†æ¬Šäºº"
            if "ç®¡ç†æ¬Šäºº" in clean_line:
                match = re.search(r"ç®¡ç†æ¬Šäºº[:ï¼š|](.*)", clean_line)
                if match:
                    val = match.group(1)
                    # å¦‚æœæŠ“åˆ°çš„æ˜¯ "é€šè¨Šè™•..." é€™ç¨®ç„¡æ•ˆè³‡æ–™ï¼Œå°±å¿½ç•¥
                    if "é€šè¨Šè™•" not in val:
                        info['ç®¡ç†æ¬Šäºº'] = val
            
            # å‚™ç”¨ï¼šæ‰¾ "å§“å" (ä½†è¦æ’é™¤ "æª¢ä¿®äººå“¡å§“å")
            if "å§“å" in clean_line and "æª¢ä¿®äººå“¡" not in clean_line and "ç®¡ç†æ¬Šäºº" not in info:
                 match = re.search(r"å§“å[:ï¼š|](.*)", clean_line)
                 if match:
                     # å¯èƒ½æœƒæŠ“åˆ° "å»–å‰éŠ˜èº«åˆ†è­‰å­—è™Ÿ..."ï¼Œè©¦è‘—åˆ‡æ‰å¾Œé¢
                     val = match.group(1)
                     if "èº«åˆ†è­‰" in val:
                         val = val.split("èº«åˆ†è­‰")[0]
                     info['ç®¡ç†æ¬Šäºº'] = val
            
            # 2. åœ°å€
            if "åœ°å€" in clean_line:
                 # å„ªå…ˆæŠ“ "å ´æ‰€åœ°å€"
                 if "å ´æ‰€åœ°å€" in clean_line:
                     match = re.search(r"å ´æ‰€åœ°å€[:ï¼š|](.*)", clean_line)
                     if match:
                         info['å ´æ‰€åœ°å€'] = match.group(1)
                 # å¦‚æœæ˜¯ "åœ°å€" ä¸” å­—å…¸è£¡é‚„æ²’æœ‰ "å ´æ‰€åœ°å€" (é¿å…è¦†è“‹æ‰çœŸæ­£çš„å ´æ‰€åœ°å€ï¼Œå› ç‚ºå¾Œé¢å¯èƒ½æœƒå‡ºç¾æª¢ä¿®å–®ä½çš„åœ°å€)
                 elif "åœ°å€" in clean_line and 'å ´æ‰€åœ°å€' not in info:
                     match = re.search(r"åœ°å€[:ï¼š|](.*)", clean_line)
                     if match:
                         info['å ´æ‰€åœ°å€'] = match.group(1)

            # 3. é›»è©±
            if "é›»è©±" in clean_line:
                # æ’é™¤ "ç®¡ç†æ¬Šäººé›»è©±" (é€šå¸¸æˆ‘å€‘æƒ³æŠ“å ´æ‰€é›»è©±)
                # åªæœ‰ç•¶å­—å…¸è£¡é‚„æ²’æœ‰é›»è©±æ™‚æ‰æŠ“å– (é¿å…æŠ“åˆ°ä¸‹é¢æª¢ä¿®å…¬å¸çš„é›»è©±)
                if 'å ´æ‰€é›»è©±' not in info:
                    match = re.search(r"é›»è©±[:ï¼š|]([\d\-]+)", clean_line)
                    if match:
                         info['å ´æ‰€é›»è©±'] = match.group(1)
                     
            # 4. å ´æ‰€åç¨±
            if "å ´æ‰€åç¨±" in clean_line:
                match = re.search(r"å ´æ‰€åç¨±[:ï¼š|](.*)", clean_line)
                if match:
                    info['å ´æ‰€åç¨±'] = match.group(1)

            # 5. æ¶ˆé˜²è¨­å‚™ç¨®é¡ (ç¬¬ä¸€é å‚™ç”¨)
            # å¦‚æœæ²’æœ‰ç¬¬äºŒé è³‡æ–™ï¼Œæ‰å˜—è©¦å¾ç¬¬ä¸€é æŠ“ (é€šå¸¸æ˜¯ "ç”³å ±é …ç›®" æˆ– "æª¢ä¿®é …ç›®")
            if not pages_text_list:
                if "ç”³å ±é …ç›®" in clean_line or "æª¢ä¿®é …ç›®" in clean_line:
                     match = re.search(r"(ç”³å ±é …ç›®|æª¢ä¿®é …ç›®)[:ï¼š|](.*)", clean_line)
                     if match:
                         # ä½¿ç”¨æ­£è¦åŒ–å‡½å¼è™•ç†
                         info['æ¶ˆé˜²è¨­å‚™ç¨®é¡'] = normalize_equipment_str(match.group(2))

    # --- å¤šé è§£æ (å°‹æ‰¾æ¶ˆé˜²è¨­å‚™ç¨®é¡) ---
    if pages_text_list and isinstance(pages_text_list, list):
        target_page_text = None
        
        # 1. å„ªå…ˆå°‹æ‰¾åŒ…å« "æ¶ˆé˜²å®‰å…¨è¨­å‚™æª¢ä¿®ç”³å ±æ›¸ç›®éŒ„" çš„é é¢
        for page_text in pages_text_list:
            if "æ¶ˆé˜²å®‰å…¨è¨­å‚™æª¢ä¿®ç”³å ±æ›¸ç›®éŒ„" in page_text.replace(" ", ""):
                target_page_text = page_text
                break
        
        # 2. å¦‚æœæ‰¾ä¸åˆ°ï¼Œå›é€€ä½¿ç”¨ç¬¬äºŒé  (Index 1)
        if not target_page_text and len(pages_text_list) > 1:
            target_page_text = pages_text_list[1]
            
        if target_page_text:
            # ç­–ç•¥ï¼š
            # 1. æ‰¾åˆ° "äºŒã€æ¶ˆé˜²å®‰å…¨è¨­å‚™æª¢æŸ¥è¡¨" ä¹‹å¾Œçš„å…§å®¹
            # 2. æŠ“å–æ‰€æœ‰åŒ…å« "æª¢æŸ¥è¡¨" çš„è¡Œ
            # 3. å‚³å…¥ normalize_equipment_str é€²è¡Œçµ±ä¸€æ¯”å°
            
            # ç‚ºäº†æé«˜æº–ç¢ºç‡ï¼Œæˆ‘å€‘å…ˆæŠŠ "äºŒã€æ¶ˆé˜²å®‰å…¨è¨­å‚™æª¢æŸ¥è¡¨" ä¹‹å¾Œçš„æ–‡å­—æˆªå–å‡ºä¾†
            # ç°¡å–®åšæ³•ï¼šæ‰¾åˆ°é—œéµå­—å¾Œï¼Œå–å…¶å¾Œçš„æ‰€æœ‰æ–‡å­—
            clean_page_text = target_page_text.replace(" ", "").replace("ã€€", "")
            if "æ¶ˆé˜²å®‰å…¨è¨­å‚™æª¢æŸ¥è¡¨" in clean_page_text:
                # åˆ‡å‰²å‡ºå¾ŒåŠæ®µ
                relevant_text = clean_page_text.split("æ¶ˆé˜²å®‰å…¨è¨­å‚™æª¢æŸ¥è¡¨", 1)[1]
                
                # ç›´æ¥å°é€™æ®µæ–‡å­—é€²è¡Œæ­£è¦åŒ–æ¯”å°
                normalized_eq = normalize_equipment_str(relevant_text)
                if normalized_eq:
                    info['æ¶ˆé˜²è¨­å‚™ç¨®é¡'] = normalized_eq
                 
    return info






# ==========================================
# ä¸»ç¨‹å¼å€
# ==========================================

st.title("ğŸš’ è‡ºæ±ç¸£æ¶ˆé˜²å±€æª¢ä¿®ç”³å ±æ›¸æª¢æ ¸æ¯”å°ç³»çµ±")

# CSS æ¨£å¼ï¼šå·¦å³åˆ†æ¬„ç¨ç«‹æ²å‹• (Split View)
st.markdown("""
    <style>
    /* é‡å°ä¸»å€å¡Š (Main) çš„é›™æ¬„ä½è¨­å®šç¨ç«‹æ²å‹• */
    
    /* å·¦å´æ¬„ä½ (ç”³å ±æª”æ¡ˆ)ï¼šè¨­å®šå›ºå®šé«˜åº¦ + æ²å‹•è»¸ */
    section[data-testid="stMain"] div[data-testid="column"]:nth-of-type(1) > div[data-testid="stVerticalBlock"] {
        height: 80vh;       /* è¨­å®šé«˜åº¦ä½”è¢å¹• 80% */
        overflow-y: auto;   /* è¶…éé«˜åº¦é¡¯ç¤ºæ²å‹•è»¸ */
        padding-right: 15px;
        border-right: 1px solid #444; /* ä¸­é–“åŠ ä¸€æ¢åˆ†éš”ç·š */
    }
    
    /* å³å´æ¬„ä½ (æ¯”å°è¡¨æ ¼)ï¼šè¨­å®šå›ºå®šé«˜åº¦ + æ²å‹•è»¸ */
    section[data-testid="stMain"] div[data-testid="column"]:nth-of-type(2) > div[data-testid="stVerticalBlock"] {
        height: 80vh;       /* è¨­å®šé«˜åº¦ä½”è¢å¹• 80% */
        overflow-y: auto;   /* è¶…éé«˜åº¦é¡¯ç¤ºæ²å‹•è»¸ */
        padding-left: 15px;
    }
    </style>
    """, unsafe_allow_html=True)

# --- å´é‚Šæ¬„ï¼šè³‡æ–™è¼‰å…¥ ---
with st.sidebar:
    st.header("1. è¨­å®šèˆ‡è³‡æ–™ä¾†æº")
    
    # Tesseract è·¯å¾‘è¨­å®š (ç§»é™¤ä½¿ç”¨è€…è¼¸å…¥ï¼Œæ”¹ç‚ºè‡ªå‹•åµæ¸¬èˆ‡è¨­å®šæª”è®€å–)
    tesseract_path = None
    
    # 1. å˜—è©¦å¾è¨­å®šæª”è®€å–
    config_path = config_loader.CONFIG.get("ocr", {}).get("default_tesseract_path")
    if config_path and os.path.exists(config_path):
        tesseract_path = config_path
    
    # 2. å¦‚æœè¨­å®šæª”çš„è·¯å¾‘ä¸å­˜åœ¨ï¼Œå˜—è©¦è‡ªå‹•åµæ¸¬
    if not tesseract_path:
        possible_paths = [
            r"C:\Program Files\Tesseract-OCR\tesseract.exe",
            r"D:\Program Files\Tesseract-OCR\tesseract.exe",
            r"E:\Program Files\Tesseract-OCR\tesseract.exe",
            r"C:\Program Files (x86)\Tesseract-OCR\tesseract.exe",
            r"D:\Program Files (x86)\Tesseract-OCR\tesseract.exe"
        ]
        for p in possible_paths:
            if os.path.exists(p):
                tesseract_path = p
                break
    
    with st.expander("âš™ï¸ OCR è¨­å®šç‹€æ…‹", expanded=True):
        if tesseract_path and os.path.exists(tesseract_path):
             st.success(f"âœ… å·²åµæ¸¬åˆ° Tesseract: {tesseract_path}")
        else:
             st.error("âŒ æ‰¾ä¸åˆ° Tesseract åŸ·è¡Œæª”ï¼\nè«‹å®‰è£ Tesseract-OCR æˆ–åœ¨ config.toml ä¸­è¨­å®šæ­£ç¢ºè·¯å¾‘ã€‚")
             if not tesseract_path:
                tesseract_path = "tesseract.exe" # Fallback

        # æª¢æŸ¥èªè¨€åŒ…
        if not os.path.exists(os.path.join(LOCAL_TESSDATA_DIR, "chi_tra.traineddata")):
            st.warning("âš ï¸ ç¼ºå°‘ç¹é«”ä¸­æ–‡èªè¨€åŒ…")
            if st.button("ğŸ“¥ ä¸‹è¼‰ä¸­æ–‡èªè¨€åŒ… (å¿…è¦)"):
                download_lang_data()
    # 1. ç³»çµ±è³‡æ–™ (ä½¿ç”¨è¨­å®šæª”é è¨­å€¼æˆ–ä¸Šå‚³æª”æ¡ˆ)
    
    # è®€å–é è¨­è·¯å¾‘ (å¾è¨­å®šæª”)
    default_excel_path = config_loader.CONFIG.get("ocr", {}).get("default_excel_path")
    
    # æä¾›æª”æ¡ˆä¸Šå‚³é¸é … (å„ªå…ˆæ–¼é è¨­è·¯å¾‘)
    uploaded_system_file = st.file_uploader("ä¸Šå‚³ç³»çµ±åˆ—ç®¡è³‡æ–™ (Excel)", type=["xls", "xlsx"])
    
    system_source = None
    if uploaded_system_file:
        system_source = uploaded_system_file
        st.info("ğŸ“‚ ä½¿ç”¨ä¸Šå‚³çš„ç³»çµ±è³‡æ–™")
    elif default_excel_path and os.path.exists(default_excel_path):
        system_source = default_excel_path
        st.caption(f"ğŸ“‚ ä½¿ç”¨é è¨­ç³»çµ±è³‡æ–™ä¾†æº: {os.path.basename(default_excel_path)}")
    else:
        st.warning("âš ï¸ æœªè¨­å®šç³»çµ±è³‡æ–™ä¾†æºï¼Œè«‹ä¸Šå‚³æª”æ¡ˆæˆ–æª¢æŸ¥ config.toml è¨­å®šã€‚")

    df_system = load_system_data(system_source)
    
    selected_place = None
    
    if df_system is not None:
        st.success(f"å·²è¼‰å…¥ç³»çµ±è³‡æ–™: {len(df_system)} ç­†")
        
        # é™¤éŒ¯ç”¨ï¼šé¡¯ç¤ºæ¬„ä½åç¨±
        with st.expander("ğŸ” æŸ¥çœ‹ Excel æ¬„ä½åç¨± (é™¤éŒ¯ç”¨)"):
            st.write(df_system.columns.tolist())
        
        # 2. é¸æ“‡å ´æ‰€ (å¢åŠ æœå°‹åŠŸèƒ½)
        st.header("2. é¸æ“‡æ¯”å°å ´æ‰€")
        
        # å–å¾—æ‰€æœ‰å ´æ‰€åç¨±
        all_place_names = df_system['å ´æ‰€åç¨±'].astype(str).unique().tolist()
        
        # æœå°‹æ¡†
        search_term = st.text_input("ğŸ” æœå°‹å ´æ‰€åç¨± (æ”¯æ´æ¨¡ç³Šæ¯”å°)", "")
        
        # æ ¹æ“šæœå°‹çµæœéæ¿¾
        if search_term:
            filtered_places = [p for p in all_place_names if search_term in p]
        else:
            filtered_places = all_place_names
            
        # å¦‚æœæœå°‹ä¸åˆ°ï¼Œé¡¯ç¤ºæç¤º
        if not filtered_places:
            st.warning("æ‰¾ä¸åˆ°ç¬¦åˆçš„å ´æ‰€")
        else:
            # ä¸‹æ‹‰é¸å–® (åªé¡¯ç¤ºéæ¿¾å¾Œçš„çµæœ)
            selected_place = st.selectbox("è«‹é¸æ“‡å ´æ‰€", filtered_places)
        
    else:
        st.warning("å°šæœªè¼‰å…¥ç³»çµ±è³‡æ–™ï¼Œè«‹ç¢ºèªè·¯å¾‘ã€‚")

# --- ä¸»ç•«é¢ï¼šæ¯”å°å€ ---
uploaded_file = None
target_row = None

# 1. å…ˆå»ºç«‹ç‰ˆé¢ (å·¦å³åˆ†æ¬„)
col1, col2 = st.columns([1, 1])

# ç”¨æ–¼å„²å­˜ OCR çµæœ
all_ocr_text = ""
page_one_text = ""
page_two_text = ""
extracted_data = {}
ocr_place_name = ""

# å·¦æ¬„ï¼šæ°‘çœ¾ç”³å ±è³‡æ–™ (PDF/åœ–ç‰‡)
with col1:
    st.subheader("ğŸ“„ æ°‘çœ¾ç”³å ±è³‡æ–™ (OCR è¾¨è­˜)")
    
    # å°‡ä¸Šå‚³å…ƒä»¶ç§»è‡³æ­¤è™•
    uploaded_file = st.file_uploader("è«‹æ‹–æ‹‰æˆ–é¸æ“‡ç”³å ±æª”æ¡ˆ (PDF/åœ–ç‰‡)", type=["pdf", "png", "jpg", "jpeg"])
    
    if uploaded_file:
        # ç”¢ç”Ÿæª”æ¡ˆå”¯ä¸€è­˜åˆ¥ç¢¼ (ä½¿ç”¨æª”å+å¤§å°)
        file_key = f"{uploaded_file.name}_{uploaded_file.size}"
        
        # æª¢æŸ¥ Session State æ˜¯å¦å·²æœ‰æ­¤æª”æ¡ˆçš„ OCR çµæœ
        if 'ocr_cache' not in st.session_state:
            st.session_state.ocr_cache = {}
        
        # å¦‚æœæ˜¯æ–°æª”æ¡ˆæˆ–å°šæœªè¾¨è­˜é
        if st.session_state.ocr_cache.get('file_key') != file_key:
            # 1. å…ˆè½‰æ›ä¸¦é¡¯ç¤ºåœ–ç‰‡ (è®“ä½¿ç”¨è€…å…ˆçœ‹åˆ°é è¦½)
            images = []
            if uploaded_file.type == "application/pdf":
                # é¡¯ç¤ºè½‰æ›è¨Šæ¯
                with st.spinner("ğŸ“„ æ­£åœ¨å°‡ PDF è½‰æ›ç‚ºåœ–ç‰‡..."):
                    images = pdf_to_images(uploaded_file)
            else:
                images = [Image.open(uploaded_file)]
            
            # å…ˆé¡¯ç¤ºåœ–ç‰‡é è¦½
            for i, img in enumerate(images):
                st.image(img, caption=f"ç¬¬ {i+1} é  (é è¦½)", use_container_width=True)
            
            # 2. åŸ·è¡Œ OCR
            with st.spinner("ğŸ” æ­£åœ¨é€²è¡Œ OCR è¾¨è­˜ä¸­ (è«‹ç¨å€™)..."):
                temp_all_text = ""
                temp_p1_text = ""
                temp_p2_text = ""
                
                # åŸ·è¡Œ OCR
                pages_text = []
                for i, img in enumerate(images):
                    ocr_text = perform_ocr(img, tesseract_path)
                    temp_all_text += ocr_text + "\n"
                    pages_text.append(ocr_text)
                    
                    if i == 0: temp_p1_text = ocr_text
                    if i == 1: temp_p2_text = ocr_text
                
                # å­˜å…¥ Session State
                st.session_state.ocr_cache['file_key'] = file_key
                st.session_state.ocr_cache['all_ocr_text'] = temp_all_text
                st.session_state.ocr_cache['page_one_text'] = temp_p1_text
                st.session_state.ocr_cache['page_two_text'] = temp_p2_text
                st.session_state.ocr_cache['pages_text'] = pages_text # å„²å­˜æ‰€æœ‰é é¢æ–‡å­—
                st.session_state.ocr_cache['images'] = images 
                
                # é‡æ–°æ•´ç†é é¢ä»¥é¡¯ç¤º OCR çµæœ
                st.rerun()
        
        # å¾ Session State å–å‡ºè³‡æ–™ (Cache Hit)
        all_ocr_text = st.session_state.ocr_cache.get('all_ocr_text', "")
        page_one_text = st.session_state.ocr_cache.get('page_one_text', "")
        page_two_text = st.session_state.ocr_cache.get('page_two_text', "")
        pages_text = st.session_state.ocr_cache.get('pages_text', [])
        cached_images = st.session_state.ocr_cache.get('images', [])
        
        # æå–è³‡æ–™
        extracted_data = extract_info_from_ocr(page_one_text, pages_text)
        ocr_place_name = extracted_data.get('å ´æ‰€åç¨±', '')

        # é¡¯ç¤ºåœ–ç‰‡èˆ‡ OCR çµæœ (é€™æ˜¯ Rerun å¾Œæˆ– Cache Hit æœƒçœ‹åˆ°çš„)
        for i, img in enumerate(cached_images):
            st.image(img, caption=f"ç¬¬ {i+1} é ", use_container_width=True)
            with st.expander(f"ç¬¬ {i+1} é  OCR æ–‡å­—å…§å®¹ (é™¤éŒ¯ç”¨)", expanded=False):
                if i == 0: st.text(page_one_text)
                elif i == 1: st.text(page_two_text)
                else: st.text("(å…¶ä»–é é¢å…§å®¹è«‹è¦‹ç¸½è¦½)")
                
                if "Error" in all_ocr_text:
                        st.error("OCR åŸ·è¡Œå¤±æ•—ï¼Œè«‹æª¢æŸ¥å´é‚Šæ¬„çš„ Tesseract è¨­å®šã€‚")
    else:
        st.info("ğŸ‘ˆ è«‹åœ¨ä¸Šæ–¹ä¸Šå‚³æ°‘çœ¾ç”³å ±æª”æ¡ˆ (PDF) ä»¥é–‹å§‹æ¯”å°ã€‚")

# é‚è¼¯ï¼šæ±ºå®šä½¿ç”¨å“ªä¸€ç­†ç³»çµ±è³‡æ–™ (target_row)
# å„ªå…ˆé †åºï¼š
# 1. è‡ªå‹•æ¯”å°ï¼šè‹¥ OCR æœ‰æŠ“åˆ°å ´æ‰€åç¨±ï¼Œä¸”åœ¨ç³»çµ±è³‡æ–™ä¸­æ‰¾å¾—åˆ° (å®Œå…¨ç¬¦åˆæˆ–åŒ…å«)
# 2. æ‰‹å‹•é¸æ“‡ï¼šä½¿ç”¨å´é‚Šæ¬„é¸å–çš„ selected_place

auto_matched_place = None
if df_system is not None and ocr_place_name:
    # å˜—è©¦è‡ªå‹•æœå°‹
    # 1. å®Œå…¨ç¬¦åˆ
    match = df_system[df_system['å ´æ‰€åç¨±'] == ocr_place_name]
    if not match.empty:
        auto_matched_place = ocr_place_name
        target_row = match.iloc[0]
    else:
        # 2. æ¨¡ç³Š/åŒ…å«æœå°‹ (å»é™¤å°/è‡ºå·®ç•°)
        clean_ocr = ocr_place_name.replace("å°", "è‡º").replace(" ", "")
        
        # æœå°‹ç³»çµ±è³‡æ–™ä¸­æ˜¯å¦æœ‰åŒ…å«æ­¤åç¨±çš„
        # é€™è£¡åšä¸€å€‹ç°¡å–®çš„éæ­·æœå°‹
        for idx, row in df_system.iterrows():
            sys_name = str(row['å ´æ‰€åç¨±'])
            clean_sys = sys_name.replace("å°", "è‡º").replace(" ", "")
            
            if clean_ocr and (clean_ocr in clean_sys or clean_sys in clean_ocr):
                auto_matched_place = sys_name
                target_row = row
                break

# å¦‚æœæ²’æœ‰è‡ªå‹•æ¯”å°åˆ°ï¼Œå‰‡ä½¿ç”¨æ‰‹å‹•é¸æ“‡çš„
if target_row is None and selected_place and df_system is not None:
    target_row = df_system[df_system['å ´æ‰€åç¨±'] == selected_place].iloc[0]

# å³æ¬„ï¼šç³»çµ±åˆ—ç®¡è³‡æ–™
with col2:
    # --- å¯©æ ¸å€å¡Š (ç½®é ‚) ---
    st.markdown("### ğŸ‘® æ¡ˆä»¶å¯©æ ¸")
    review_col1, review_col2 = st.columns([2, 3])
    with review_col1:
        applicant_email = st.text_input("ç”³è«‹äººä¿¡ç®±", placeholder="example@email.com")
    with review_col2:
        st.write("å¯©æ ¸çµæœé€šçŸ¥ï¼š")
        b1, b2, b3 = st.columns(3)
        
        # å®šç¾©ç™¼é€é‚è¼¯
        def handle_review(status, subject_prefix, msg_template):
            if not applicant_email:
                st.warning("è«‹å…ˆè¼¸å…¥ç”³è«‹äººä¿¡ç®±")
                return
            
            # é¡¯ç¤º UI è¨Šæ¯ (æ¨¡æ“¬)
            if status == "success":
                st.success(f"å·²ç”¢ç”Ÿã€{subject_prefix}ã€‘é€šçŸ¥")
            elif status == "warning":
                st.warning(f"å·²ç”¢ç”Ÿã€{subject_prefix}ã€‘é€šçŸ¥")
            else:
                st.error(f"å·²ç”¢ç”Ÿã€{subject_prefix}ã€‘é€šçŸ¥")
                
            # å˜—è©¦ç™¼é€çœŸå¯¦éƒµä»¶
            if sender_email and sender_password:
                with st.spinner("ğŸ“§ æ­£åœ¨ç™¼é€éƒµä»¶..."):
                    subject = f"ã€æ¶ˆé˜²å±€é€šçŸ¥ã€‘æ¡ˆä»¶å¯©æ ¸çµæœï¼š{subject_prefix}"
                    body = f"æ‚¨å¥½ï¼Œ\n\næ‚¨çš„æ¶ˆé˜²å®‰å…¨è¨­å‚™æª¢ä¿®ç”³å ±æ¡ˆä»¶å¯©æ ¸çµæœç‚ºï¼š{subject_prefix}ã€‚\n\n{msg_template}\n\nè‡ºæ±ç¸£æ¶ˆé˜²å±€ æ•¬å•Ÿ"
                    
                    success, msg = send_email(sender_email, sender_password, applicant_email, subject, body)
                    if success:
                        st.toast(f"âœ… éƒµä»¶å·²æˆåŠŸç™¼é€è‡³ {applicant_email}")
                    else:
                        st.error(msg)
            else:
                st.info("ğŸ’¡ æç¤ºï¼šè‹¥éœ€ç™¼é€çœŸå¯¦éƒµä»¶ï¼Œè«‹è‡³å´é‚Šæ¬„è¨­å®šå¯„ä»¶è€…è³‡è¨Šã€‚")

        if b1.button("âœ… åˆæ ¼"):
            handle_review("success", "åˆæ ¼", "æ­å–œæ‚¨ï¼Œæ¡ˆä»¶å·²å¯©æ ¸é€šéã€‚")
        
        if b2.button("âš ï¸ è£œä»¶"):
            handle_review("warning", "è£œä»¶", "è«‹å„˜é€Ÿè£œé½Šç›¸é—œæ–‡ä»¶ã€‚")

        if b3.button("ğŸš« é€€ä»¶"):
            handle_review("error", "é€€ä»¶", "æ¡ˆä»¶å·²è¢«é€€å›ï¼Œè«‹ä¿®æ­£å¾Œé‡æ–°ç”³å ±ã€‚")
    
    st.divider()
    
    st.subheader("ğŸ’» ç³»çµ±åˆ—ç®¡è³‡æ–™ vs ç”³å ±è³‡æ–™")
    
    if target_row is not None:
        # é¡¯ç¤ºç›®å‰ä½¿ç”¨çš„å ´æ‰€è³‡æ–™ä¾†æº
        if auto_matched_place:
            st.success(f"ğŸ¤– å·²è‡ªå‹•å°æ‡‰ç³»çµ±å ´æ‰€ï¼š{auto_matched_place}")
        elif selected_place:
            st.info(f"ğŸ‘¤ ç›®å‰æ‰‹å‹•é¸æ“‡å ´æ‰€ï¼š{selected_place}")
            if ocr_place_name:
                st.warning(f"âš ï¸ ç³»çµ±ç„¡æ³•è‡ªå‹•å°æ‡‰ OCR å ´æ‰€ã€Œ{ocr_place_name}ã€ï¼Œè«‹ç¢ºèªæ‰‹å‹•é¸æ“‡æ˜¯å¦æ­£ç¢ºã€‚")
        
        if uploaded_file:
            # é¡¯ç¤ºé–å®šè³‡è¨Š
            if page_one_text:
                st.caption("â„¹ï¸ å·²é–å®šä½¿ç”¨ç¬¬ 1 é å…§å®¹é€²è¡Œè‡ªå‹•å¡«å…¥ (åŸºæœ¬è³‡æ–™)")
            if page_two_text:
                st.caption("â„¹ï¸ å·²é–å®šä½¿ç”¨ç¬¬ 2 é å…§å®¹é€²è¡Œè‡ªå‹•å¡«å…¥ (æ¶ˆé˜²è¨­å‚™ç¨®é¡)")
        else:
            st.caption("â„¹ï¸ ç­‰å¾…ä¸Šå‚³ç”³å ±æª”æ¡ˆä»¥é€²è¡Œè‡ªå‹•å¡«å…¥...")
        
        # å®šç¾©æ¬„ä½å°æ‡‰
        field_mapping = {
            'å ´æ‰€åç¨±': 'å ´æ‰€åç¨±',
            'å ´æ‰€åœ°å€': 'å ´æ‰€åœ°å€',
            'ç®¡ç†æ¬Šäºº': 'ç®¡ç†æ¬Šäººå§“å',
            'é›»è©±': 'å ´æ‰€é›»è©±',
            'æ¶ˆé˜²è¨­å‚™ç¨®é¡': 'æ¶ˆé˜²å®‰å…¨è¨­å‚™'
        }
        
        # æª¢æŸ¥å ´æ‰€åç¨±æ˜¯å¦ä¸€è‡´ (å¦‚æœæ˜¯æ‰‹å‹•é¸æ“‡æ‰éœ€è¦è­¦å‘Šï¼Œè‡ªå‹•å°æ‡‰é€šå¸¸å°±æ˜¯ä¸€è‡´çš„)
        # é è¨­ä¸é¡¯ç¤ºç³»çµ±è³‡æ–™ï¼Œç›´åˆ°æœ‰ä¸Šå‚³æª”æ¡ˆä¸”æ¯”å°ç‹€æ…‹å…è¨±
        show_system_data = False
        
        if uploaded_file:
            show_system_data = True
            
            if not auto_matched_place and ocr_place_name and selected_place:
                clean_ocr = ocr_place_name.replace("å°", "è‡º").replace(" ", "")
                clean_sys = selected_place.replace("å°", "è‡º").replace(" ", "")
                
                if clean_sys not in clean_ocr and clean_ocr not in clean_sys:
                     st.error(f"âš ï¸ è­¦å‘Šï¼šOCR è¾¨è­˜åˆ°çš„å ´æ‰€åç¨±ã€Œ{ocr_place_name}ã€èˆ‡æ‚¨é¸æ“‡çš„ç³»çµ±å ´æ‰€ã€Œ{selected_place}ã€ä¸ç¬¦ï¼")
                     # å¦‚æœæ¯”å°ä¸æˆåŠŸï¼Œä¸”æ˜¯æ‰‹å‹•é¸æ“‡çš„ä¸ä¸€è‡´ï¼Œå‰‡ä¸é¡¯ç¤ºç³»çµ±è³‡æ–™ï¼Œé¿å…èª¤å°
                     show_system_data = False

        # å»ºç«‹æ¯”å°è¡¨æ ¼è³‡æ–™
        comparison_data = []
        for display_name, excel_col in field_mapping.items():
            # ç³»çµ±è³‡æ–™
            sys_val = ""
            if show_system_data:
                sys_val = target_row.get(excel_col, "ç„¡è³‡æ–™")
                if pd.isna(sys_val): sys_val = ""
            
            # ç‰¹æ®Šè™•ç†ï¼šæ¶ˆé˜²è¨­å‚™ç¨®é¡ (ç³»çµ±è³‡æ–™) - æ›è¡Œé¡¯ç¤º
            if display_name == 'æ¶ˆé˜²è¨­å‚™ç¨®é¡' and isinstance(sys_val, str) and show_system_data:
                # ä½¿ç”¨æ¨™æº–åŒ–å‡½å¼è™•ç†ç³»çµ±è³‡æ–™
                # é€™æœƒéæ¿¾æ‰ä¸ç›¸é—œçš„æ–‡å­—ï¼Œåªä¿ç•™æ¨™æº–è¨­å‚™åç¨±ï¼Œä¸¦ä»¥é “è™Ÿåˆ†éš”
                normalized_sys_val = normalize_equipment_str(sys_val)
                
                # ç›´æ¥ä½¿ç”¨é “è™Ÿåˆ†éš”
                sys_val = normalized_sys_val
            
            # ç”³å ±è³‡æ–™
            ocr_key = display_name
            if display_name == 'é›»è©±':
                ocr_key = 'å ´æ‰€é›»è©±'
            
            ocr_val = extracted_data.get(ocr_key, "")
            
            # ç‰¹æ®Šè™•ç†ï¼šæ¶ˆé˜²è¨­å‚™ç¨®é¡ (ç”³å ±è³‡æ–™) - æ›è¡Œé¡¯ç¤º
            # ä¿æŒé “è™Ÿåˆ†éš”
            pass
            
            comparison_data.append({
                "æ¬„ä½": display_name,
                "ç³»çµ±è³‡æ–™": str(sys_val),
                "ç”³å ±è³‡æ–™ (OCR/äººå·¥)": ocr_val
            })
            
        # è½‰ç‚º DataFrame
        df_comparison = pd.DataFrame(comparison_data)

        # ä½¿ç”¨ data_editor è®“ä½¿ç”¨è€…å¯ä»¥ç·¨è¼¯å³é‚Šçš„æ¬„ä½
        edited_df = st.data_editor(
            df_comparison,
            column_config={
                "æ¬„ä½": st.column_config.TextColumn(disabled=True),
                "ç³»çµ±è³‡æ–™": st.column_config.TextColumn(
                    "ç³»çµ±è³‡æ–™",
                    disabled=True,
                    width="medium" # å¢åŠ å¯¬åº¦ä»¥åˆ©é–±è®€
                ),
                "ç”³å ±è³‡æ–™ (OCR/äººå·¥)": st.column_config.TextColumn(
                    "ç”³å ±è³‡æ–™ (å¯ç·¨è¼¯)",
                    help="å¦‚æœæ˜¯ç©ºçš„ï¼Œè«‹åƒè€ƒå·¦å´åœ–ç‰‡æ‰‹å‹•è¼¸å…¥",
                    required=False,
                    width="medium"
                )
            },
            hide_index=True,
            use_container_width=True
        )
        
        st.warning("ğŸ’¡ ç”³å ±è³‡æ–™æ¬„ä½è‹¥ç‚ºç©ºç™½ï¼Œè«‹åƒè€ƒå·¦å´å½±åƒæ‰‹å‹•è¼¸å…¥ã€‚")
        
        # æª¢æ ¸æ¸…å–®
        st.write("### âœ… å·®ç•°æª¢æ ¸")
        
        # è‡ªå‹•åˆ¤æ–·å·®ç•° (ç°¡å–®æ¯”å°)
        for index, row in edited_df.iterrows():
            field = row['æ¬„ä½']
            sys_val = str(row['ç³»çµ±è³‡æ–™']).strip()
            ocr_val = str(row['ç”³å ±è³‡æ–™ (OCR/äººå·¥)']).strip()
            
            # åœ°å€æ¨¡ç³Šæ¯”å°é‚è¼¯
            if field == 'å ´æ‰€åœ°å€':
                # å®šç¾©æ­£è¦åŒ–å‡½å¼
                def normalize_addr(addr):
                    # 1. çµ±ä¸€ å°/è‡º
                    addr = addr.replace("å°", "è‡º")
                    # 2. å»é™¤é–‹é ­çš„ "è‡ºæ±ç¸£" (æˆ– "å°æ±ç¸£")
                    addr = addr.replace("è‡ºæ±ç¸£", "")
                    # 3. å»é™¤ç©ºç™½
                    addr = addr.replace(" ", "")
                    return addr
                
                norm_sys = normalize_addr(sys_val)
                norm_ocr = normalize_addr(ocr_val)
                
                if ocr_val and norm_sys != norm_ocr:
                     # å˜—è©¦æ›´å¯¬é¬†çš„æ¯”å° (ä¾‹å¦‚åŒ…å«é—œä¿‚)
                     if norm_ocr in norm_sys or norm_sys in norm_ocr:
                          st.success(f"âœ… ã€{field}ã€‘ä¸€è‡´ (æ¨¡ç³Šæ¯”å°æˆåŠŸ)")
                     else:
                          st.error(f"âš ï¸ ã€{field}ã€‘ä¸ä¸€è‡´ï¼\nç³»çµ±ï¼š{sys_val} (æ­£è¦åŒ–å¾Œ: {norm_sys})\nç”³å ±ï¼š{ocr_val} (æ­£è¦åŒ–å¾Œ: {norm_ocr})")
                elif ocr_val and norm_sys == norm_ocr:
                    st.success(f"âœ… ã€{field}ã€‘ä¸€è‡´")
                else:
                    st.info(f"âšª ã€{field}ã€‘å¾…ç¢ºèª")
            
            # æ¶ˆé˜²è¨­å‚™ç¨®é¡çš„ç‰¹æ®Šæ¯”å°é‚è¼¯
            elif field == 'æ¶ˆé˜²è¨­å‚™ç¨®é¡':
                if ocr_val and sys_val != ocr_val:
                    # è½‰ç‚ºé›†åˆé€²è¡Œæ¯”å°
                    sys_set = set(sys_val.split("ã€")) if sys_val else set()
                    ocr_set = set(ocr_val.split("ã€")) if ocr_val else set()
                    
                    # å»é™¤ç©ºå­—ä¸²
                    sys_set.discard("")
                    ocr_set.discard("")
                    
                    # è¨ˆç®—å·®ç•°
                    missing_in_ocr = sys_set - ocr_set # ç³»çµ±æœ‰ï¼Œç”³å ±ç„¡ (æ¼å ±?)
                    extra_in_ocr = ocr_set - sys_set   # ç”³å ±æœ‰ï¼Œç³»çµ±ç„¡ (æ–°å¢?)
                    
                    if not missing_in_ocr and not extra_in_ocr:
                        st.success(f"âœ… ã€{field}ã€‘ä¸€è‡´")
                    else:
                        st.error(f"âš ï¸ ã€{field}ã€‘ä¸ä¸€è‡´ï¼")
                        
                        # ä½¿ç”¨ Columns é¡¯ç¤ºå·®ç•°ï¼Œæ¯”è¼ƒæ¸…æ¥š
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            if missing_in_ocr:
                                st.markdown(f"**âŒ ç³»çµ±æœ‰ï¼Œä½†ç”³å ±è³‡æ–™æœªåˆ—å‡ºï¼š**")
                                for item in missing_in_ocr:
                                    st.markdown(f"- <span style='color:red'>{item}</span>", unsafe_allow_html=True)
                            else:
                                st.markdown("**âœ… ç³»çµ±é …ç›®çš†å·²ç”³å ±**")
                                
                        with col2:
                            if extra_in_ocr:
                                st.markdown(f"**â“ ç”³å ±è³‡æ–™å¤šå‡ºçš„é …ç›®ï¼š**")
                                for item in extra_in_ocr:
                                    st.markdown(f"- <span style='color:orange'>{item}</span>", unsafe_allow_html=True)
                            else:
                                st.markdown("**âœ… ç„¡é¡å¤–ç”³å ±é …ç›®**")
                                
                elif ocr_val and sys_val == ocr_val:
                    st.success(f"âœ… ã€{field}ã€‘ä¸€è‡´")
                else:
                    st.info(f"âšª ã€{field}ã€‘å¾…ç¢ºèª")

            # å…¶ä»–æ¬„ä½çš„ä¸€èˆ¬æ¯”å°
            else:
                if ocr_val and sys_val != ocr_val:
                    # å˜—è©¦æ›´å¯¬é¬†çš„æ¯”å° (ä¾‹å¦‚åŒ…å«é—œä¿‚)
                    if ocr_val in sys_val or sys_val in ocr_val:
                         st.success(f"âœ… ã€{field}ã€‘ä¸€è‡´ (éƒ¨åˆ†ç¬¦åˆ)")
                    else:
                         st.error(f"âš ï¸ ã€{field}ã€‘ä¸ä¸€è‡´ï¼ç³»çµ±ï¼š{sys_val} vs ç”³å ±ï¼š{ocr_val}")
                elif ocr_val and sys_val == ocr_val:
                    st.success(f"âœ… ã€{field}ã€‘ä¸€è‡´")
                else:
                    st.info(f"âšª ã€{field}ã€‘å¾…ç¢ºèª")

        # --- æ–°å¢ï¼šæª¢æŸ¥é …ç›® (æ¶ˆé˜²è¨­å‚™) ---
        st.write("---")
        st.subheader("âœ… æª¢æŸ¥é …ç›® (æ¶ˆé˜²å®‰å…¨è¨­å‚™)")
        
        # å®šç¾©è¨­å‚™æ¸…å–®
        equipment_categories = {
            "æ»…ç«è¨­å‚™": [
                "æ»…ç«å™¨", "å®¤å…§æ¶ˆé˜²æ “è¨­å‚™", "å®¤å¤–æ¶ˆé˜²æ “è¨­å‚™", "è‡ªå‹•æ’’æ°´è¨­å‚™", 
                "æ°´éœ§æ»…ç«è¨­å‚™", "æ³¡æ²«æ»…ç«è¨­å‚™", "æƒ°æ€§æ°£é«”æ»…ç«è¨­å‚™", "ä¹¾ç²‰æ»…ç«è¨­å‚™", 
                "æµ·é¾æ»…ç«è¨­å‚™", "ç°¡æ˜“è‡ªå‹•æ»…ç«è¨­å‚™", "é¹µåŒ–çƒ´æ»…ç«è¨­å‚™"
            ],
            "è­¦å ±è¨­å‚™": [
                "ç«è­¦è‡ªå‹•è­¦å ±è¨­å‚™", "ç“¦æ–¯æ¼æ°£ç«è­¦è‡ªå‹•è­¦å ±è¨­å‚™", "ç·Šæ€¥å»£æ’­è¨­å‚™", 
                "ä¸€ä¸€ä¹ç«ç½é€šå ±è£ç½®"
            ],
            "é¿é›£é€ƒç”Ÿè¨­å‚™": [
                "æ¨™ç¤ºè¨­å‚™", "é¿é›£å™¨å…·", "ç·Šæ€¥ç…§æ˜è¨­å‚™"
            ],
            "æ¶ˆé˜²æ¶æ•‘ä¸Šä¹‹å¿…è¦è¨­å‚™": [
                "é€£çµé€æ°´ç®¡", "æ¶ˆé˜²å°ˆç”¨è“„æ°´æ± ", "æ’ç…™è¨­å‚™", "ç„¡ç·šé›»é€šä¿¡è¼”åŠ©è¨­å‚™", 
                "ç·Šæ€¥é›»æºæ’åº§", "é˜²ç½ç›£æ§ç³»çµ±ç¶œåˆæ“ä½œè£ç½®"
            ],
            "å…¶ä»–": [
                "å†·å»æ’’æ°´è¨­å‚™", "å°„æ°´è¨­å‚™", "é…ç·š"
            ]
        }
        
        # å˜—è©¦å¾ç³»çµ±è³‡æ–™ä¸­æ‰¾å‡ºæ‰€æœ‰å¯èƒ½çš„è¨­å‚™å­—ä¸²
        # å°‡æ•´åˆ—è³‡æ–™è½‰ç‚ºå­—ä¸²ï¼Œæ–¹ä¾¿æœå°‹
        system_row_str = target_row.to_string() if target_row is not None else ""
        
        # é¡¯ç¤º Checkbox
        for category, items in equipment_categories.items():
            st.write(f"**{category}**")
            cols = st.columns(3) # åˆ†ä¸‰æ¬„é¡¯ç¤ºæ¯”è¼ƒæ•´é½Š
            for i, item in enumerate(items):
                # åˆ¤æ–·æ˜¯å¦è¦æ‰“å‹¾ (å¦‚æœç³»çµ±è³‡æ–™è£¡é¢æœ‰å‡ºç¾é€™å€‹è©)
                is_checked = item in system_row_str
                
                # ä½¿ç”¨ columns æ’ç‰ˆ
                with cols[i % 3]:
                    st.checkbox(item, value=is_checked, key=f"chk_{item}", disabled=True) # disabled=True è¡¨ç¤ºå”¯è®€ï¼Œåæ˜ ç³»çµ±è³‡æ–™

    else:
        if df_system is None:
             st.warning("è«‹å…ˆåœ¨å·¦å´è¼‰å…¥ç³»çµ± Excel è³‡æ–™ã€‚")
        else:
             st.info("ğŸ‘ˆ è«‹åœ¨å·¦å´é¸æ“‡æ¯”å°å ´æ‰€ï¼Œæˆ–ä¸Šå‚³æª”æ¡ˆé€²è¡Œè‡ªå‹•å°æ‡‰ã€‚")
